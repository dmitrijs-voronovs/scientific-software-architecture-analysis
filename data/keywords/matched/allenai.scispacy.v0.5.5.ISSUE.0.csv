id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/allenai/scispacy/pull/1:0,safety,Test,Test,0,Test team city config;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/1
https://github.com/allenai/scispacy/pull/1:5,security,team,team,5,Test team city config;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/1
https://github.com/allenai/scispacy/pull/1:0,testability,Test,Test,0,Test team city config;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/1
https://github.com/allenai/scispacy/pull/3:10,safety,test,test,10,add dummy test;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/3
https://github.com/allenai/scispacy/pull/3:10,testability,test,test,10,add dummy test;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/3
https://github.com/allenai/scispacy/issues/4:11,security,token,tokenizer,11,Add custom tokenizer;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/4
https://github.com/allenai/scispacy/issues/4:4,usability,custom,custom,4,Add custom tokenizer;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/4
https://github.com/allenai/scispacy/issues/5:4,usability,custom,custom,4,Add custom segmenter;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/5
https://github.com/allenai/scispacy/issues/6:10,safety,test,tests,10,Add spacy tests;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/6
https://github.com/allenai/scispacy/issues/6:10,testability,test,tests,10,Add spacy tests;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/6
https://github.com/allenai/scispacy/issues/7:11,safety,test,tests,11,Add custom tests;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/7
https://github.com/allenai/scispacy/issues/7:11,testability,test,tests,11,Add custom tests;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/7
https://github.com/allenai/scispacy/issues/7:4,usability,custom,custom,4,Add custom tests;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/7
https://github.com/allenai/scispacy/issues/8:13,energy efficiency,model,models,13,Add finished models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/8
https://github.com/allenai/scispacy/issues/8:13,security,model,models,13,Add finished models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/8
https://github.com/allenai/scispacy/issues/9:0,deployability,Updat,Update,0,Update readme to be complete;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/9
https://github.com/allenai/scispacy/issues/9:0,safety,Updat,Update,0,Update readme to be complete;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/9
https://github.com/allenai/scispacy/issues/9:20,safety,compl,complete,20,Update readme to be complete;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/9
https://github.com/allenai/scispacy/issues/9:0,security,Updat,Update,0,Update readme to be complete;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/9
https://github.com/allenai/scispacy/issues/9:20,security,compl,complete,20,Update readme to be complete;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/9
https://github.com/allenai/scispacy/pull/11:25,testability,coverag,coverage,25,Attempt to pass lint and coverage;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/11
https://github.com/allenai/scispacy/pull/13:322,availability,error,errors,322,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:111,deployability,version,version,111,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:111,integrability,version,version,111,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:102,modifiability,pac,packaged,102,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:111,modifiability,version,version,111,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:322,performance,error,errors,322,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:174,safety,test,tests,174,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:220,safety,test,tests,220,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:290,safety,test,tests,290,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:322,safety,error,errors,322,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:7,security,token,tokenizer,7,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:67,security,token,tokenizer,67,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:257,security,modif,modifications,257,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:358,security,token,tokenizer,358,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:174,testability,test,tests,174,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:220,testability,test,tests,220,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:290,testability,test,tests,290,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:0,usability,Custom,Custom,0,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:60,usability,custom,custom,60,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:78,usability,custom,custom,78,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:322,usability,error,errors,322,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/13:351,usability,custom,custom,351,"Custom tokenizer and splitter; This pull request includes a custom tokenizer, custom segmenter, and a packaged version of spaCy that includes them. There are two sections of tests, one folder called spacy_tests which is tests straight from space with minor modifications, and one folder of tests intended to encompass the errors that are fixed by the custom tokenizer and segmenter.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/13
https://github.com/allenai/scispacy/pull/14:18,energy efficiency,model,models,18,"Add genia trained models; @kyleclo This pr includes the genia trained models. I am not entirely sure what is best here, to merge this for you to use them, or to just leave it here and you can pull from it if you want to use it. Do you have thoughts on this? Don't delete this branch without telling Kyle",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/14
https://github.com/allenai/scispacy/pull/14:70,energy efficiency,model,models,70,"Add genia trained models; @kyleclo This pr includes the genia trained models. I am not entirely sure what is best here, to merge this for you to use them, or to just leave it here and you can pull from it if you want to use it. Do you have thoughts on this? Don't delete this branch without telling Kyle",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/14
https://github.com/allenai/scispacy/pull/14:18,security,model,models,18,"Add genia trained models; @kyleclo This pr includes the genia trained models. I am not entirely sure what is best here, to merge this for you to use them, or to just leave it here and you can pull from it if you want to use it. Do you have thoughts on this? Don't delete this branch without telling Kyle",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/14
https://github.com/allenai/scispacy/pull/14:70,security,model,models,70,"Add genia trained models; @kyleclo This pr includes the genia trained models. I am not entirely sure what is best here, to merge this for you to use them, or to just leave it here and you can pull from it if you want to use it. Do you have thoughts on this? Don't delete this branch without telling Kyle",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/14
https://github.com/allenai/scispacy/pull/15:0,deployability,Updat,Update,0,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:7,deployability,version,version,7,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:70,deployability,updat,update,70,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:118,deployability,version,version,118,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:136,deployability,instal,installed,136,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:149,deployability,updat,updated,149,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:164,deployability,version,version,164,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:7,integrability,version,version,7,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:118,integrability,version,version,118,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:164,integrability,version,version,164,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:45,interoperability,incompatib,incompatibility,45,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:7,modifiability,version,version,7,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:118,modifiability,version,version,118,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:164,modifiability,version,version,164,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:0,safety,Updat,Update,0,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:70,safety,updat,update,70,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:149,safety,updat,updated,149,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:0,security,Updat,Update,0,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:70,security,updat,update,70,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/15:149,security,updat,updated,149,"Update version of spacy to cope with msgpack incompatibility; msgpack update broke spacy, so spacy pinned the msgpack version that gets installed. i updated to the version of spacy with the msgpack pin",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/15
https://github.com/allenai/scispacy/pull/16:322,deployability,fail,fails,322,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:484,deployability,fail,fails,484,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:553,energy efficiency,model,model,553,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:604,energy efficiency,model,model,604,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:322,reliability,fail,fails,322,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:484,reliability,fail,fails,484,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:38,safety,test,test,38,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:358,safety,detect,detection,358,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:368,safety,test,tests,368,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:450,safety,test,tests,450,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:358,security,detect,detection,358,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:553,security,model,model,553,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:604,security,model,model,604,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:626,security,token,tokenizer,626,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:38,testability,test,test,38,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:368,testability,test,tests,368,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/16:450,testability,test,tests,450,"Genia parser; Parsing scores on GENIA test: UAS: 0.8944619583117678, LAS: 0.8763939208582319. I think this parser is no longer as good at normal text. A more sophisticated method of training could likely fix this problem (e.g. intersperse examples of normal text with the GENIA text when training the parser). This parser fails some of the sentence boundary detection tests from spacy, some of which were easily fixed and some of which were not. The tests that the GENIA parser newly fails are marked as such with a comment. The main changes are: add a model folder with just the retrained parser, add a model folder with the tokenizer/splitting stuff and the parser, and add retrain_parser.py script to retrain the parser.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/16
https://github.com/allenai/scispacy/pull/17:210,availability,down,download,210,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:744,availability,sli,slightly,744,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:804,availability,state,state,804,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:934,availability,state,state,934,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:222,deployability,automat,automatically,222,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:380,deployability,modul,module,380,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:590,energy efficiency,model,model,590,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:596,energy efficiency,load,loading,596,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:607,energy efficiency,Load,Loading,607,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:619,energy efficiency,model,models,619,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:709,energy efficiency,load,load,709,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:768,energy efficiency,model,model,768,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:663,integrability,coupl,couple,663,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:804,integrability,state,state,804,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:934,integrability,state,state,934,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:486,interoperability,format,formatting,486,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:380,modifiability,modul,module,380,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:663,modifiability,coupl,couple,663,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:690,modifiability,paramet,parametrised,690,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:5,performance,cach,cache,5,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:73,performance,cach,cache,73,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:164,performance,cach,cache,164,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:576,performance,cach,caching,576,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:596,performance,load,loading,596,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:607,performance,Load,Loading,607,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:650,performance,time,time,650,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:709,performance,load,load,709,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:744,reliability,sli,slightly,744,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:13,safety,test,test,13,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:346,safety,test,tests,346,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:363,safety,test,tests,363,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:380,safety,modul,module,380,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:522,safety,test,test,522,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:703,safety,test,tests,703,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:760,safety,test,testing,760,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:971,safety,test,tests,971,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:322,security,modif,modification,322,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:590,security,model,model,590,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:619,security,model,models,619,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:768,security,model,model,768,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:923,security,modif,modify,923,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:13,testability,test,test,13,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:61,testability,simpl,simple,61,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:222,testability,automat,automatically,222,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:346,testability,test,tests,346,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:363,testability,test,tests,363,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:522,testability,test,test,522,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:663,testability,coupl,couple,663,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:703,testability,test,tests,703,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:760,testability,test,testing,760,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:971,testability,test,tests,971,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/17:61,usability,simpl,simple,61,"File cache + test speedups; - Adds `file_cache.py`, a really simple file cache which lets you do . ```. from SciSpaCy.file_cache import cached_path. # Looks in the cache for the dataset - if it's not there,. # download it automatically. dataset = dataset_loading_function(cached_path(""https://...."")). ```. - Removes path modification to run the tests by making `tests/` a python module. - Adds two scripts `scripts/pylint.sh` and `scripts/mypy.sh` which run the linters with some nice formatting options. - Speeds up the test suite by about 10x(360s -> 24s on my macbook) by caching spacy model loading. . Loading the models takes up quite a bit of time (like a couple of seconds) and the parametrised tests load them independently. Perhaps a slightly better testing model would be to have classes with state, but this also works. Lmk if you don't like it or something, it means you have to be a little bit careful not to modify the state of global spacy `nlp`'s in the tests.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/17
https://github.com/allenai/scispacy/pull/18:50,energy efficiency,model,model,50,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/18:216,integrability,sub,subset,216,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/18:348,interoperability,semant,semantic,348,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/18:476,interoperability,format,format,476,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/18:549,modifiability,reu,reuse,549,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/18:50,security,model,model,50,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/18:412,testability,plan,plan,412,"Med mentions; . This adds a script which trains a model on the entity mentions from the [MedMentions](https://github.com/chanzuckerberg/MedMentions) dataset (for entity linking). The F1 is around 60 ish if I use the subset of the data which is cleaner (typically used for Information Retrieval research) and constrained to a smaller number of UMLS semantic types. . I don't actually have any idea of the overall plan for SciSpacy so maybe this isn't super useful (the dataset format is used by some other biomedical NER datasets though, so we could reuse some of this code regardless). I mainly did this because I wanted to play around with the dataset, as it's quite new and looks quite good.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/18
https://github.com/allenai/scispacy/pull/19:611,integrability,Sub,Substance,611,"UMLS Semantic Type tree; Adds a UMLS Semantic Type tree. I'm going to use this to collapse the label space of the NER to see if it helps accuracy/F1. Depth vs num labels:. ```. 1: 3. 2: 7. 3: 27. 4: 67. 5: 91. 6: 110. 7: 127. ```. E.g for depth 3, this is the label space, which looks like a good trade off between granularity and not having a massive number of very similar labels:. ```. Behavior. Group Attribute. Group. Natural Phenomenon or Process. Injury or Poisoning. Physical Object. Manufactured Object. Occupation or Discipline. Organization. Finding. UnknownType. Human-caused Phenomenon or Process. Substance. Phenomenon or Process. Event. Activity. ILanguage. Occupational Activity. Entity. Intellectual Product. Organism. Daily or Recreational Activity. Conceptual Entity. Organism Attribute. Idea or Concept. Anatomical Structure. Machine Activity. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/19
https://github.com/allenai/scispacy/pull/19:645,integrability,Event,Event,645,"UMLS Semantic Type tree; Adds a UMLS Semantic Type tree. I'm going to use this to collapse the label space of the NER to see if it helps accuracy/F1. Depth vs num labels:. ```. 1: 3. 2: 7. 3: 27. 4: 67. 5: 91. 6: 110. 7: 127. ```. E.g for depth 3, this is the label space, which looks like a good trade off between granularity and not having a massive number of very similar labels:. ```. Behavior. Group Attribute. Group. Natural Phenomenon or Process. Injury or Poisoning. Physical Object. Manufactured Object. Occupation or Discipline. Organization. Finding. UnknownType. Human-caused Phenomenon or Process. Substance. Phenomenon or Process. Event. Activity. ILanguage. Occupational Activity. Entity. Intellectual Product. Organism. Daily or Recreational Activity. Conceptual Entity. Organism Attribute. Idea or Concept. Anatomical Structure. Machine Activity. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/19
https://github.com/allenai/scispacy/pull/19:5,interoperability,Semant,Semantic,5,"UMLS Semantic Type tree; Adds a UMLS Semantic Type tree. I'm going to use this to collapse the label space of the NER to see if it helps accuracy/F1. Depth vs num labels:. ```. 1: 3. 2: 7. 3: 27. 4: 67. 5: 91. 6: 110. 7: 127. ```. E.g for depth 3, this is the label space, which looks like a good trade off between granularity and not having a massive number of very similar labels:. ```. Behavior. Group Attribute. Group. Natural Phenomenon or Process. Injury or Poisoning. Physical Object. Manufactured Object. Occupation or Discipline. Organization. Finding. UnknownType. Human-caused Phenomenon or Process. Substance. Phenomenon or Process. Event. Activity. ILanguage. Occupational Activity. Entity. Intellectual Product. Organism. Daily or Recreational Activity. Conceptual Entity. Organism Attribute. Idea or Concept. Anatomical Structure. Machine Activity. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/19
https://github.com/allenai/scispacy/pull/19:37,interoperability,Semant,Semantic,37,"UMLS Semantic Type tree; Adds a UMLS Semantic Type tree. I'm going to use this to collapse the label space of the NER to see if it helps accuracy/F1. Depth vs num labels:. ```. 1: 3. 2: 7. 3: 27. 4: 67. 5: 91. 6: 110. 7: 127. ```. E.g for depth 3, this is the label space, which looks like a good trade off between granularity and not having a massive number of very similar labels:. ```. Behavior. Group Attribute. Group. Natural Phenomenon or Process. Injury or Poisoning. Physical Object. Manufactured Object. Occupation or Discipline. Organization. Finding. UnknownType. Human-caused Phenomenon or Process. Substance. Phenomenon or Process. Event. Activity. ILanguage. Occupational Activity. Entity. Intellectual Product. Organism. Daily or Recreational Activity. Conceptual Entity. Organism Attribute. Idea or Concept. Anatomical Structure. Machine Activity. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/19
https://github.com/allenai/scispacy/pull/19:131,usability,help,helps,131,"UMLS Semantic Type tree; Adds a UMLS Semantic Type tree. I'm going to use this to collapse the label space of the NER to see if it helps accuracy/F1. Depth vs num labels:. ```. 1: 3. 2: 7. 3: 27. 4: 67. 5: 91. 6: 110. 7: 127. ```. E.g for depth 3, this is the label space, which looks like a good trade off between granularity and not having a massive number of very similar labels:. ```. Behavior. Group Attribute. Group. Natural Phenomenon or Process. Injury or Poisoning. Physical Object. Manufactured Object. Occupation or Discipline. Organization. Finding. UnknownType. Human-caused Phenomenon or Process. Substance. Phenomenon or Process. Event. Activity. ILanguage. Occupational Activity. Entity. Intellectual Product. Organism. Daily or Recreational Activity. Conceptual Entity. Organism Attribute. Idea or Concept. Anatomical Structure. Machine Activity. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/19
https://github.com/allenai/scispacy/pull/19:389,usability,Behavi,Behavior,389,"UMLS Semantic Type tree; Adds a UMLS Semantic Type tree. I'm going to use this to collapse the label space of the NER to see if it helps accuracy/F1. Depth vs num labels:. ```. 1: 3. 2: 7. 3: 27. 4: 67. 5: 91. 6: 110. 7: 127. ```. E.g for depth 3, this is the label space, which looks like a good trade off between granularity and not having a massive number of very similar labels:. ```. Behavior. Group Attribute. Group. Natural Phenomenon or Process. Injury or Poisoning. Physical Object. Manufactured Object. Occupation or Discipline. Organization. Finding. UnknownType. Human-caused Phenomenon or Process. Substance. Phenomenon or Process. Event. Activity. ILanguage. Occupational Activity. Entity. Intellectual Product. Organism. Daily or Recreational Activity. Conceptual Entity. Organism Attribute. Idea or Concept. Anatomical Structure. Machine Activity. ```.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/19
https://github.com/allenai/scispacy/pull/20:227,energy efficiency,current,current,227,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:470,energy efficiency,model,models,470,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:71,integrability,abstract,abstract,71,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:71,modifiability,abstract,abstract,71,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:176,reliability,doe,doesn,176,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:498,safety,test,test,498,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:627,safety,test,test,627,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:470,security,model,models,470,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:498,testability,test,test,498,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:627,testability,test,test,627,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/20:197,usability,help,helped,197,Retrain tagger with parser; The results dropped a bit when I made each abstract its own doc (rather than just taking 10 sentences per doc). Training the tagger with the parser doesn't seem to have helped the parser either. The current results are:. UAS: 88.20111767220226. LAS: 83.52462519986702. Tag %: 93.92745820345706. compared to the results from en_core_web_sm on genia:. UAS: 38.79313230027779. LAS: 33.25077813849192. Tag %: 75.40096344573534. and the retrained models results on ontonotes test:. UAS: 48.23223139414712. LAS: 35.89068693502179. Tag %: 77.11257347126586. compared to en_core_web_sm results on ontonotes test:. UAS: 91.66278968907955. LAS: 89.78869815035314. Tag %: 97.40151035187591.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/20
https://github.com/allenai/scispacy/pull/22:112,deployability,version,version,112,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/22:186,deployability,version,version,186,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/22:112,integrability,version,version,112,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/22:186,integrability,version,version,186,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/22:112,modifiability,version,version,112,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/22:186,modifiability,version,version,186,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/22:61,reliability,doe,does,61,"add dump_to_spacy script; @danielkingai2 I think this script does the dumping to file in the right way for this version of spacy - I see what you mean about the differences between this version and later, that will be annoying to change. Edit: I tried converting the data and training a parser with `spacy train en -N train.json dev.json`, this seems to work nicely - 98.6 POS tag acc and 88.8 LAS after 3 epochs of training.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/22
https://github.com/allenai/scispacy/pull/23:153,availability,down,download,153,"add makefile shell to fill in; Add a Makefile shell to generate the various components. Eventually I want all of these commands to run without having to download any data, by using the `cached_path` function I added and storing all the data we need in an S3 bucket.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/23
https://github.com/allenai/scispacy/pull/23:76,integrability,compon,components,76,"add makefile shell to fill in; Add a Makefile shell to generate the various components. Eventually I want all of these commands to run without having to download any data, by using the `cached_path` function I added and storing all the data we need in an S3 bucket.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/23
https://github.com/allenai/scispacy/pull/23:88,integrability,Event,Eventually,88,"add makefile shell to fill in; Add a Makefile shell to generate the various components. Eventually I want all of these commands to run without having to download any data, by using the `cached_path` function I added and storing all the data we need in an S3 bucket.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/23
https://github.com/allenai/scispacy/pull/23:76,interoperability,compon,components,76,"add makefile shell to fill in; Add a Makefile shell to generate the various components. Eventually I want all of these commands to run without having to download any data, by using the `cached_path` function I added and storing all the data we need in an S3 bucket.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/23
https://github.com/allenai/scispacy/pull/23:76,modifiability,compon,components,76,"add makefile shell to fill in; Add a Makefile shell to generate the various components. Eventually I want all of these commands to run without having to download any data, by using the `cached_path` function I added and storing all the data we need in an S3 bucket.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/23
https://github.com/allenai/scispacy/pull/23:119,usability,command,commands,119,"add makefile shell to fill in; Add a Makefile shell to generate the various components. Eventually I want all of these commands to run without having to download any data, by using the `cached_path` function I added and storing all the data we need in an S3 bucket.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/23
https://github.com/allenai/scispacy/pull/24:121,performance,perform,performance,121,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:147,performance,improves perform,improves performance,147,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:99,reliability,doe,doesn,99,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:181,security,sign,significanly,181,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:15,testability,Simpl,Simply,15,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:15,usability,Simpl,Simply,15,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:121,usability,perform,performance,121,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/pull/24:156,usability,perform,performance,156,"Ontonotes mix; Simply mixing in some of the ontonoes training data (i used 0.01 as the percentage) doesn't really change performance on genia, and improves performance on ontonotes significanly. certainly fancier things could be done here, but i am going back to mainly working on the competition that i am participating in now. here are the results of the newly trained parser and tagger. Retrained genia evaluation. UAS: 89.38557819773715. LAS: 87.86570891266146. Tag %: 98.64842454394693. Retrained ontonotes evaluation. UAS: 71.47788282743629. LAS: 65.09388995102533. Tag %: 90.93788874450267",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/24
https://github.com/allenai/scispacy/issues/25:133,security,token,tokenized,133,General ideas; - explore training with gold preprocessing = True/False. - explore using a different parser metric or rejoining badly tokenized words in some way so the parser isn't hurt by the poor tokenization. - play around more with how to mix ontonotes data into training of the parser/tagger,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/25
https://github.com/allenai/scispacy/issues/25:198,security,token,tokenization,198,General ideas; - explore training with gold preprocessing = True/False. - explore using a different parser metric or rejoining badly tokenized words in some way so the parser isn't hurt by the poor tokenization. - play around more with how to mix ontonotes data into training of the parser/tagger,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/25
https://github.com/allenai/scispacy/issues/28:5,energy efficiency,model,models,5,Move models and data to s3/ai2-s2-scispacy; All script commands should work with remote data (using `cached_path`) and we shouldn't have models stored in the repo.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/28
https://github.com/allenai/scispacy/issues/28:137,energy efficiency,model,models,137,Move models and data to s3/ai2-s2-scispacy; All script commands should work with remote data (using `cached_path`) and we shouldn't have models stored in the repo.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/28
https://github.com/allenai/scispacy/issues/28:5,security,model,models,5,Move models and data to s3/ai2-s2-scispacy; All script commands should work with remote data (using `cached_path`) and we shouldn't have models stored in the repo.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/28
https://github.com/allenai/scispacy/issues/28:137,security,model,models,137,Move models and data to s3/ai2-s2-scispacy; All script commands should work with remote data (using `cached_path`) and we shouldn't have models stored in the repo.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/28
https://github.com/allenai/scispacy/issues/28:55,usability,command,commands,55,Move models and data to s3/ai2-s2-scispacy; All script commands should work with remote data (using `cached_path`) and we shouldn't have models stored in the repo.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/28
https://github.com/allenai/scispacy/issues/31:16,deployability,depend,dependencies,16,explicitly list dependencies in setup.py;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/31
https://github.com/allenai/scispacy/issues/31:16,integrability,depend,dependencies,16,explicitly list dependencies in setup.py;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/31
https://github.com/allenai/scispacy/issues/31:16,modifiability,depend,dependencies,16,explicitly list dependencies in setup.py;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/31
https://github.com/allenai/scispacy/issues/31:16,safety,depend,dependencies,16,explicitly list dependencies in setup.py;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/31
https://github.com/allenai/scispacy/issues/31:16,testability,depend,dependencies,16,explicitly list dependencies in setup.py;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/31
https://github.com/allenai/scispacy/issues/35:197,deployability,releas,released,197,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:277,deployability,releas,release,277,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:37,energy efficiency,model,models,37,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:72,energy efficiency,core,core,72,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:104,energy efficiency,core,core,104,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:206,energy efficiency,model,models,206,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:124,integrability,compon,components,124,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:46,interoperability,Format,Format,46,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:124,interoperability,compon,components,124,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:124,modifiability,compon,components,124,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:295,safety,detect,detector,295,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:37,security,model,models,37,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:206,security,model,models,206,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/issues/35:295,security,detect,detector,295,"Respect spacy naming conventions for models.; Format should be `[lang] [core/ent/dep] [genre] [size]`. 'core' if it has all components, 'ent' if it's only NER, 'dep' if it's syntax. Therefore, our released models should be:. `en_core_sci_sm`. `en_core_sci_lg`. possibly, if we release a mention detector separately:. `en_ent_sci_[sm/lg]`.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/35
https://github.com/allenai/scispacy/pull/37:39,integrability,pub,pubmed,39,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:46,integrability,abstract,abstracts,46,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:46,modifiability,abstract,abstracts,46,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:64,safety,test,test,64,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:190,safety,test,test,190,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:318,safety,test,test,318,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:6,security,token,tokenizer,6,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:24,security,Token,Tokenising,24,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:64,testability,test,test,64,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:190,testability,test,test,190,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/37:318,testability,test,test,318,"Genia tokenizer; . #### Tokenising 10k pubmed abstracts:. Speed test: genia_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 28.98577332496643, Std: 0.9618087746695202. Speed test: custom_tokenizer. iteration 0. iteration 1. iteration 2. Mean (3 runs) 104.88270195325215, Std: 0.5736707635762457. Speed test: spacy. iteration 0. iteration 1. iteration 2. Mean (3 runs) 64.94790593783061, Std: 0.6912257483692967.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/37
https://github.com/allenai/scispacy/pull/38:12,energy efficiency,model,model,12,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:40,energy efficiency,model,model,40,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:220,energy efficiency,model,model,220,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:368,energy efficiency,model,models,368,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:246,integrability,pub,pubmed,246,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:12,security,model,model,12,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:40,security,model,model,40,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:220,security,model,model,220,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:368,security,model,models,368,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:0,usability,Custom,Custom,0,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/38:28,usability,custom,custom,28,Custom init model; . Adds a custom init model script which creates a vocab and optionally vectors. It also adds a bit of functionality:. - Allows not adding all the words in the vectors file to the vocab (this makes the model massive because the pubmed vectors are very large). - Allows overriding items in the `meta.json` file so that we can have correct info in our models. - Makes providing the vectors actually optional.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/38
https://github.com/allenai/scispacy/pull/39:0,deployability,Pipelin,Pipeline,0,Pipeline tagger parser;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/39
https://github.com/allenai/scispacy/pull/39:0,integrability,Pipelin,Pipeline,0,Pipeline tagger parser;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/39
https://github.com/allenai/scispacy/pull/41:0,deployability,Pipelin,Pipeline,0,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:237,deployability,build,build,237,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:251,energy efficiency,model,model,251,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:0,integrability,Pipelin,Pipeline,0,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:203,integrability,coupl,couple,203,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:203,modifiability,coupl,couple,203,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:251,security,model,model,251,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:203,testability,coupl,couple,203,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/41:222,usability,command,commands,222,Pipeline improvements; . - Cleans up some argparsing. - Makes it possible to read the med mentions data from a tar file which is necessary to be able to do things seamlessly with `cached_path`. - adds a couple of makefile commands which build the NER model on top of the parser,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/41
https://github.com/allenai/scispacy/pull/43:0,deployability,Build,Build,0,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:65,deployability,pipelin,pipeline,65,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:242,deployability,pipelin,pipeline,242,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:6,energy efficiency,model,models,6,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:178,energy efficiency,model,model,178,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:392,energy efficiency,model,model,392,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:65,integrability,pipelin,pipeline,65,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:242,integrability,pipelin,pipeline,242,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:354,safety,input,input,354,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:6,security,model,models,6,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:178,security,model,model,178,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:341,security,modif,modified,341,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:392,security,model,model,392,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/43:354,usability,input,input,354,"Build models; Fixes some stuff from actually trying to train the pipeline:. - Be more careful with the ` with nlp.disable_pipes` because this actually removes the pipes from the model when they are under this scope, meaning some parts of the pipeline don't get serialized. - Fixes embarrassing bug I introduced in the `PerClassScorer` which modified the input. - Adds more words to the large model's vocab, in correlation with Spacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/43
https://github.com/allenai/scispacy/pull/45:21,security,token,tokenizer,21,add flag to evaluate tokenizer;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/45
https://github.com/allenai/scispacy/pull/46:4,deployability,version,version,4,add version stuff;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/46
https://github.com/allenai/scispacy/pull/46:4,integrability,version,version,4,add version stuff;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/46
https://github.com/allenai/scispacy/pull/46:4,modifiability,version,version,4,add version stuff;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/46
https://github.com/allenai/scispacy/pull/47:47,deployability,pipelin,pipeline,47,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:63,deployability,modul,modular,63,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:47,integrability,pipelin,pipeline,47,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:63,integrability,modular,modular,63,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:63,modifiability,modul,modular,63,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:127,modifiability,pac,packaging,127,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:186,modifiability,pac,package,186,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:63,safety,modul,modular,63,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/47:63,testability,modula,modular,63,"Remove makefile; - Remove makefile. - Make the pipeline really modular, so you can run it all at once or in pieces. - Fix some packaging things (spacy adds the lang to the name when you package it, so it shouldn't be in the name already).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/47
https://github.com/allenai/scispacy/pull/50:4,energy efficiency,model,models,4,Ner models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/50
https://github.com/allenai/scispacy/pull/50:4,security,model,models,4,Ner models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/50
https://github.com/allenai/scispacy/pull/51:19,interoperability,compatib,compatible,19,make setup.py pypi compatible; https://pypi.org/project/scispacy/0.0.0.post0/ 🍾 . Fixes #31,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/51
https://github.com/allenai/scispacy/pull/52:36,energy efficiency,model,models,36,couple of training tweaks for final models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/52
https://github.com/allenai/scispacy/pull/52:0,integrability,coupl,couple,0,couple of training tweaks for final models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/52
https://github.com/allenai/scispacy/pull/52:0,modifiability,coupl,couple,0,couple of training tweaks for final models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/52
https://github.com/allenai/scispacy/pull/52:36,security,model,models,36,couple of training tweaks for final models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/52
https://github.com/allenai/scispacy/pull/52:0,testability,coupl,couple,0,couple of training tweaks for final models;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/52
https://github.com/allenai/scispacy/issues/53:22,integrability,pub,public,22,Investigate making CI public;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/53
https://github.com/allenai/scispacy/pull/54:4,deployability,pipelin,pipeline,4,Ner pipeline;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/54
https://github.com/allenai/scispacy/pull/54:4,integrability,pipelin,pipeline,4,Ner pipeline;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/54
https://github.com/allenai/scispacy/pull/55:16,deployability,releas,release,16,add interactive release script;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/55
https://github.com/allenai/scispacy/pull/55:4,usability,interact,interactive,4,add interactive release script;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/55
https://github.com/allenai/scispacy/pull/56:0,deployability,Upgrad,Upgrade,0,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/pull/56:56,deployability,upgrad,upgrade,56,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/pull/56:74,deployability,upgrad,upgrading,74,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/pull/56:0,modifiability,Upgrad,Upgrade,0,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/pull/56:56,modifiability,upgrad,upgrade,56,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/pull/56:74,modifiability,upgrad,upgrading,74,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/pull/56:124,modifiability,pac,package,124,"Upgrade spacy to 2.1.0; Not sure what the proper way to upgrade is, since upgrading to 2.1 requires using the spacy-nightly package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/56
https://github.com/allenai/scispacy/issues/57:43,energy efficiency,model,models,43,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:143,energy efficiency,model,models,143,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:185,energy efficiency,load,load,185,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:199,energy efficiency,model,model,199,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:0,modifiability,Refact,Refactor,0,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:0,performance,Refactor,Refactor,0,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:33,performance,cach,cache,33,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:185,performance,load,load,185,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:9,safety,test,tests,9,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:89,safety,test,test,89,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:227,safety,test,tests,227,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:43,security,model,models,43,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:143,security,model,models,143,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:199,security,model,model,199,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:9,testability,test,tests,9,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:89,testability,test,test,89,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/issues/57:227,testability,test,tests,227,"Refactor tests to not use global cache for models; We should move away from a functional test framework because it makes the ""god-object-spacy-models"" dangerous. Instead we should just load a single model for groups of related tests and re-use them.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/57
https://github.com/allenai/scispacy/pull/58:39,deployability,pipelin,pipeline,39,"Add sentence segmentation pipe and fix pipeline order; @DeNeutoy are you opposed to adding the sentence segmentation pipe back in? I think its useful for real body text, and as a place for other potential ad hoc fixes",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/58
https://github.com/allenai/scispacy/pull/58:39,integrability,pipelin,pipeline,39,"Add sentence segmentation pipe and fix pipeline order; @DeNeutoy are you opposed to adding the sentence segmentation pipe back in? I think its useful for real body text, and as a place for other potential ad hoc fixes",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/58
https://github.com/allenai/scispacy/pull/59:58,deployability,instal,install,58,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:178,deployability,instal,install,178,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:390,deployability,pipelin,pipeline,390,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:464,deployability,pipelin,pipeline,464,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:501,deployability,build,build,501,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:201,energy efficiency,load,load,201,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:227,energy efficiency,model,model,227,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:34,integrability,discover,discovered,34,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:390,integrability,pipelin,pipeline,390,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:464,integrability,pipelin,pipeline,464,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:34,interoperability,discover,discovered,34,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:5,modifiability,pac,packages,5,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:201,performance,load,load,201,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:227,security,model,model,227,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/pull/59:34,usability,discov,discovered,34,"Base packages on spacy-nightly; I discovered that the pip install was broken because it was looking for spacy >= 2.1.0a6. If we are basing off of spacy-nightly, in order for pip install to work (spacy.load with the path to the model directory would still work), the metas need to have a parent_package key set to spacy-nightly. Also, added check to remove directory if it already exists in pipeline.sh, because it seemed to not be recreating everything if you run pipeline.sh again after a successful build",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/59
https://github.com/allenai/scispacy/issues/60:51,deployability,releas,release,51,remove `parent_package` from model meta once spacy release 2.1;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/60
https://github.com/allenai/scispacy/issues/60:29,energy efficiency,model,model,29,remove `parent_package` from model meta once spacy release 2.1;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/60
https://github.com/allenai/scispacy/issues/60:29,security,model,model,29,remove `parent_package` from model meta once spacy release 2.1;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/60
https://github.com/allenai/scispacy/issues/63:4,deployability,instal,install,4,Fix install instructions in readme once ready;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/63
https://github.com/allenai/scispacy/pull/64:55,availability,state,state,55,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:0,deployability,Updat,Update,0,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:15,deployability,Updat,Update,15,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:82,deployability,log,logos,82,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:55,integrability,state,state,55,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:0,safety,Updat,Update,0,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:15,safety,Updat,Update,15,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:82,safety,log,logos,82,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:0,security,Updat,Update,0,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:15,security,Updat,Update,15,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:82,security,log,logos,82,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/pull/64:82,testability,log,logos,82,"Update readme; Update the readme to reflect the future state of the world, add in logos to the readme and the github site (look at the readme directly in my branch)",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/64
https://github.com/allenai/scispacy/issues/65:50,deployability,depend,dependency,50,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:133,deployability,depend,dependency,133,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:182,deployability,version,version,182,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:298,energy efficiency,model,model,298,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:50,integrability,depend,dependency,50,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:133,integrability,depend,dependency,133,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:182,integrability,version,version,182,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:50,modifiability,depend,dependency,50,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:133,modifiability,depend,dependency,133,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:182,modifiability,version,version,182,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:50,safety,depend,dependency,50,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:133,safety,depend,dependency,133,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:298,security,model,model,298,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:50,testability,depend,dependency,50,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/65:133,testability,depend,dependency,133,Parse a large quantity of text with a very strong dependency parser for retraining; We have the ability to train an extremely strong dependency parser (via allennlp + the scientific version of elmo we have). We could generate a larger dataset of biomedical text which we can use to train the spacy model with.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/65
https://github.com/allenai/scispacy/issues/66:122,safety,Detect,Detection,122,Evaluate how difficult feature parity with MetamapLite is; - [ ] Term normalisation. - [ ] Entity Linking. - [ ] Negation Detection. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6080672/,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/66
https://github.com/allenai/scispacy/issues/66:122,security,Detect,Detection,122,Evaluate how difficult feature parity with MetamapLite is; - [ ] Term normalisation. - [ ] Entity Linking. - [ ] Negation Detection. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6080672/,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/66
https://github.com/allenai/scispacy/pull/67:52,deployability,releas,release,52,"Export umls json; Read the META directory of a UMLS release and output a json file that with a list of concepts. . Each concept has a canonical name, definition, list of types, and list of aliases. . Running this script on a UMLS_2017_AA_FULL gives the following statistics: . ```. Number of concepts: 3334533. Number of concepts without canonical name (one of the aliases will be used instead): 10803. Number of concepts with no aliases: 1820697. Number of concepts with 1 aliase: 663401. Number of concepts with > 1 aliase: 850435. Number of concepts with no type: 0. Number of concepts with 1 type: 3053977. Number of concepts with > 1 type: 280556. Number of concepts with no definition: 3139611. Number of concepts with definition from preferred sources: 149029. Number of concepts with definition from other sources: 45893. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/67
https://github.com/allenai/scispacy/pull/67:741,usability,prefer,preferred,741,"Export umls json; Read the META directory of a UMLS release and output a json file that with a list of concepts. . Each concept has a canonical name, definition, list of types, and list of aliases. . Running this script on a UMLS_2017_AA_FULL gives the following statistics: . ```. Number of concepts: 3334533. Number of concepts without canonical name (one of the aliases will be used instead): 10803. Number of concepts with no aliases: 1820697. Number of concepts with 1 aliase: 663401. Number of concepts with > 1 aliase: 850435. Number of concepts with no type: 0. Number of concepts with 1 type: 3053977. Number of concepts with > 1 type: 280556. Number of concepts with no definition: 3139611. Number of concepts with definition from preferred sources: 149029. Number of concepts with definition from other sources: 45893. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/67
https://github.com/allenai/scispacy/issues/68:6,availability,down,download,6,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:37,availability,down,download,37,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:90,availability,down,download,90,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:112,availability,avail,available,112,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:178,deployability,instal,install,178,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:186,deployability,fail,fails,186,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:223,deployability,build,build,223,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:0,energy efficiency,Model,Model,0,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:58,energy efficiency,model,models,58,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:122,energy efficiency,model,models,122,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:166,energy efficiency,current,current,166,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:112,reliability,availab,available,112,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:186,reliability,fail,fails,186,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:112,safety,avail,available,112,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:0,security,Model,Model,0,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:58,security,model,models,58,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:112,security,availab,available,112,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/issues/68:122,security,model,models,122,"Model download URLs; Hi, Where can I download the trained models? I am unable to find the download URLs for the available models mentioned in this repo. Moreover the current pip install fails. We have to clone the repo and build from the setup.py files",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/68
https://github.com/allenai/scispacy/pull/69:0,deployability,Roll,Roll,0,Roll back;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/69
https://github.com/allenai/scispacy/pull/70:0,deployability,Releas,Release,0,Release v0.1.0;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/70
https://github.com/allenai/scispacy/pull/71:4,energy efficiency,model,model,4,add model urls and performance specs;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/71
https://github.com/allenai/scispacy/pull/71:19,performance,perform,performance,19,add model urls and performance specs;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/71
https://github.com/allenai/scispacy/pull/71:4,security,model,model,4,add model urls and performance specs;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/71
https://github.com/allenai/scispacy/pull/71:19,usability,perform,performance,19,add model urls and performance specs;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/71
https://github.com/allenai/scispacy/pull/72:107,deployability,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:17,energy efficiency,model,model,17,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:107,integrability,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:107,interoperability,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:107,modifiability,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:88,performance,perform,performance,88,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:163,performance,perform,performance,163,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:107,reliability,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:17,security,model,model,17,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:107,security,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:107,testability,integr,integrating,107,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:88,usability,perform,performance,88,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/pull/72:163,usability,perform,performance,163,baseline linking model; The goal is to iterate on this baseline until reaching a decent performance before integrating it with spacy. . This one has the following performance: . - MedMentions entities not in UMLS: 0. - MedMentions entities found in UMLS: 71062. - Correct linking: 30.19%. - Wrong linking: 3.93%. - No linking: 65.88%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/72
https://github.com/allenai/scispacy/issues/73:36,deployability,version,version,36,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:99,deployability,version,version,99,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:177,deployability,version,versions,177,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:36,integrability,version,version,36,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:99,integrability,version,version,99,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:177,integrability,version,versions,177,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:36,modifiability,version,version,36,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:99,modifiability,version,version,99,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:177,modifiability,version,versions,177,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:0,usability,Support,Support,0,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/issues/73:60,usability,support,support,60,Support for spacy-nightly (2.1.0a*) version; Looks like the support has changed from spacy-nightly version to spacy 2.0.8. Is it possible to use it with spacy-nightly (2.1.0a*) versions?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/73
https://github.com/allenai/scispacy/pull/74:0,deployability,Updat,Update,0,Update README.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/74
https://github.com/allenai/scispacy/pull/74:0,safety,Updat,Update,0,Update README.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/74
https://github.com/allenai/scispacy/pull/74:0,security,Updat,Update,0,Update README.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/74
https://github.com/allenai/scispacy/pull/75:27,modifiability,pac,packages,27,remove nightly from parent packages;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/75
https://github.com/allenai/scispacy/pull/76:67,deployability,releas,releases,67,add dockerfile for pip; I think this will be useful to test future releases before we release them.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/76
https://github.com/allenai/scispacy/pull/76:86,deployability,releas,release,86,add dockerfile for pip; I think this will be useful to test future releases before we release them.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/76
https://github.com/allenai/scispacy/pull/76:55,safety,test,test,55,add dockerfile for pip; I think this will be useful to test future releases before we release them.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/76
https://github.com/allenai/scispacy/pull/76:55,testability,test,test,55,add dockerfile for pip; I think this will be useful to test future releases before we release them.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/76
https://github.com/allenai/scispacy/issues/77:35,deployability,depend,dependencies,35,Run evaluation again with stanford dependencies to make results comparable ; https://twitter.com/d_q_nguyen/status/1098821054414258177.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/77
https://github.com/allenai/scispacy/issues/77:35,integrability,depend,dependencies,35,Run evaluation again with stanford dependencies to make results comparable ; https://twitter.com/d_q_nguyen/status/1098821054414258177.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/77
https://github.com/allenai/scispacy/issues/77:35,modifiability,depend,dependencies,35,Run evaluation again with stanford dependencies to make results comparable ; https://twitter.com/d_q_nguyen/status/1098821054414258177.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/77
https://github.com/allenai/scispacy/issues/77:35,safety,depend,dependencies,35,Run evaluation again with stanford dependencies to make results comparable ; https://twitter.com/d_q_nguyen/status/1098821054414258177.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/77
https://github.com/allenai/scispacy/issues/77:35,testability,depend,dependencies,35,Run evaluation again with stanford dependencies to make results comparable ; https://twitter.com/d_q_nguyen/status/1098821054414258177.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/77
https://github.com/allenai/scispacy/issues/77:108,usability,statu,status,108,Run evaluation again with stanford dependencies to make results comparable ; https://twitter.com/d_q_nguyen/status/1098821054414258177.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/77
https://github.com/allenai/scispacy/issues/78:106,availability,error,error,106,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:3,deployability,modul,module,3,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:182,deployability,modul,module,182,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:276,deployability,modul,module,276,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:364,deployability,Version,Versions,364,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:529,deployability,Version,Versions,529,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:705,deployability,Version,Versions,705,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:880,deployability,Version,Versions,880,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1063,deployability,Version,Versions,1063,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1145,deployability,modul,module,1145,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1235,deployability,Modul,ModuleNotFoundError,1235,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1259,deployability,modul,module,1259,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:297,energy efficiency,load,load,297,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:437,energy efficiency,load,load,437,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:364,integrability,Version,Versions,364,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:529,integrability,Version,Versions,529,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:705,integrability,Version,Versions,705,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:880,integrability,Version,Versions,880,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1063,integrability,Version,Versions,1063,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:3,modifiability,modul,module,3,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:74,modifiability,pac,package,74,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:182,modifiability,modul,module,182,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:276,modifiability,modul,module,276,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:364,modifiability,Version,Versions,364,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:396,modifiability,pac,packages,396,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:529,modifiability,Version,Versions,529,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:561,modifiability,pac,packages,561,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:705,modifiability,Version,Versions,705,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:737,modifiability,pac,packages,737,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:880,modifiability,Version,Versions,880,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1003,modifiability,pac,package,1003,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1063,modifiability,Version,Versions,1063,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1095,modifiability,pac,packages,1095,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1145,modifiability,modul,module,1145,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1235,modifiability,Modul,ModuleNotFoundError,1235,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1259,modifiability,modul,module,1259,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1330,modifiability,pac,package,1330,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:106,performance,error,error,106,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:297,performance,load,load,297,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:437,performance,load,load,437,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:3,safety,modul,module,3,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:106,safety,error,error,106,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:182,safety,modul,module,182,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:276,safety,modul,module,276,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1145,safety,modul,module,1145,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1235,safety,Modul,ModuleNotFoundError,1235,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:1259,safety,modul,module,1259,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:114,testability,Trace,Traceback,114,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:106,usability,error,error,106,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/78:215,usability,User,Users,215,"No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package; I am getting following error:. Traceback (most recent call last):. File ""scispacy.py"", line 2, in <module>. import scispacy. File ""/Users/shai26/office/spacy/scispacy/scispacy.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. ModuleNotFoundError: No module named 'scispacy.custom_sentence_segmenter'; 'scispacy' is not a package",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/78
https://github.com/allenai/scispacy/issues/79:60,usability,indicat,indication,60,"How to know what type of entity is extracted (e.g drug name,indication,treatment)using scispacy?;",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/79
https://github.com/allenai/scispacy/issues/81:41,availability,avail,available,41,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:0,energy efficiency,GPU,GPU,0,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:29,energy efficiency,GPU,GPU,29,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:0,performance,GPU,GPU,0,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:29,performance,GPU,GPU,29,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:41,reliability,availab,available,41,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:41,safety,avail,available,41,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:41,security,availab,available,41,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:4,usability,Support,Support,4,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/81:33,usability,support,support,33,GPU Support for scispacy; Is GPU support available for scispacy?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/81
https://github.com/allenai/scispacy/issues/82:124,availability,error,error,124,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:369,availability,error,error,369,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:690,availability,Error,Error,690,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:277,deployability,pipelin,pipeline,277,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:546,deployability,modul,module,546,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:832,deployability,pipelin,pipeline,832,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:84,energy efficiency,model,models,84,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:184,energy efficiency,load,load,184,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:220,energy efficiency,load,load,220,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:802,energy efficiency,model,model,802,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:277,integrability,pipelin,pipeline,277,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:832,integrability,pipelin,pipeline,832,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:546,modifiability,modul,module,546,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:124,performance,error,error,124,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:184,performance,load,load,184,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:220,performance,load,load,220,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:369,performance,error,error,369,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:690,performance,Error,Error,690,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:124,safety,error,error,124,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:369,safety,error,error,369,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:519,safety,input,input-,519,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:546,safety,modul,module,546,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:690,safety,Error,Error,690,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:84,security,model,models,84,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:592,security,token,tokens,592,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:641,security,token,tokens,641,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:802,security,model,model,802,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:475,testability,Trace,Traceback,475,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:124,usability,error,error,124,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:144,usability,help,help,144,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:369,usability,error,error,369,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:519,usability,input,input-,519,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/82:690,usability,Error,Error,690,"Replace NER; Hi, . I'm trying to add one of your pre-trained NER to one of the main models but unfortunately, I run into an error. Can somebody help? This is what I did: . nlp = spacy.load(""en_core_sci_sm""). ner = spacy.load(""en_ner_bionlp13cg_md""). nlp.replace_pipe('ner',ner.pipeline[0][1]). Then run on some text:. doc = nlp(text). When I ask for entities I get the error:. doc.ents. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-30-2631206314ab> in <module>(). ----> 1 doc.ents. doc.pyx in spacy.tokens.doc.Doc.ents.__get__(). span.pyx in spacy.tokens.span.Span.__cinit__(). ValueError: [E084] Error assigning label ID 7634832301877222523 to span: not in StringStore. If I try to just add a new NER to the model with:. nlp.add_pipe(ner.pipeline[0][1], 'new_ner'). the kernel crashes... Thank you!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/82
https://github.com/allenai/scispacy/issues/83:59,energy efficiency,model,models,59,Embedding; Can I know what embeddings you use to train the models? Is it clinic data related embeddings?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/83
https://github.com/allenai/scispacy/issues/83:59,security,model,models,59,Embedding; Can I know what embeddings you use to train the models? Is it clinic data related embeddings?,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/83
https://github.com/allenai/scispacy/issues/84:80,deployability,modul,modules,80,"Span.vector usage; Hi,. I am trying to use en_ner_craft_md and en_ner_jnlpba_md modules. I found Spacy's Span object has Span.vector as a vector representation its text,. is it possible to use these representations directly for some gene name normalization task (e.g. ""Basic Helix-Loop-Helix Transcription Factor Scleraxis"" is similar to ""SCX"" gene)? Thanks! Shunfu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/84
https://github.com/allenai/scispacy/issues/84:80,modifiability,modul,modules,80,"Span.vector usage; Hi,. I am trying to use en_ner_craft_md and en_ner_jnlpba_md modules. I found Spacy's Span object has Span.vector as a vector representation its text,. is it possible to use these representations directly for some gene name normalization task (e.g. ""Basic Helix-Loop-Helix Transcription Factor Scleraxis"" is similar to ""SCX"" gene)? Thanks! Shunfu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/84
https://github.com/allenai/scispacy/issues/84:80,safety,modul,modules,80,"Span.vector usage; Hi,. I am trying to use en_ner_craft_md and en_ner_jnlpba_md modules. I found Spacy's Span object has Span.vector as a vector representation its text,. is it possible to use these representations directly for some gene name normalization task (e.g. ""Basic Helix-Loop-Helix Transcription Factor Scleraxis"" is similar to ""SCX"" gene)? Thanks! Shunfu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/84
https://github.com/allenai/scispacy/issues/85:7,availability,error,error,7,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:61,availability,avail,available,61,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:111,availability,error,error,111,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:256,deployability,modul,module,256,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:1365,deployability,modul,module,1365,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:277,energy efficiency,load,load,277,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:380,energy efficiency,load,load,380,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:256,modifiability,modul,module,256,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:339,modifiability,pac,packages,339,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:467,modifiability,pac,packages,467,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:606,modifiability,pac,packages,606,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:835,modifiability,pac,package,835,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:1315,modifiability,pac,packages,1315,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:1365,modifiability,modul,module,1365,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:1493,modifiability,pac,packages,1493,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:7,performance,error,error,7,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:111,performance,error,error,111,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:277,performance,load,load,277,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:380,performance,load,load,380,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:61,reliability,availab,available,61,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:7,safety,error,error,7,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:61,safety,avail,available,61,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:111,safety,error,error,111,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:256,safety,modul,module,256,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:1365,safety,modul,module,1365,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:61,security,availab,available,61,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:1565,security,Token,Token,1565,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:191,testability,Trace,Traceback,191,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:7,usability,error,error,7,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:111,usability,error,error,111,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/issues/85:129,usability,help,help,129,"Syntax error(python 3.5); When I am running the example code available in the scispacy site, I am getting this error.. Could you help me solve the problem? . (env) vk@vk:~$ python test1.py . Traceback (most recent call last):. File ""test1.py"", line 5, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/vk/env/lib/python3.5/site-packages/spacy/__init__.py"", line 21, in load. return util.load_model(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 114, in load_model. return load_model_from_package(name, **overrides). File ""/home/vk/env/lib/python3.5/site-packages/spacy/util.py"", line 134, in load_model_from_package. cls = importlib.import_module(name). File ""/home/vk/env/lib/python3.5/importlib/__init__.py"", line 126, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import. File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module. File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed. File ""/home/vk/env/lib/python3.5/site-packages/en_core_sci_sm/__init__.py"", line 7, in <module>. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. File ""/home/vk/env/lib/python3.5/site-packages/scispacy/custom_sentence_segmenter.py"", line 15. prev_token_1: Token = None. ^. SyntaxError: invalid syntax",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/85
https://github.com/allenai/scispacy/pull/86:21,deployability,version,version,21,Bump required python version to 3.6; Inline type hinting with mypy requires python 3.6,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/86
https://github.com/allenai/scispacy/pull/86:21,integrability,version,version,21,Bump required python version to 3.6; Inline type hinting with mypy requires python 3.6,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/86
https://github.com/allenai/scispacy/pull/86:21,modifiability,version,version,21,Bump required python version to 3.6; Inline type hinting with mypy requires python 3.6,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/86
https://github.com/allenai/scispacy/pull/86:49,usability,hint,hinting,49,Bump required python version to 3.6; Inline type hinting with mypy requires python 3.6,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/86
https://github.com/allenai/scispacy/pull/87:8,deployability,version,version,8,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/87:59,deployability,version,version,59,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/87:8,integrability,version,version,8,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/87:59,integrability,version,version,59,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/87:8,modifiability,version,version,8,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/87:59,modifiability,version,version,59,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/87:28,usability,support,support,28,Bump up version and provide support for spaCy 2.1; Bump up version in [requirements file](https://github.com/allenai/scispacy/blob/master/requirements.in),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/87
https://github.com/allenai/scispacy/pull/88:485,availability,slo,slowest,485,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1089,deployability,releas,release,1089,"It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1467,deployability,log,log,1467," as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMen",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:2322,deployability,fail,failed,2322,orizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for ,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:2648,deployability,fail,failed,2648,0 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:2976,deployability,fail,failed,2976,2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%. ```,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:3306,deployability,fail,failed,3306,2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%. ```,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:3638,deployability,fail,failed,3638,2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%. ```,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:409,energy efficiency,predict,prediction,409,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:438,energy efficiency,load,loading,438,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:594,energy efficiency,load,load,594,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1478,energy efficiency,Load,Loading,1478,"he slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entitie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1674,energy efficiency,Load,Loading,1674," to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Gen",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1916,energy efficiency,Load,Loading,1916,"2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:438,performance,load,loading,438,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:456,performance,memor,memory,456,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:594,performance,load,load,594,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:611,performance,disk,disk,611,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:795,performance,perform,performance,795,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1478,performance,Load,Loading,1478,"he slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entitie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1674,performance,Load,Loading,1674," to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Gen",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1916,performance,Load,Loading,1916,"2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:485,reliability,slo,slowest,485,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:2322,reliability,fail,failed,2322,orizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for ,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:2648,reliability,fail,failed,2648,0 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:2976,reliability,fail,failed,2976,2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%. ```,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:3306,reliability,fail,failed,3306,2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%. ```,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:3638,reliability,fail,failed,3638,2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 2. Gold concept in candidates: 63.45%. Gold concept not in candidates: 34.05%. Candidate generation failed: 2.50%. for k = 10. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.654996 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 10. Gold concept in candidates: 73.53%. Gold concept not in candidates: 23.97%. Candidate generation failed: 2.50%. for k = 100. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 31.947052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 100. Gold concept in candidates: 81.68%. Gold concept not in candidates: 15.82%. Candidate generation failed: 2.50%. for k = 1000. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 60.497052 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1000. Gold concept in candidates: 85.40%. Gold concept not in candidates: 12.10%. Candidate generation failed: 2.50%. ```,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:182,safety,hot,hot,182,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:409,safety,predict,prediction,409,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1467,safety,log,log,1467," as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMen",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1467,security,log,log,1467," as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMen",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1467,testability,log,log,1467," as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 70306. K: 1. Gold concept in candidates: 54.92%. Gold concept not in candidates: 42.58%. Candidate generation failed: 2.50%. for k = 2. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 23.073926 seconds. MedMen",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:456,usability,memor,memory,456,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:584,usability,prefer,prefer,584,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:795,usability,perform,performance,795,"Entity linking candidate generation based on char-n-gram and approximate nearest neighbors ; It works as follows: . - map canonical names and aliases of entities in UMLS to sparse 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMent",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/88:1175,usability,command,command,1175," 1-hot encoding vectors using tfidf weighted char-3gram and char-4gram. - use `nmslib` to index all of UMLS. - given a query, use nmslib to search for `k` approximate nearest neighbors. Notes: . - results are assuming gold NER. - prediction is very fast, but loading things in memory is not as fast. - the slowest part is vectorizing the KB (6 minutes), and the vectorized KB is more than 4GB (in case we prefer to load it from the disk). It will be great to find a way around this. - potential ways to speed things up: use char4gram only or don't use aliases. I will try both and see which one results it a smaller performance drop. Data: . - evaluation data: `s3://ai2-s2-scispacy/data/med_mentions.tar.gz`. - nmslib ann index: `s3://ai2-s2-scispacy/data/nmslib_index_char34gram_withaliases.bin`. - sklearn tfidf char34 gram vectorizer: `s3://ai2-s2-scispacy/data/tfidf_char34gram_vectorizer.joblib`. - umls release: `s3://ai2-s2-scispacy/data/umls_2017_aa_cat0129.json`. Running the following command. ```python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --tfidf_vectorizer_path data/tfidfvec_char34gram_vectorizer.joblib --ann_index_path data/nmslib_index_char34gram_withaliases.bin```. Prints the following log:. ```. Loading umls concepts from data/umls_2017_aa_cat0129.json. Number of umls concepts: 2783846. Collecting aliases ... . Processed 1000000 or 2783846 concepts. Processed 2000000 or 2783846 concepts. Loading tfidf vectorizer from data/tfidfvec_char34gram_vectorizer.joblib. Vectorizing aliases ... . Vectorizing aliases took 329.725663 seconds. Deleting 4289/6336776 aliases because their tfidf is empty. ['MP' 'SL' 'SL' ... 'Ha' '3Y' '2Y']. Loading ann index from data/nmslib_index_char34gram_withaliases.bin. Reading MedMentions ... . for k = 1. Generating candidates for 70306 mentions. Number of empty vectors: 1755. Finding neighbors took 25.768434 seconds. MedMentions entities not in UMLS: 756. Med",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/88
https://github.com/allenai/scispacy/pull/89:0,deployability,upgrad,upgrade,0,upgrade to stretch; @ibeltagy this should fix the CI for your PR.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/89
https://github.com/allenai/scispacy/pull/89:0,modifiability,upgrad,upgrade,0,upgrade to stretch; @ibeltagy this should fix the CI for your PR.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/89
https://github.com/allenai/scispacy/pull/90:3,deployability,upgrad,upgrade,3,21 upgrade; Upgrade master to spacy 2.1,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/90
https://github.com/allenai/scispacy/pull/90:12,deployability,Upgrad,Upgrade,12,21 upgrade; Upgrade master to spacy 2.1,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/90
https://github.com/allenai/scispacy/pull/90:3,modifiability,upgrad,upgrade,3,21 upgrade; Upgrade master to spacy 2.1,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/90
https://github.com/allenai/scispacy/pull/90:12,modifiability,Upgrad,Upgrade,12,21 upgrade; Upgrade master to spacy 2.1,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/90
https://github.com/allenai/scispacy/pull/91:0,deployability,Releas,Release,0,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/pull/91:186,energy efficiency,model,models,186,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/pull/91:16,performance,Perform,Performance,16,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/pull/91:33,performance,perform,performance,33,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/pull/91:186,security,model,models,186,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/pull/91:16,usability,Perform,Performance,16,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/pull/91:33,usability,perform,performance,33,"Release v0.2.0; Performance (the performance bump ended up being the same between starting with base and starting with full md, so I went with starting with base for the specialized ner models). en_core_sci_sm:. - genia UAS: 89.47. - genia LAS: 87.61. - onto UAS: 85.48. - medmentions F1 overall: 0.676. en_core_sci_md:. - genia UAS: 89.94. - genia LAS: 88.08. - onto UAS: 86.70. - medmentions F1 overall: 0.693. en_ner_bc5cdr_md: 0.843. en_ner_bionlp13cg_md: 0.785. en_ner_craft_md: 0.769. en_ner_jnlpba_md: 0.745",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/91
https://github.com/allenai/scispacy/issues/92:0,availability,Error,Error,0,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:99,availability,error,error,99,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2581,availability,error,error,2581,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2630,availability,error,error,2630,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:230,deployability,modul,module,230,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:21,energy efficiency,load,load,21,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:142,energy efficiency,load,load,142,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:331,energy efficiency,load,load,331,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:657,energy efficiency,load,load,657,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:777,energy efficiency,load,load,777,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:230,modifiability,modul,module,230,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:290,modifiability,pac,packages,290,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:431,modifiability,pac,packages,431,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:583,modifiability,pac,packages,583,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:727,modifiability,pac,packages,727,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:888,modifiability,pac,packages,888,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1061,modifiability,pac,packages,1061," going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in co",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1206,modifiability,pac,packages,1206,"tdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1356,modifiability,pac,packages,1356,"name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1476,modifiability,pac,packages,1476," return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). F",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:0,performance,Error,Error,0,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:21,performance,load,load,21,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:99,performance,error,error,99,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:142,performance,load,load,142,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:331,performance,load,load,331,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:657,performance,load,load,657,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:777,performance,load,load,777,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2581,performance,error,error,2581,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2630,performance,error,error,2630,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:0,safety,Error,Error,0,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:99,safety,error,error,99,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:230,safety,modul,module,230,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2581,safety,error,error,2581,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2630,safety,error,error,2630,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1543,security,token,tokenizer,1543,"herd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1572,security,token,tokenizer,1572,"/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise sou",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1621,security,token,tokenizer,1621,"model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1656,security,token,tokenizer,1656,"(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at positio",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1666,security,Token,Tokenizer,1666,"es). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. **",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1693,security,token,tokenizer,1693,"anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. *****************************",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1728,security,token,tokenizer,1728,"es/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:1738,security,Token,Tokenizer,1738,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:166,testability,Trace,Traceback,166,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:0,usability,Error,Error,0,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:99,usability,error,error,99,"Error when trying to load ""en_core_sci_sm""; Not sure of what's is going on, but I got this parsing error:. `>>> import spacy. >>> nlp = spacy.load(""en_core_sci_sm""). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 131, in load_model. return load_model_from_package(name, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 152, in load_model_from_package. return cls.load(**overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/en_core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/b",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2581,usability,error,error,2581,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/issues/92:2630,usability,error,error,2630,"core_sci_sm/__init__.py"", line 14, in load. nlp = load_model_from_init_py(__file__, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 190, in load_model_from_init_py. return load_model_from_path(data_path, meta, **overrides). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 173, in load_model_from_path. return nlp.from_disk(model_path). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 786, in from_disk. util.from_disk(path, deserializers, exclude). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 611, in from_disk. reader(path / key). File ""/home/bancherd3/anaconda3/lib/python3.7/site-packages/spacy/language.py"", line 776, in <lambda>. deserializers[""tokenizer""] = lambda p: self.tokenizer.from_disk(p, exclude=[""vocab""]). File ""tokenizer.pyx"", line 390, in spacy.tokenizer.Tokenizer.from_disk. File ""tokenizer.pyx"", line 436, in spacy.tokenizer.Tokenizer.from_bytes. File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 234, in compile. return _compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/re.py"", line 286, in _compile. p = sre_compile.compile(pattern, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_compile.py"", line 764, in compile. p = sre_parse.parse(p, flags). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 930, in parse. p = _parse_sub(source, pattern, flags & SRE_FLAG_VERBOSE, 0). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 426, in _parse_sub. not nested and not items)). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 536, in _parse. code1 = _class_escape(source, this). File ""/home/bancherd3/anaconda3/lib/python3.7/sre_parse.py"", line 337, in _class_escape. raise source.error('bad escape %s' % escape, len(escape)). re.error: bad escape \p at position 326`. ************************************************. Thank you very much.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/92
https://github.com/allenai/scispacy/pull/93:0,deployability,Updat,Update,0,Update README.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/93
https://github.com/allenai/scispacy/pull/93:0,safety,Updat,Update,0,Update README.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/93
https://github.com/allenai/scispacy/pull/93:0,security,Updat,Update,0,Update README.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/93
https://github.com/allenai/scispacy/pull/94:0,deployability,Updat,Update,0,Update index.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/94
https://github.com/allenai/scispacy/pull/94:0,safety,Updat,Update,0,Update index.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/94
https://github.com/allenai/scispacy/pull/94:0,security,Updat,Update,0,Update index.md;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/94
https://github.com/allenai/scispacy/pull/95:0,deployability,Updat,Update,0,Update paper link to S2 link;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/95
https://github.com/allenai/scispacy/pull/95:0,safety,Updat,Update,0,Update paper link to S2 link;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/95
https://github.com/allenai/scispacy/pull/95:0,security,Updat,Update,0,Update paper link to S2 link;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/95
https://github.com/allenai/scispacy/pull/96:0,energy efficiency,Reduc,Reduce,0,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:35,energy efficiency,predict,prediction,35,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:52,energy efficiency,Current,Currently,52,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:76,energy efficiency,Model,Model,76,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:150,energy efficiency,model,model,150,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:7,performance,memor,memory,7,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:46,performance,time,time,46,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:35,safety,predict,prediction,35,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:76,security,Model,Model,76,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:150,security,model,model,150,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/96:7,usability,memor,memory,7,"Reduce memory usage for linking at prediction time; Currently requires 5GB. Model files are here: `s3://ai2-s2-scispacy/data/linking_model/`. Run the model with this: `python3 scripts/linking.py --medmentions_path data/medmentions --umls_path data/umls_2017_aa_cat0129.json --k 1,2,10,100,1000 --model_path data/linking_model`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/96
https://github.com/allenai/scispacy/pull/97:103,availability,state,state,103,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:234,deployability,contain,contains,234,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:673,energy efficiency,reduc,reducing,673,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:840,energy efficiency,reduc,reduce,840,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:64,integrability,event,eventually,64,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:103,integrability,state,state,103,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:34,modifiability,Refact,Refactored,34,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:89,modifiability,maintain,maintain,89,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:143,modifiability,refact,refactored,143,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:34,performance,Refactor,Refactored,34,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:143,performance,refactor,refactored,143,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:89,safety,maintain,maintain,89,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/97:587,safety,avoid,avoiding,587,"Linking improvements; Changes:. - Refactored to use a class, as eventually we'll want to maintain some state around the candidate generator. - refactored `generate_candidates` to return a `List[Dict]` for each mention. The dictionary contains a mapping from `umls_canonical_id -> [list of cosine distances]`. note that the length of this dictionary for each mention may not be `k`, because we are doing NN search on the union of canonical ids and aliases, which will be mapped back to their canonical id. - use `scipy.sparse.save_npz` and `numpy.float16` during serialisation as well as avoiding serializing arrays with `dtype=numpy.object`, resulting in the tfidf vectors reducing in size from 1.8G to 395MB. - serialise the concept ids using json, not numpy: 193MB -> 67MB. - Deduplicating the aliases before computing the index means we reduce the size of the vectors + index by 15%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/97
https://github.com/allenai/scispacy/pull/99:88,interoperability,specif,specifically,88,"add abbreviation detection and tests; I thought this would be generally useful and also specifically might also help the entity linking efforts, because now we'll be able to expand abbreviations which are mentioned in the text, which it pretty common.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/99
https://github.com/allenai/scispacy/pull/99:17,safety,detect,detection,17,"add abbreviation detection and tests; I thought this would be generally useful and also specifically might also help the entity linking efforts, because now we'll be able to expand abbreviations which are mentioned in the text, which it pretty common.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/99
https://github.com/allenai/scispacy/pull/99:31,safety,test,tests,31,"add abbreviation detection and tests; I thought this would be generally useful and also specifically might also help the entity linking efforts, because now we'll be able to expand abbreviations which are mentioned in the text, which it pretty common.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/99
https://github.com/allenai/scispacy/pull/99:17,security,detect,detection,17,"add abbreviation detection and tests; I thought this would be generally useful and also specifically might also help the entity linking efforts, because now we'll be able to expand abbreviations which are mentioned in the text, which it pretty common.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/99
https://github.com/allenai/scispacy/pull/99:31,testability,test,tests,31,"add abbreviation detection and tests; I thought this would be generally useful and also specifically might also help the entity linking efforts, because now we'll be able to expand abbreviations which are mentioned in the text, which it pretty common.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/99
https://github.com/allenai/scispacy/pull/99:112,usability,help,help,112,"add abbreviation detection and tests; I thought this would be generally useful and also specifically might also help the entity linking efforts, because now we'll be able to expand abbreviations which are mentioned in the text, which it pretty common.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/99
https://github.com/allenai/scispacy/issues/100:567,availability,error,errors,567,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:961,availability,error,errors,961,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1195,availability,error,errors,1195,"/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3895,availability,replic,replication,3895,"y, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a car",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5950,availability,replic,replication,5950,"ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kap",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9577,availability,avail,available,9577,"n factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12562,availability,degrad,degradation,12562,"cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13675,availability,replic,replication,13675," to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:455,deployability,modul,module,455,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:505,deployability,depend,dependency,505,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1302,deployability,manag,manageable,1302,"ault written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-depend",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1374,deployability,modul,module,1374,"tps://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2301,deployability,depend,dependent,2301,"geable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this seq",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3565,deployability,observ,observed,3565," to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3694,deployability,depend,dependent,3694,"d VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protei",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3974,deployability,depend,dependent,3974,"5 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4227,deployability,fail,fails,4227," Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate th",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4821,deployability,contain,contains,4821,"inally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficie",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4922,deployability,contain,containing,4922,"verse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6774,deployability,provis,provision,6774,"is study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6960,deployability,contain,containing,6960,"ough activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7538,deployability,contain,contained,7538,"either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7705,deployability,observ,observed,7705," IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcriptio",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7943,deployability,modul,modulatory,7943,"h NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediate",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8829,deployability,depend,dependent,8829,"cts of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9173,deployability,depend,dependent,9173,"ecific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the exp",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10156,deployability,observ,observed,10156,"CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflamma",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10518,deployability,modul,modulating,10518,"e of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal pa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12714,deployability,observ,observed,12714,"x may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13434,deployability,depend,dependent,13434,"m the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contain",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:14432,deployability,contain,contains,14432,"pendent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. **[SPLIT HERE]** Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:15399,deployability,manag,managing,15399,"rs of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. **[SPLIT HERE]** Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:144,energy efficiency,model,model,144,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:348,energy efficiency,model,model,348,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1302,energy efficiency,manag,manageable,1302,"ault written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-depend",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2681,energy efficiency,reduc,reduced,2681,"adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3756,energy efficiency,reduc,reduced,3756,"escence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11266,energy efficiency,adapt,adaptors,11266,"h products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in bo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13964,energy efficiency,optim,optimal,13964,"Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of trans",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:15399,energy efficiency,manag,managing,15399,"rs of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. **[SPLIT HERE]** Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:505,integrability,depend,dependency,505,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2228,integrability,mediat,mediated,2228," . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. E",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2301,integrability,depend,dependent,2301,"geable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this seq",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3694,integrability,depend,dependent,3694,"d VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protei",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3974,integrability,depend,dependent,3974,"5 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4013,integrability,sub,subunit,4013,"-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4595,integrability,mediat,mediated,4595,"kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C becaus",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5559,integrability,mediat,mediated,5559,"gregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A m",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6177,integrability,mediat,mediated,6177,"at nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that un",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7335,integrability,sub,subunits,7335,"*[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8196,integrability,sub,subunit,8196,"s predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8829,integrability,depend,dependent,8829,"cts of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8941,integrability,mediat,mediated,8941,"dulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9173,integrability,depend,dependent,9173,"ecific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the exp",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10099,integrability,mediat,mediated,10099,"re with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** Howeve",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10198,integrability,sub,subunit,10198,"ivity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11266,integrability,adapt,adaptors,11266,"h products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in bo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11754,integrability,mediat,mediated,11754,"whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addit",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11763,integrability,transform,transformation,11763," activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this ag",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11973,integrability,sub,subsets,11973,"IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Underspli",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12141,integrability,mediat,mediated,12141,"ese proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12297,integrability,sub,subsets,12297,"ignaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcrip",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12408,integrability,sub,subsets,12408,"duction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synt",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12553,integrability,mediat,mediated,12553," signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp16",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12957,integrability,sub,subsets,12957,"RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessar",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13434,integrability,depend,dependent,13434,"m the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contain",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13559,integrability,mediat,mediated,13559,"egradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13849,integrability,mediat,mediated,13849,"racellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:212,interoperability,Share,SharedTask,212,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:589,interoperability,share,share,589,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2228,interoperability,mediat,mediated,2228," . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. E",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2741,interoperability,specif,specific,2741," pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dr",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3526,interoperability,bind,binding,3526," 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants wa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4576,interoperability,bind,binding,4576,"ersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through prot",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4595,interoperability,mediat,mediated,4595,"kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C becaus",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5559,interoperability,mediat,mediated,5559,"gregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A m",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6177,interoperability,mediat,mediated,6177,"at nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that un",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6915,interoperability,specif,specifically,6915,"tokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7069,interoperability,bind,binding,7069,"La-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive N",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7675,interoperability,specif,specific,7675,"ce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposi",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8176,interoperability,specif,specific,8176,"nstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-depende",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8373,interoperability,bind,binding,8373,"ma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]**",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8739,interoperability,cot,cotransfection,8739,"I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8941,interoperability,mediat,mediated,8941,"dulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9010,interoperability,specif,specific,9010," human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 pr",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10099,interoperability,mediat,mediated,10099,"re with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** Howeve",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11122,interoperability,prox,proximal,11122,"as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsivenes",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11266,interoperability,adapt,adaptors,11266,"h products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in bo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11754,interoperability,mediat,mediated,11754,"whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addit",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11763,interoperability,transform,transformation,11763," activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this ag",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12141,interoperability,mediat,mediated,12141,"ese proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12553,interoperability,mediat,mediated,12553," signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp16",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13079,interoperability,bind,binding,13079,"ignificantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosph",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13226,interoperability,bind,binding,13226,"d nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13559,interoperability,mediat,mediated,13559,"egradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13849,interoperability,mediat,mediated,13849,"racellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:455,modifiability,modul,module,455,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:505,modifiability,depend,dependency,505,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1374,modifiability,modul,module,1374,"tps://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2301,modifiability,depend,dependent,2301,"geable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this seq",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3526,modifiability,bind,binding,3526," 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants wa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3694,modifiability,depend,dependent,3694,"d VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protei",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3974,modifiability,depend,dependent,3974,"5 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4576,modifiability,bind,binding,4576,"ersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through prot",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7069,modifiability,bind,binding,7069,"La-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive N",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7943,modifiability,modul,modulatory,7943,"h NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediate",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8373,modifiability,bind,binding,8373,"ma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]**",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8829,modifiability,depend,dependent,8829,"cts of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9173,modifiability,depend,dependent,9173,"ecific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the exp",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10518,modifiability,modul,modulating,10518,"e of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal pa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11266,modifiability,adapt,adaptors,11266,"h products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in bo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13079,modifiability,bind,binding,13079,"ignificantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosph",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13226,modifiability,bind,binding,13226,"d nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13434,modifiability,depend,dependent,13434,"m the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contain",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:567,performance,error,errors,567,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:961,performance,error,errors,961,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1195,performance,error,errors,1195,"/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3321,performance,time,time,3321," maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not d",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3384,performance,time,time,3384,"% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11929,performance,memor,memory,11929,"ents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12059,performance,memor,memory,12059,"ion of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12273,performance,memor,memory,12273,"which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked sti",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12599,performance,memor,memory,12599,"-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 po",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12932,performance,memor,memory,12932," (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Althoug",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4227,reliability,fail,fails,4227," Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate th",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9577,reliability,availab,available,9577,"n factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12562,reliability,degrad,degradation,12562,"cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:455,safety,modul,module,455,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:505,safety,depend,dependency,505,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:567,safety,error,errors,567,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:961,safety,error,errors,961,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1195,safety,error,errors,1195,"/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1302,safety,manag,manageable,1302,"ault written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-depend",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1374,safety,modul,module,1374,"tps://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2301,safety,depend,dependent,2301,"geable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this seq",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3280,safety,detect,detected,3280," by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and ba",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3694,safety,depend,dependent,3694,"d VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protei",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3974,safety,depend,dependent,3974,"5 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4067,safety,compl,complex,4067,"toxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6937,safety,compl,complex,6937,"es HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for th",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7943,safety,modul,modulatory,7943,"h NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediate",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8046,safety,compl,complexes,8046," the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is conc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8829,safety,depend,dependent,8829,"cts of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9173,safety,depend,dependent,9173,"ecific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the exp",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9577,safety,avail,available,9577,"n factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10518,safety,modul,modulating,10518,"e of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal pa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13434,safety,depend,dependent,13434,"m the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contain",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:14238,safety,detect,detectable,14238,"was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:15399,safety,manag,managing,15399,"rs of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. **[SPLIT HERE]** Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:144,security,model,model,144,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:348,security,model,model,348,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1091,security,ident,identify,1091,"reat work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1323,security,token,tokenization,1323,"e `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maxim",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3280,security,detect,detected,3280," by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and ba",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4067,security,compl,complex,4067,"toxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4532,security,ident,identified,4532,"p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5323,security,sign,signals,5323,"tly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of N",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5380,security,sign,signals,5380,"te the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to th",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5547,security,sign,signals,5547,"ctionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:6937,security,compl,complex,6937,"es HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation was due to the translocation of p65 and c-Rel NF.kappa B proteins from cytoplasmic stores to the nucleus, where they bound the kappa B sequence of the IL-2R alpha promoter either as p50. - A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for th",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8046,security,compl,complexes,8046," the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is conc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8523,security,sign,signals,8523," monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9577,security,availab,available,9577,"n factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9783,security,sign,significantly,9783,"KC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10021,security,ident,identified,10021,"lating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and I",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10313,security,control,controlled,10313,"ar translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10982,security,sign,signaling,10982,"ation of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from y",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11300,security,sign,signaling,11300,"tion is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets,",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11558,security,sign,signaling,11558,"cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated d",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12082,security,sign,significantly,12082,"HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding ac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12380,security,sign,significantly,12380,"ly, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:14238,security,detect,detectable,14238,"was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:505,testability,depend,dependency,505,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:2301,testability,depend,dependent,2301,"geable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this seq",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3565,testability,observ,observed,3565," to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3694,testability,depend,dependent,3694,"d VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf and Survanta suppress TNF mRNA and secretion (85 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protei",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:3974,testability,depend,dependent,3974,"5 +/-. - 4% mean percent inhibition +/-. - SEM by Exosurf; 71 +/-. - 6% by Survanta) by endotoxin-stimulated THP-1, a human monocytic cell line. **Oversplitting in between ""p65.c-Rel"" / ""p50-.c-Rel""**. Example 1. - p65 or as p50. - c-Rel heterodimers. Example 2. - p50. - c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation. Example 3. - However, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7705,testability,observ,observed,7705," IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. **[SPLIT HERE]** We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcriptio",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:7943,testability,modula,modulatory,7943,"h NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site. - Electrophoretic mobility shift assays (EMSAs) demonstrated that unstimulated monocytes predominantly expressed p50 NF-kappa B. **[SPLIT HERE]** Stimulation with LPS or IFN-gamma resulted in the expression of p50 and p65 subunits, while the combination of IFN-gamma plus LPS caused a further increase in the expression of NF-kappa B. **[SPLIT HERE]** With Western blotting, it was shown that nuclear extracts from monocytes contained p50 and p65 protein in response to LPS and IFN-gamma stimulation. - The effects of IFN-gamma on the transcription factors were specific, since no change was observed in the expression of NF-IL-6 or I kappa B alpha, the inhibitor of NF-kappa B. **[SPLIT HERE]** We conclude that the effects of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediate",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:8829,testability,depend,dependent,8829,"cts of IFN-gamma on the expression of the transcription factors AP-1 and NF-kappa B may be important for the modulatory effects of IFN-gamma on the cytokine expression in activated human monocytes. - Protein-DNA complexes of constitutive NF-kappa B are similar in mobility to the LPS-induced NF-kappa B and both are recognized by an antibody specific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:9173,testability,depend,dependent,9173,"ecific to the p50 subunit of NF-kappa B. **[SPLIT HERE]** By contrast, treatment of cells with pyrrolidine dithiocarbamate (PDTC) will only block LPS-induced NF-kappa B, but not the constitutive binding protein. - Stimulation of T-cells by agonistic anti-CD28 antibodies in conjunction with phorbol 12-myristate 13-acetate (PMA)- or TcR-derived signals induces the enhanced activation of the transcription factor NF-kappa B. **[SPLIT HERE]** Here we report that CD28 engagement, however, exerts opposite effects on the transcription factor AP-1. - In addition, cotransfection of a negative dominant molecule of PKC-zeta (PKC-zeta mut) with NF-kappa B-dependent reporter genes selectively inhibits the HIV- but not phorbol myristate acetate- or lipopolysaccharide-mediated activation of NF-kappa B. **[SPLIT HERE]** That PKC-zeta is specific in regulating NF-kappa B is concluded from the inability of PKC-zeta(mut) to interfere with the basal or phorbol myristate acetate-inducible CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the exp",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10156,testability,observ,observed,10156,"CREB- or AP1-dependent transcriptional activity. - Inhibition of TNF-alpha secretion by LPS-stimulated THP-1-hGH cells was associated with a decrease in nuclear translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflamma",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10313,testability,control,controlled,10313,"ar translocation of nuclear factor-kappaB. **[SPLIT HERE]** The capacity of GH to inhibit LPS-induced TNF-alpha production by monocytes without altering other pathways leading to TNF-alpha production may be of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:10518,testability,modula,modulating,10518,"e of potential relevance in septic shock, since GH is available for clinical use. - In this manuscript we have investigated the molecular mechanisms by which T cell lines stimulated with phorbol 12-myristate 13-acetate (PMA) and phytohemagglutin (PHA) display significantly higher levels of NF-kappa B1 encoding transcripts than cells stimulated with tumor necrosis factor-alpha, despite the fact that both stimuli activate NF-kappa B. **[SPLIT HERE]** Characterization of the NF-kappa B1 promoter identified an Egr-1 site which was found to be essential for both the PMA/PHA-mediated induction as well as the synergistic activation observed after the expression of the RelA subunit of NF-kappa B and Egr-1. - The expression of many genes for which products are involved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal pa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12714,testability,observ,observed,12714,"x may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increa",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:13434,testability,depend,dependent,13434,"m the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contain",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:567,usability,error,errors,567,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:961,usability,error,errors,961,"Under/over-splitting in BioNLP09: common cases; Hi everyone, and thank you very much for your great work! I tried the scispacy `en_core_sci_md` model on the [BioNLP09 corpus](http://www.nactem.ac.uk/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1195,usability,error,errors,1195,"/tsujii/GENIA/SharedTask/index.shtml) and I noticed an improved sentence segmentation accuracy w.r.t. the default written text genre `en_core_web_md` model. I read your [paper](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1367,usability,custom,custom,1367,"per](https://arxiv.org/abs/1902.07669) and I'm excited that the rule-based segmenter module is not usually needed due to the in-domain dependency parser training. However, I noticed some recurrent errors that I want to share with you, since they occur on the aforementioned, widely used BioNLP corpus. I collected many examples that I'm reporting here, and that can be summarized as:. - Oversplitting after ""+/-"" or at the dot in ""p50.c-rel"". - Undersplitting after a capital letter followed by a dot (e.g., kappa B., kinase A., Cya.). You can also find attached a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC an",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:1929,usability,clear,clearly,1929,"a list of other less common errors I screened ([other_errors.txt](https://github.com/allenai/scispacy/files/3111859/other_errors.txt)), but I think even just identify a solution for and/or handling these cases would be great since they represent the majority of errors (~75%) in the BioNLP09 corpus! . What would you recommend for handling these cases? Are they easily manageable by adding tokenization rules or you suggest to have a custom module to workaround the problem? Thank you very much indeed! Alan. _____. **Oversplitting after ""+/-""**. Example 1. - PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/-. - 86 pg/ml). Example 2. - The addition of anti-CD28 mAb to anti-CD3-stimulated cells markedly increased IL-2 production in both cell types, but levels of IL-2 in neonatal T cells remained clearly lower than those of adult T cells (respective mean values: 385 +/-. - 109 pg/ml and 4494 +/-. - 1199 pg/ml). Example 3. - Maximal inhibition of IgE production for B cells was at 10(-8) mol/L for all-trans RA (94% +/-. - 1.8%) and 96% +/-. - 3.2% for 13-cis RA. Example 4. - Anti-CD40 + IL-4-mediated proliferation of PBMC and B cells was inhibited by RA in a dose-dependent manner, with maximal inhibition of 62% +/-. - 5% in PBMC and 55% +/-. - 4.4% in B cells by all-trans RA, and 58% +/-. - 6.7% and 51% +/-. - 4.7%, respectively by 13-cis RA. Example 5. - By immunocytochemistry, 25 +/-. - 7% of the human neutrophils were shown to express immunoreactive GH, whereas eosinophils were negative. Example 6. - TCP succinate (200 microM, 24 h) reduced TNF-induced VCAM-1 and E-selectin expression from a specific mean fluorescence intensity of 151 +/- 28 to 12 +/-. - 4 channels and from 225 +/- 38 to 79 +/-. - 21 channels, respectively. Example 7. - In this study, we report that both Exosurf a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:4435,usability,interact,interaction,4435,"owever, immediately after TcR/CD3 cross-linking (after approximately 1 h; immediate) binding of p50. - p65 heterodimers was observed. **Undersplitting after ""kappa B."" / ""kappaB.""**. - Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. **[SPLIT HERE]** Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner. - The NF-kappa B p65 subunit provides the transactivation activity in this complex and serves as an intracellular receptor for a cytoplasmic inhibitor of NF-kappa B, termed I kappa B. **[SPLIT HERE]** In contrast, NF-kappa B p50 alone fails to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B. **[SPLIT HERE]** To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:5366,usability,interact,interact,5366,"* To investigate the molecular basis for the critical regulatory interaction between NF-kappa B and I kappa B/MAD-3, a series of human NF-kappa B p65 mutants was identified that functionally segregated DNA binding, I kappa B-mediated inhibition, and I kappa B-induced nuclear exclusion of this transcription factor. - This protein is most similar to the 105-kDa precursor polypeptide of p50-NF-kappa B. **[SPLIT HERE]** Like the 105-kDa precursor, it contains an amino-terminal Rel-related domain of about 300 amino acids and a carboxy-terminal domain containing six full cell cycle or ankyrin repeats. - The kappa B enhancer of the gene encoding the interleukin-2 (IL-2) receptor alpha chain (IL-2R alpha) is functional only in the hybrids expressing nuclear NF-kappa B. **[SPLIT HERE]** These findings show that nuclear NF-kappa B is necessary to activate the kappa B enhancer, while KBF1 by itself is not sufficient. - In this report we describe how signals initiated through the type I IL-1R interact with signals from the antigen receptor to synergistically augment the transactivating properties of NF-kappa B. **[SPLIT HERE]** The synergistic antigen receptor initiated signals are mediated through protein kinase C because they can be mimicked by the phorbol ester, 12-O-tetradecanoylphorbol-13-acetate, but not with calcium ionophores; and are staurosporine sensitive but cyclosporine resistant. - This study demonstrates that human immunodeficiency virus type 1 (HIV-1) Tat protein amplifies the activity of tumor necrosis factor (TNF), a cytokine that stimulates HIV-1 replication through activation of NF-kappa B. **[SPLIT HERE]** In HeLa cells stably transfected with the HIV-1 tat gene (HeLa-tat cells), expression of the Tat protein enhanced both TNF-induced activation of NF-kappa B and TNF-mediated cytotoxicity. - Treatment of human resting T cells with phorbol esters strongly induced the expression of IL-2R alpha and the activation of NF.kappa B. **[SPLIT HERE]** This activation",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11282,usability,effectiv,effectively,11282,"olved in inflammation is controlled by the transcriptional regulator nuclear factor (NF)-kappa B. **[SPLIT HERE]** Because surfactant protein (SP) A is involved in local host defense in the lung and alters immune cell function by modulating the expression of proinflammatory cytokines as well as surface proteins involved in inflammation, we hypothesized that SP-A exerts its action, at least in part, via activation of NF-kappa B. We used gel shift assays to determine whether SP-A activated NF-kappa B in the THP-1 cell line, a human monocytic cell line. - Similarly, a kinase-deficient mutant of NIK (NF-kappaB-inducing kinase), which represents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naiv",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:11929,usability,memor,memory,11929,"ents an upstream kinase in the TNF-alpha and IL-1 signaling pathways leading to IKKalpha and IKKbeta activation, blocks Tax induction of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12059,usability,memor,memory,12059,"ion of NF-kappaB. **[SPLIT HERE]** However, plasma membrane-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce a",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12113,usability,responsiv,responsiveness,12113,"e-proximal elements in these proinflammatory cytokine pathways are apparently not involved since dominant negative mutants of the TRAF2 and TRAF6 adaptors, which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcr",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12273,usability,memor,memory,12273,"which effectively block signaling through the cytoplasmic tails of the TNF-alpha and IL-1 receptors, respectively, do not inhibit Tax induction of NF-kappaB. **[SPLIT HERE]** Together, these studies demonstrate that HTLV-1 Tax exploits a distal part of the proinflammatory cytokine signaling cascade leading to induction of NF-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked sti",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12599,usability,memor,memory,12599,"-kappaB. **[SPLIT HERE]** The pathological alteration of this cytokine pathway leading to NF-kappaB activation by Tax may play a central role in HTLV-1-mediated transformation of human T cells, clinically manifested as the adult T-cell leukemia. - Our analyses of the induction of nuclear factor-kappaB (NFkappaB) in activated memory (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 po",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:12932,usability,memor,memory,12932," (CD45RO+) and naive (CD45RA+) T cell subsets from young and elderly donors has demonstrated that, regardless of donor age, memory T cells are not significantly altered in their responsiveness to TNF-alpha-mediated induction of NFkappaB. **[SPLIT HERE]** Although treatment with TNF-alpha induced nuclear localization of NFkappaB in both memory and naive T cell subsets, irrespective of the age of the donor, the levels of induced NFkappaB were significantly lower in both subsets of T cells obtained from the elderly, when compared to those in young. - Examination of IkappaB alpha regulation revealed that TNF-alpha-mediated degradation of IkappaB alpha in both memory and naive T cells from the elderly was severely impaired, thus contributing to the lowered induction of the observed NFkappaB. **[SPLIT HERE]** In addition, this age-related decrease in induction of nuclear NFkappaB correlated with decrease in intracellular IL-2 receptor expression and anti-CD3-induced proliferation of both memory and naive T cells subsets. **Undersplitting after ""kinase C."" / ""kinase A.""**. - In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Althoug",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:14112,usability,interact,interaction,14112,"cription factor whose activity is also regulated by protein kinase C. **[SPLIT HERE]** The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun. - The stimulatory effect of gp160 on NF-kappa B activation is protein synthesis independent, is dependent upon protein tyrosine phosphorylation, and abrogated by inhibitors of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demo",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/issues/100:14900,usability,indicat,indicates,14900,"rs of protein kinase C. **[SPLIT HERE]** The gp160-mediated activation of NF-kappa B in CD4 positive T cells may be involved in biological effects, e.g., enhanced HIV replication, hypergammaglobulinemia, increased cytokine secretion, hypercellularity in bone marrow and apoptosis. - The phosphorylation of CREB that results in activation is mediated by protein kinase C rather than by protein kinase A. **[SPLIT HERE]** Although the CRE site is necessary, optimal induction of bcl-2 expression requires participation of the upstream regulatory element, suggesting that phosphorylation of CREB alters its interaction with the upstream regulatory element. **Undersplitting after ""CyA."" or ""CsA.""**. - Induction of the PILOT gene is detectable in human T cells 20 min following activation in the presence of cycloheximide and is fully suppressed by CyA. **[SPLIT HERE]** The PILOT protein has a calculated M(r) of 42.6 kDa and contains three zinc fingers of the C2H2-type at the carboxyl-terminus which are highly homologous to the zinc finger regions of the transcription factors EGR1, EGR2, and pAT 133. - Transactivation by recombinant NFAT1 in Jurkat T cells requires dual stimulation with ionomycin and phorbol 12-myristate 13-acetate; this activity is potentiated by coexpression of constitutively active calcineurin and is inhibited by CsA. **[SPLIT HERE]** . Immunocytochemical analysis indicates that recombinant NFAT1 localizes in the cytoplasm of transiently transfected T cells and translocates into the nucleus in a CsA-sensitive manner following ionomycin stimulation. - CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. **[SPLIT HERE]** Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/100
https://github.com/allenai/scispacy/pull/101:40,energy efficiency,model,model,40,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:125,energy efficiency,model,model,125,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:465,energy efficiency,model,model,465,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:275,integrability,abstract,abstract,275,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:275,modifiability,abstract,abstract,275,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:394,safety,avoid,avoid,394,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:404,safety,compl,complexity,404,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:40,security,model,model,40,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:125,security,model,model,125,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:404,security,compl,complexity,404,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:465,security,model,model,465,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/101:346,usability,document,document,346,"Add an evaluation option to use a spacy model for ner instead of gold mentions; Evaluates candidate generation using a spacy model for ner instead of gold mentions. In this setting, an entity candidate is considered correct if that entity is in the gold entities for a given abstract. i.e. candidate entities are evaluated for correctness at the document level instead of the mention level, to avoid the complexity of trying to align mentions produced by the spacy model with the gold mentions.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/101
https://github.com/allenai/scispacy/pull/102:152,testability,simpl,simpler,152,"remove outdated script; We originally tried using the raw docs along with the annotations, but it didn't make any difference so we switched back to the simpler way. The data can be generated using the `spacy` command line args so we don't need this stuff anymore.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/102
https://github.com/allenai/scispacy/pull/102:152,usability,simpl,simpler,152,"remove outdated script; We originally tried using the raw docs along with the annotations, but it didn't make any difference so we switched back to the simpler way. The data can be generated using the `spacy` command line args so we don't need this stuff anymore.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/102
https://github.com/allenai/scispacy/pull/102:209,usability,command,command,209,"remove outdated script; We originally tried using the raw docs along with the annotations, but it didn't make any difference so we switched back to the simpler way. The data can be generated using the `spacy` command line args so we don't need this stuff anymore.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/102
https://github.com/allenai/scispacy/pull/103:93,energy efficiency,reduc,reduce,93,Improving linking evaluation code; - fix a small bug in linking evaluation. - refactoring to reduce duplicate code,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/103
https://github.com/allenai/scispacy/pull/103:78,modifiability,refact,refactoring,78,Improving linking evaluation code; - fix a small bug in linking evaluation. - refactoring to reduce duplicate code,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/103
https://github.com/allenai/scispacy/pull/103:78,performance,refactor,refactoring,78,Improving linking evaluation code; - fix a small bug in linking evaluation. - refactoring to reduce duplicate code,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/103
https://github.com/allenai/scispacy/issues/104:23,interoperability,specif,specific,23,if i want to recognise specific entity(like genes or decease) what to do?;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/104
https://github.com/allenai/scispacy/pull/105:407,deployability,fail,failed,407,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:947,deployability,fail,failed,947,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:0,energy efficiency,Predict,Prediction,0,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:617,energy efficiency,predict,predicted,617,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:199,integrability,Filter,Filtered,199,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:559,integrability,filter,filtered,559,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:739,integrability,Filter,Filtered,739,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:1100,integrability,filter,filtered,1100,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:407,reliability,fail,failed,407,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:947,reliability,fail,failed,947,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:0,safety,Predict,Prediction,0,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/105:617,safety,predict,predicted,617,"Prediction using linker; Adding a linker; a supervised sklearn classifier. . With gold mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.28%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. Candidate generation failed: 0.05%. Correct mention-level linking: 63.52% <<<===============. Mean, std, min, max candidate ids: 56.07%, 13.51%, 0, 164. Mean, std, min, max filtered candidate ids: 56.07%, 13.51%, 0, 164. ```. With predicted mentions and types:. ```. MedMentions entities not in UMLS: 756. MedMentions entities found in UMLS: 91. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 51.90%. Gold concept not in candidates: 9.32%. Doc level gold concept in candidates: 75.51%. Doc level gold concepts missed: 24.49%. Candidate generation failed: 38.79%. Correct mention-level linking: 38.67% <<<===============. Mean, std, min, max candidate ids: 55.97%, 13.63%, 0, 163. Mean, std, min, max filtered candidate ids: 55.97%, 13.63%, 0, 163. ```. Will follow up with the code for generating training data and training classifier.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/105
https://github.com/allenai/scispacy/pull/108:22,energy efficiency,predict,predict,22,use predict_proba not predict;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/108
https://github.com/allenai/scispacy/pull/108:22,safety,predict,predict,22,use predict_proba not predict;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/108
https://github.com/allenai/scispacy/pull/110:136,usability,help,help,136,More linker features; Added more fields to the linker classifier training data and added more features. None of the additional features help.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/110
https://github.com/allenai/scispacy/pull/111:294,deployability,fail,fails,294,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:36,energy efficiency,model,model,36,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:420,energy efficiency,predict,predicted,420,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:142,modifiability,Refact,Refactored,142,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:311,modifiability,Refact,Refactored,311,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:142,performance,Refactor,Refactored,142,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:311,performance,Refactor,Refactored,311,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:294,reliability,fail,fails,294,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:420,safety,predict,predicted,420,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:36,security,model,model,36,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/111:469,security,modif,modify,469,"Abbr linker; . Changes:. 1. A spacy model is now required, because we need the doc to do abbreviation dectection, even with gold mentions. 2. Refactored a bit, pulling out some functions. 3. Moved the check for generating the training data outside of the main evaluation function so the script fails faster. 4. Refactored to actually use the doc creation function, (additionally pulls out the generation of the gold and predicted mentions, because I need to be able to modify them when replacing abbreviations). Both results below use gold mentions. . **Without abbreviations**. Gold concept in candidates: 83.67%. Gold concept not in candidates: 16.29%. Doc level gold concept in candidates: 92.79%. Doc level gold concepts missed: 7.21%. **With abbreviations**. Gold concept in candidates: 86.60%. Gold concept not in candidates: 13.36%. Doc level gold concept in candidates: 92.77%. Doc level gold concepts missed: 7.23%.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/111
https://github.com/allenai/scispacy/pull/112:458,deployability,fail,failed,458,"Doc level eval; ```. python scripts/linking.py --medmentions_path s3_data/med_mentions --umls_path s3_data/umls_2017_aa_cat0129.json --model_path data/linking_model2/ --ks 80 --thresholds 1.0 --spacy_model en_core_sci_md --use_soft_matching. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 71.60%. Gold concept not in candidates: 17.35%. Doc level gold concept in candidates: 80.65%. Doc level gold concepts missed: 19.35%. Candidate generation failed: 11.05%. Mention linking precision 46.61%. Doc linking precision 42.67%. Normalized doc linking precision 60.04%. Doc linking recall 48.42%. Linking mention-level recall@1: 41.98%. Normalized linking mention-level recall@1: 58.63%. Linking mention-level recall@3: 54.96%. Normalized linking mention-level recall@3: 76.76%. Linking mention-level recall@5: 59.02%. Normalized linking mention-level recall@5: 82.43%. Linking mention-level recall@10: 63.95%. Normalized linking mention-level recall@10: 89.31%. Mean, std, min, max candidate ids: 56.09, 13.64, 0, 164. Mean, std, min, max filtered candidate ids: 56.09, 13.64, 0, 164. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/112
https://github.com/allenai/scispacy/pull/112:249,integrability,Filter,Filtered,249,"Doc level eval; ```. python scripts/linking.py --medmentions_path s3_data/med_mentions --umls_path s3_data/umls_2017_aa_cat0129.json --model_path data/linking_model2/ --ks 80 --thresholds 1.0 --spacy_model en_core_sci_md --use_soft_matching. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 71.60%. Gold concept not in candidates: 17.35%. Doc level gold concept in candidates: 80.65%. Doc level gold concepts missed: 19.35%. Candidate generation failed: 11.05%. Mention linking precision 46.61%. Doc linking precision 42.67%. Normalized doc linking precision 60.04%. Doc linking recall 48.42%. Linking mention-level recall@1: 41.98%. Normalized linking mention-level recall@1: 58.63%. Linking mention-level recall@3: 54.96%. Normalized linking mention-level recall@3: 76.76%. Linking mention-level recall@5: 59.02%. Normalized linking mention-level recall@5: 82.43%. Linking mention-level recall@10: 63.95%. Normalized linking mention-level recall@10: 89.31%. Mean, std, min, max candidate ids: 56.09, 13.64, 0, 164. Mean, std, min, max filtered candidate ids: 56.09, 13.64, 0, 164. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/112
https://github.com/allenai/scispacy/pull/112:1049,integrability,filter,filtered,1049,"Doc level eval; ```. python scripts/linking.py --medmentions_path s3_data/med_mentions --umls_path s3_data/umls_2017_aa_cat0129.json --model_path data/linking_model2/ --ks 80 --thresholds 1.0 --spacy_model en_core_sci_md --use_soft_matching. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 71.60%. Gold concept not in candidates: 17.35%. Doc level gold concept in candidates: 80.65%. Doc level gold concepts missed: 19.35%. Candidate generation failed: 11.05%. Mention linking precision 46.61%. Doc linking precision 42.67%. Normalized doc linking precision 60.04%. Doc linking recall 48.42%. Linking mention-level recall@1: 41.98%. Normalized linking mention-level recall@1: 58.63%. Linking mention-level recall@3: 54.96%. Normalized linking mention-level recall@3: 76.76%. Linking mention-level recall@5: 59.02%. Normalized linking mention-level recall@5: 82.43%. Linking mention-level recall@10: 63.95%. Normalized linking mention-level recall@10: 89.31%. Mean, std, min, max candidate ids: 56.09, 13.64, 0, 164. Mean, std, min, max filtered candidate ids: 56.09, 13.64, 0, 164. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/112
https://github.com/allenai/scispacy/pull/112:458,reliability,fail,failed,458,"Doc level eval; ```. python scripts/linking.py --medmentions_path s3_data/med_mentions --umls_path s3_data/umls_2017_aa_cat0129.json --model_path data/linking_model2/ --ks 80 --thresholds 1.0 --spacy_model en_core_sci_md --use_soft_matching. K: 80, Filtered threshold : 1.0. Gold concept in candidates: 71.60%. Gold concept not in candidates: 17.35%. Doc level gold concept in candidates: 80.65%. Doc level gold concepts missed: 19.35%. Candidate generation failed: 11.05%. Mention linking precision 46.61%. Doc linking precision 42.67%. Normalized doc linking precision 60.04%. Doc linking recall 48.42%. Linking mention-level recall@1: 41.98%. Normalized linking mention-level recall@1: 58.63%. Linking mention-level recall@3: 54.96%. Normalized linking mention-level recall@3: 76.76%. Linking mention-level recall@5: 59.02%. Normalized linking mention-level recall@5: 82.43%. Linking mention-level recall@10: 63.95%. Normalized linking mention-level recall@10: 89.31%. Mean, std, min, max candidate ids: 56.09, 13.64, 0, 164. Mean, std, min, max filtered candidate ids: 56.09, 13.64, 0, 164. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/112
https://github.com/allenai/scispacy/pull/113:46,availability,state,statement,46,Accidentally committed with a debugging print statement;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/113
https://github.com/allenai/scispacy/pull/113:46,integrability,state,statement,46,Accidentally committed with a debugging print statement;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/113
https://github.com/allenai/scispacy/pull/113:0,safety,Accid,Accidentally,0,Accidentally committed with a debugging print statement;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/113
https://github.com/allenai/scispacy/issues/116:1084,deployability,Version,Version,1084,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:1109,deployability,Version,Version,1109,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:390,energy efficiency,load,load,390,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:435,energy efficiency,load,load,435,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:1084,integrability,Version,Version,1084,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:1109,integrability,Version,Version,1109,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:1084,modifiability,Version,Version,1084,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:1109,modifiability,Version,Version,1109,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:390,performance,load,load,390,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:435,performance,load,load,435,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:819,safety,detect,detected,819,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:819,security,detect,detected,819,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/issues/116:1028,usability,help,help,1028,"Issue determining symptoms and affected body parts: e.g. arms; I am trying to determine a way to retrieve symptoms and the affected body parts when a text is analyzed. I am using en_ner_bc5cdr_md and en_ner_bionlp13cg_md to retrieve this information. But I do seem some issues. For example. ```. text =""I have numbness in my arm and leg"". import scispacy. import spacy. symptom_nlp = spacy.load(""en_ner_bc5cdr_md"") . organ_nlp = spacy.load(""en_ner_bionlp13cg_md""). text =""I have numbness in my arm and leg"". doc_symptoms = symptom_nlp(text). doc_organs = organ_nlp(text). ```. I get the following results:. ```. Symptoms:. numbness DISEASE. Organ:. arm CANCER. leg ORGAN. ```. I never thought of any correlation between arm and cancer. Also when I just use text = ""I have numbness in my arm"" , the word arm is not even detected. Also if I change to text = ""I have numbness in my arm and leg and toes"" I get the following:. ```. Symptoms:. numbness DISEASE. Organ:. arm PATHOLOGICAL_FORMATION. leg ORGAN. ```. Any ideas why? Any help would be appreciated. Thank you. I am using. spacy Version: 2.1.3. scispacy Version: 0.2.0",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/116
https://github.com/allenai/scispacy/pull/118:13,deployability,api,api,13,"Abbreviation api; Originally I set up the abbreviation component to return `LongForm, Set[ShortForm]` tuples, which was the wrong way to go about it because mostly, people will want to manipulate the short forms of the abbreviations. This way works much better.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/118
https://github.com/allenai/scispacy/pull/118:13,integrability,api,api,13,"Abbreviation api; Originally I set up the abbreviation component to return `LongForm, Set[ShortForm]` tuples, which was the wrong way to go about it because mostly, people will want to manipulate the short forms of the abbreviations. This way works much better.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/118
https://github.com/allenai/scispacy/pull/118:55,integrability,compon,component,55,"Abbreviation api; Originally I set up the abbreviation component to return `LongForm, Set[ShortForm]` tuples, which was the wrong way to go about it because mostly, people will want to manipulate the short forms of the abbreviations. This way works much better.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/118
https://github.com/allenai/scispacy/pull/118:13,interoperability,api,api,13,"Abbreviation api; Originally I set up the abbreviation component to return `LongForm, Set[ShortForm]` tuples, which was the wrong way to go about it because mostly, people will want to manipulate the short forms of the abbreviations. This way works much better.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/118
https://github.com/allenai/scispacy/pull/118:55,interoperability,compon,component,55,"Abbreviation api; Originally I set up the abbreviation component to return `LongForm, Set[ShortForm]` tuples, which was the wrong way to go about it because mostly, people will want to manipulate the short forms of the abbreviations. This way works much better.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/118
https://github.com/allenai/scispacy/pull/118:55,modifiability,compon,component,55,"Abbreviation api; Originally I set up the abbreviation component to return `LongForm, Set[ShortForm]` tuples, which was the wrong way to go about it because mostly, people will want to manipulate the short forms of the abbreviations. This way works much better.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/118
https://github.com/allenai/scispacy/pull/119:7,deployability,api,api,7,Linker api;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/119
https://github.com/allenai/scispacy/pull/119:7,integrability,api,api,7,Linker api;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/119
https://github.com/allenai/scispacy/pull/119:7,interoperability,api,api,7,Linker api;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/119
https://github.com/allenai/scispacy/issues/120:488,availability,Error,Errors,488,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:193,deployability,modul,module,193,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:27,energy efficiency,model,model,27,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:214,energy efficiency,load,load,214,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:327,energy efficiency,load,load,327,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:547,energy efficiency,model,model,547,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:500,interoperability,format,format,500,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:193,modifiability,modul,module,193,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:286,modifiability,pac,packages,286,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:424,modifiability,pac,packages,424,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:619,modifiability,pac,package,619,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:214,performance,load,load,214,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:327,performance,load,load,327,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:488,performance,Error,Errors,488,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:574,reliability,doe,doesn,574,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:193,safety,modul,module,193,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:488,safety,Error,Errors,488,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:632,safety,valid,valid,632,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:27,security,model,model,27,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:547,security,model,model,547,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:488,usability,Error,Errors,488,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/issues/120:595,usability,shortcut,shortcut,595,"OSError: [E050] Can't find model 'en_core_sci_sm'; Hi,. I followed the steps here https://allenai.github.io/scispacy/ but when I try to run the example, it says. File ""example.py"", line 4, in <module>. nlp = spacy.load(""en_core_sci_sm""). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/__init__.py"", line 27, in load. return util.load_model(name, **overrides). File ""/home/darren/anaconda3/lib/python3.7/site-packages/spacy/util.py"", line 136, in load_model. raise IOError(Errors.E050.format(name=name)). OSError: [E050] Can't find model 'en_core_sci_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/120
https://github.com/allenai/scispacy/pull/122:0,deployability,Releas,Release,0,Release v0.2.1;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/122
https://github.com/allenai/scispacy/pull/123:0,deployability,Releas,Release,0,Release v0.2.2;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/123
https://github.com/allenai/scispacy/pull/124:36,integrability,compon,components,36,add examples and description of new components to readme;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/124
https://github.com/allenai/scispacy/pull/124:36,interoperability,compon,components,36,add examples and description of new components to readme;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/124
https://github.com/allenai/scispacy/pull/124:36,modifiability,compon,components,36,add examples and description of new components to readme;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/124
https://github.com/allenai/scispacy/issues/126:473,energy efficiency,model,model,473,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:570,energy efficiency,model,model,570,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:586,energy efficiency,model,model,586,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:657,energy efficiency,model,model,657,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:441,safety,test,test,441,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:626,safety,test,test,626,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:473,security,model,model,473,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:570,security,model,model,570,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:586,security,model,model,586,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:657,security,model,model,657,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:441,testability,test,test,441,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/issues/126:626,testability,test,test,626,"Do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset?; Thanks for developing nice and useful library. My question is , do both of 'en_core_sci_sm' and 'en_core_sci_md' use MedMentions all dataset? Because my task is related to MedMentions dataset itself, so I can only use MedMentions train dataset. If 'en_core_sci_sm' or 'en_core_sci_md' only used MedMentions train datasets, it's OK. But if datasets including dev/test data are used for training model, I can't use it because my task is related to datasets itself. Or, how can I retrain spacy model? If these model use MedMentions all(including dev/test) data, I'd like to create model all over again.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/126
https://github.com/allenai/scispacy/pull/127:94,integrability,abstract,abstracts,94,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:189,integrability,abstract,abstracts,189,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:279,integrability,abstract,abstracts,279,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:94,modifiability,abstract,abstracts,94,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:173,modifiability,exten,extended,173,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:189,modifiability,abstract,abstracts,189,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:263,modifiability,exten,extended,263,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/pull/127:279,modifiability,abstract,abstracts,279,Hyponym; Quick timing stats from running on MedMentions dev set:. Without hyponym pipe: 36.78 abstracts per second (23.874496698379517 seconds total). With hyponym pipe not extended: 35.12 abstracts per second (27.79159188270569 seconds total). With hyponym pipe extended: 31.59 abstracts per second (25.000983476638794 seconds total),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/127
https://github.com/allenai/scispacy/issues/128:676,deployability,version,version,676,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:696,deployability,Updat,Update,696,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:744,energy efficiency,model,model,744,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:676,integrability,version,version,676,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:676,modifiability,version,version,676,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:57,reliability,doe,doesn,57,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:13,safety,Detect,Detector,13,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:153,safety,test,test,153,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:696,safety,Updat,Update,696,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:704,safety,Test,Tested,704,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:13,security,Detect,Detector,13,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:696,security,Updat,Update,696,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:744,security,model,model,744,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:153,testability,test,test,153,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/issues/128:704,testability,Test,Tested,704,"Abbreviation Detector and UMLS Linker for en_core_sci_md doesn't return anything; I am using `en_core_sci_md` for `AbbreviationDetector` and ran a quick test using the same sentence in the `README.md` but no result is returned for the following code snippet:. ```. for abrv in doc._.abbreviations:. 	print(f""{abrv} \t ({abrv.start}, {abrv.end}) {abrv._.long_form}""). ```. Similarly, no result is returned for the UMLS entity linker:. ```. for umls_ent in entity._.umls_ents:. 	print(linker.umls.cui_to_entity[umls_ent[0]]). ```. I have followed all previous steps mentioned for both code snippets. Is this an issue with `en_core_web_md`? I thought that this was just a larger version of `_sm`. . Update: Tested both of the above with the `_sm` model, but results are only printed for the `AbbreviationDetector` and not for the UMLS entity linker.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/128
https://github.com/allenai/scispacy/pull/129:266,availability,avail,available,266,"Make use of all Concept Types; The 'type' field of MedMentions often includes several assignments, and you seem to have made the choice of only keeping the first type. The change I'm proposing creates additional entries ('entities') so that all type assignments are available for training, etc.. Quickly checking the difference in number of entities after this change, I'm seeing about 9% additional entities (in training set). Just getting started with MedMentions, don't know if there may be some reason to just keep the first type, but if there isn't, this change may be of interest.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/129
https://github.com/allenai/scispacy/pull/129:266,reliability,availab,available,266,"Make use of all Concept Types; The 'type' field of MedMentions often includes several assignments, and you seem to have made the choice of only keeping the first type. The change I'm proposing creates additional entries ('entities') so that all type assignments are available for training, etc.. Quickly checking the difference in number of entities after this change, I'm seeing about 9% additional entities (in training set). Just getting started with MedMentions, don't know if there may be some reason to just keep the first type, but if there isn't, this change may be of interest.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/129
https://github.com/allenai/scispacy/pull/129:266,safety,avail,available,266,"Make use of all Concept Types; The 'type' field of MedMentions often includes several assignments, and you seem to have made the choice of only keeping the first type. The change I'm proposing creates additional entries ('entities') so that all type assignments are available for training, etc.. Quickly checking the difference in number of entities after this change, I'm seeing about 9% additional entities (in training set). Just getting started with MedMentions, don't know if there may be some reason to just keep the first type, but if there isn't, this change may be of interest.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/129
https://github.com/allenai/scispacy/pull/129:266,security,availab,available,266,"Make use of all Concept Types; The 'type' field of MedMentions often includes several assignments, and you seem to have made the choice of only keeping the first type. The change I'm proposing creates additional entries ('entities') so that all type assignments are available for training, etc.. Quickly checking the difference in number of entities after this change, I'm seeing about 9% additional entities (in training set). Just getting started with MedMentions, don't know if there may be some reason to just keep the first type, but if there isn't, this change may be of interest.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/129
https://github.com/allenai/scispacy/issues/130:52,deployability,instal,installed,52,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:163,deployability,instal,install,163,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:228,deployability,instal,install,228,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:376,deployability,instal,installing,376,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:13,energy efficiency,model,models,13,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:111,energy efficiency,model,models,111,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:125,energy efficiency,load,loaded,125,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:257,energy efficiency,load,load,257,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:267,energy efficiency,model,models,267,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:361,energy efficiency,model,models,361,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:184,modifiability,pac,package,184,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:393,modifiability,pac,packages,393,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:125,performance,load,loaded,125,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:257,performance,load,load,257,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:13,security,model,models,13,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:111,security,model,models,111,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:267,security,model,models,267,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:361,security,model,models,361,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/issues/130:543,usability,learn,learn,543,Can scispacy models be used in spacy without having installed the additional requirements?; I noticed that the models can be loaded into spacy without the need to install the scispacy package and all its requirements (i.e. just install spacy on its own and load your models). Is there any problem with this? What do the other requirements do and can we use the models without installing these packages? > numpy. > spacy>=2.1.3. > pandas. > awscli. > conllu. > . > Candidate generation and entity linking. > joblib. > nmslib>=1.7.3.6. > scikit-learn>=0.20.3,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/130
https://github.com/allenai/scispacy/pull/131:16,deployability,depend,dependency,16,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/pull/131:31,energy efficiency,model,models,31,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/pull/131:16,integrability,depend,dependency,16,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/pull/131:16,modifiability,depend,dependency,16,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/pull/131:16,safety,depend,dependency,16,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/pull/131:31,security,model,models,31,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/pull/131:16,testability,depend,dependency,16,remove scispacy dependency for models; fixes #130,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/131
https://github.com/allenai/scispacy/issues/132:0,deployability,Updat,Update,0,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/issues/132:43,deployability,instal,install,43,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/issues/132:73,deployability,releas,release,73,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/issues/132:55,energy efficiency,model,models,55,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/issues/132:0,safety,Updat,Update,0,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/issues/132:0,security,Updat,Update,0,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/issues/132:55,security,model,models,55,Update readme/docs to not require scispacy install for models after next release;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/132
https://github.com/allenai/scispacy/pull/133:131,availability,down,down,131,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/pull/133:0,performance,memor,memory,0,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/pull/133:123,performance,memor,memory,123,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/pull/133:40,safety,Avoid,Avoid,40,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/pull/133:0,usability,memor,memory,0,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/pull/133:7,usability,efficien,efficient,7,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/pull/133:123,usability,memor,memory,123,memory efficient candidate generation ; Avoid converting from list to numpy.array and back. Now it takes less than 10GB of memory (down from 200GB),MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/133
https://github.com/allenai/scispacy/issues/134:621,deployability,stage,stage,621,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:0,performance,Perform,Performance,0,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:111,performance,perform,performance,111,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:321,performance,perform,performance,321,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:187,safety,detect,detector,187,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:311,safety,detect,detection,311,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:369,safety,test,test,369,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:187,security,detect,detector,187,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:311,security,detect,detection,311,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:369,testability,test,test,369,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:0,usability,Perform,Performance,0,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:111,usability,perform,performance,111,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/issues/134:321,usability,perform,performance,321,"Performance of (alpha) UMLS Linker on MedMentions ?; Hi,. Just wondering if you have any results regarding the performance of the alpha UMLS linker on MedMentions, using the mention span detector you trained for en_core_sci_*. Also, I see an F1 of 69.26 on https://allenai.github.io/scispacy/, this is the span detection performance of the latest en_core_sci_md on the test set for full data right (not st21pv) ? Is data from st21pv ever used? The MedMentions paper only reports results for TaggerOne with a very beefy setup (0.9TB RAM!), it'd be really useful to have another baseline using scispacy, even in this alpha stage. Thanks,. Dan",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/134
https://github.com/allenai/scispacy/pull/135:6,integrability,coupl,couple,6,Add a couple more biological abbreviations; Came across a couple abbreviations that were annoying me by breaking sentence splitting.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/135
https://github.com/allenai/scispacy/pull/135:58,integrability,coupl,couple,58,Add a couple more biological abbreviations; Came across a couple abbreviations that were annoying me by breaking sentence splitting.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/135
https://github.com/allenai/scispacy/pull/135:6,modifiability,coupl,couple,6,Add a couple more biological abbreviations; Came across a couple abbreviations that were annoying me by breaking sentence splitting.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/135
https://github.com/allenai/scispacy/pull/135:58,modifiability,coupl,couple,58,Add a couple more biological abbreviations; Came across a couple abbreviations that were annoying me by breaking sentence splitting.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/135
https://github.com/allenai/scispacy/pull/135:6,testability,coupl,couple,6,Add a couple more biological abbreviations; Came across a couple abbreviations that were annoying me by breaking sentence splitting.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/135
https://github.com/allenai/scispacy/pull/135:58,testability,coupl,couple,58,Add a couple more biological abbreviations; Came across a couple abbreviations that were annoying me by breaking sentence splitting.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/135
https://github.com/allenai/scispacy/issues/136:89,energy efficiency,model,model,89,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:174,performance,network,network,174,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:431,reliability,doe,does,431,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:156,safety,input,input,156,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:89,security,model,model,89,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:174,security,network,network,174,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:284,security,token,token,284,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:293,security,token,token,293,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:325,security,token,token,325,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:382,security,token,token,382,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:588,security,token,tokens,588,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:669,security,token,tokens,669,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:205,testability,coverag,coverage,205,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/136:156,usability,input,input,156,"`is_oov` in comparison to `in nlp.vocab`; I'm looking to use scispacy's `en_core_sci_md` model for various purposes, one being using its word vectors as an input to a neural network. As I was checking the coverage of the existing embedding, I noticed a weird phenomenon where a given token's `token.is_oov == True`, thought `token.text in nlp.vocab == True`. When this happens the `token.vector.sum() == 0`. I can't figure out how does this make sense, if it is in the vocabulary, how come it is oov and has an all zero vector? Also some basic words are missing, for example. ```python3. tokens = gather_all_tokens_from_corpus(). some_token = random.choice([t for t in tokens if t.is_oov]). print(some_token). >>> smelling. some_token.text in nlp.vocab. >>> True. some_token.vector. >>> array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,. 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32). ```. How come it is OOV yet returns `True` when checking `in nlp.vocab`? Is it expected that basic words like `smelling` won't have a vector?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/136
https://github.com/allenai/scispacy/issues/137:370,availability,Down,Downloading,370,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:905,availability,Down,Downloading,905,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1243,availability,Down,Downloading,1243,"8abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1775,availability,ERROR,ERROR,1775,"561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1838,availability,ERROR,ERROR,1838,"-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1845,availability,Down,Download,1845,"-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1854,availability,error,error,1854,"y.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_bu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2043,availability,Down,Download,2043,"macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. Fil",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2052,availability,error,error,2052,"0_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2206,availability,down,download,2206,"llecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3633,availability,error,errors,3633,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3767,availability,ERROR,ERROR,3767,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3821,availability,error,error,3821,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:4,deployability,instal,install,4,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:12,deployability,fail,fails,12,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:60,deployability,instal,install,60,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:144,deployability,instal,install,144,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2303,deployability,modul,module,2303,"199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. retu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2379,deployability,instal,install-,2379,"none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2428,deployability,modul,module,2428," Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3181,deployability,instal,installer,3181,"packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3309,deployability,instal,installer,3309,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3809,deployability,fail,failed,3809,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3898,deployability,instal,install-,3898,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3996,deployability,instal,install,3996,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:4039,deployability,instal,install,4039,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:4060,deployability,instal,install,4060,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:4179,deployability,updat,updated,4179,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3680,interoperability,distribut,distribution,3680,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:227,modifiability,pac,packages,227,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:413,modifiability,pac,packages,413,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:752,modifiability,pac,packages,752,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:948,modifiability,pac,packages,948,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1286,modifiability,pac,packages,1286,"b2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"",",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1476,modifiability,pac,packages,1476,"d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scis",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1678,modifiability,pac,packages,1678,"g joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1958,modifiability,pac,packages,1958,"/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resou",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2150,modifiability,pac,packages,2150," |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_matc",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2186,modifiability,pac,packages,2186,"34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2303,modifiability,modul,module,2303,"199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. retu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2428,modifiability,modul,module,2428," Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2504,modifiability,pac,packages,2504,"8aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2640,modifiability,pac,packages,2640,"ed https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.Dist",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2806,modifiability,pac,packages,2806," python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" f",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2944,modifiability,pac,packages,2944,"n -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jat",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3094,modifiability,pac,packages,3094,"odename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3243,modifiability,pac,packages,3243,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3383,modifiability,pac,packages,3383,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3523,modifiability,pac,packages,3523,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:189,performance,cach,cached,189,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:714,performance,cach,cached,714,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1438,performance,cach,cached,1438,"e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1640,performance,cach,cached,1640,"███████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-pac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1775,performance,ERROR,ERROR,1775,"561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1838,performance,ERROR,ERROR,1838,"-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1854,performance,error,error,1854,"y.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_bu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2052,performance,error,error,2052,"0_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3633,performance,error,errors,3633,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3767,performance,ERROR,ERROR,3767,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3821,performance,error,error,3821,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:12,reliability,fail,fails,12,"pip install fails; I've created the conda env, and ran `pip install scispacy` see the result: . . ```. (scispacy) lucas-mbp:jats lfoppiano$ pip install scispacy. Collecting scispacy. Using cached https://files.pythonhosted.org/packages/72/55/30b30a78abafaaf34d0d8368a090cf713964d6c97c5e912fb2016efadab0/scispacy-0.2.2-py3-none-any.whl. Collecting numpy (from scispacy). Downloading https://files.pythonhosted.org/packages/0f/c9/3526a357b6c35e5529158fbcfac1bb3adc8827e8809a6d254019d326d1cc/numpy-1.16.4-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.9MB). |████████████████████████████████| 13.9MB 3.5MB/s . Collecting joblib (from scispacy). Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find i",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3809,reliability,fail,failed,3809,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1775,safety,ERROR,ERROR,1775,"561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1782,safety,Compl,Complete,1782,"87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1838,safety,ERROR,ERROR,1838,"-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1854,safety,error,error,1854,"y.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_bu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2052,safety,error,error,2052,"0_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2303,safety,modul,module,2303,"199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. retu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2428,safety,modul,module,2428," Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3633,safety,error,errors,3633,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3767,safety,ERROR,ERROR,3767,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3821,safety,error,error,3821,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:4179,safety,updat,updated,4179,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1782,security,Compl,Complete,1782,"87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:4179,security,updat,updated,4179,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1880,testability,simpl,simple,1880,".1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflict",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2078,testability,simpl,simple,2078,"l.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/py",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2238,testability,Trace,Traceback,2238,"Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1775,usability,ERROR,ERROR,1775,"561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1803,usability,command,command,1803,"15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-p",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1838,usability,ERROR,ERROR,1838,"-py2.py3-none-any.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1854,usability,error,error,1854,"y.whl. Collecting spacy>=2.1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_bu",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:1880,usability,simpl,simple,1880,".1.3 (from scispacy). Downloading https://files.pythonhosted.org/packages/cb/ef/cccdeb1ababb2cb04ae464098183bcd300b8f7e4979ce309669de8a56b9d/spacy-2.1.6-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflict",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2052,usability,error,error,2052,"0_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anac",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:2078,usability,simpl,simple,2078,"l.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (34.6MB). |████████████████████████████████| 34.6MB 33.6MB/s . Collecting conllu (from scispacy). Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl. Collecting awscli (from scispacy). Using cached https://files.pythonhosted.org/packages/e6/48/8c5ac563a88239d128aa3fb67415211c19bd653fab01c7f11cecf015c343/awscli-1.16.203-py2.py3-none-any.whl. Collecting nmslib>=1.7.3.6 (from scispacy). Using cached https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz. ERROR: Complete output from command python setup.py egg_info:. ERROR: Download error on https://pypi.org/simple/numpy/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! Couldn't find index page for 'numpy' (maybe misspelled?). Download error on https://pypi.org/simple/: [Errno 8] nodename nor servname provided, or not known -- Some packages may not be found! No local packages or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/py",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3543,usability,command,command,3543,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3633,usability,error,errors,3633,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3767,usability,ERROR,ERROR,3767,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3774,usability,Command,Command,3774,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/137:3821,usability,error,error,3821,"or working download links found for numpy. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/setup.py"", line 172, in <module>. zip_safe=False,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 144, in setup. _install_setup_requires(attrs). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires. dist.fetch_build_eggs(dist.setup_requires). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 717, in fetch_build_eggs. replace_conflicting=True,. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 782, in resolve. replace_conflicting=replace_conflicting. File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1065, in best_match. return self.obtain(req, installer). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1077, in obtain. return installer(requirement). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/dist.py"", line 784, in fetch_build_egg. return cmd.easy_install(req). File ""/anaconda3/envs/scispacy/lib/python3.6/site-packages/setuptools/command/easy_install.py"", line 673, in easy_install. raise DistutilsError(msg). distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('numpy'). ----------------------------------------. ERROR: Command ""python setup.py egg_info"" failed with error code 1 in /private/var/folders/mk/scd8428n18jfgh3jdthbvpz00000gn/T/pip-install-l00jm4xn/nmslib/. (scispacy) lucas-mbp:jats lfoppiano$ . ```. To solve the issue I had to install `numpy` and `nmslib`: . ```. conda install numpy. conda install -c akode nmslib. ```. It seems to work, but maybe is not the proper way to solve it - the pip script should be updated perhaps?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/137
https://github.com/allenai/scispacy/issues/138:360,availability,slo,slow,360,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:369,deployability,resourc,resource,369,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:369,energy efficiency,resourc,resource,369,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:369,performance,resourc,resource,369,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:360,reliability,slo,slow,360,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:369,safety,resourc,resource,369,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:169,security,token,tokens,169,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:369,testability,resourc,resource,369,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:0,usability,Efficien,Efficient,0,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:54,usability,Document,Documents,54,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:105,usability,efficien,efficiently,105,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:186,usability,document,documents,186,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/138:285,usability,document,documentation,285,Efficient Computation of Similarity Matrix for Set of Documents? ; Do you have any suggestions on how to efficiently compute the pairwise similarity over a large set of tokens/sentences/documents using the scispacy en_core_sci_md vectors? I'm finding the method suggested by the spacy documentation ((https://spacy.io/usage/vectors-similarity) to be extremely slow and resource intensive.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/138
https://github.com/allenai/scispacy/issues/139:19,security,token,tokens,19,most/least similar tokens (like gensim)?; Is there some way to return the n most/least similar tokens to a given token in the en_core_sci_md vocabulary? In gensim the most_similar method allows you to do this.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/139
https://github.com/allenai/scispacy/issues/139:95,security,token,tokens,95,most/least similar tokens (like gensim)?; Is there some way to return the n most/least similar tokens to a given token in the en_core_sci_md vocabulary? In gensim the most_similar method allows you to do this.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/139
https://github.com/allenai/scispacy/issues/139:113,security,token,token,113,most/least similar tokens (like gensim)?; Is there some way to return the n most/least similar tokens to a given token in the en_core_sci_md vocabulary? In gensim the most_similar method allows you to do this.,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/139
https://github.com/allenai/scispacy/issues/140:134,availability,down,downloaded,134,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:160,deployability,releas,released,160,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:243,deployability,releas,released,243,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:169,energy efficiency,model,models,169,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:388,energy efficiency,model,models,388,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:277,safety,test,test,277,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:169,security,model,models,169,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:292,security,modif,modified,292,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:388,security,model,models,388,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:277,testability,test,test,277,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/140:934,usability,help,help,934,"Can not reproduce tagging and parsing results; Hello, . I'm trying to reproduce tagging and parsing results using the GENIA corpus. I downloaded the officially released models (`en_core_sci_sm-0.2.0` and `en_core_sci_md-0.2.0`) and officially released GENIA corpus (`train/dev/test.json`). I modified the scripts `parser.sh` and `train_parser_and_tagger.py`, and use them to evaluate the models. However, there seems to be large differences between the results reported in the paper, reported in the github repo and my reproduced result. - Paper: . - en_core_sci_sm: 98.38 89.69 87.67. - en_core_sci_md: 98.51 90.60 88.79. - Github Repo `docs/index.md`:. - en_core_sci_sm: 98.42 89.47 87.61 . - en_core_sci_md: 98.61 89.94 88.08. - My reproduced result:. - en_core_sci_sm: 98.42 89.47 84.04 . - en_core_sci_md: 98.61 89.94 84.37. The numbers are POS, UAS, LAS, respectively. Could you please check your results? Thanks a lot for your help! Sincerely,. Yuhui.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/140
https://github.com/allenai/scispacy/issues/141:451,energy efficiency,model,models,451,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:586,reliability,doe,does,586,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:451,security,model,models,451,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:222,testability,simpl,simply,222,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:7,usability,visual,visualize,7,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:35,usability,custom,custom,35,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:103,usability,custom,custom,103,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:134,usability,visual,visualization,134,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/141:222,usability,simpl,simply,222,"How to visualize named entities in custom colors; There's an `options` in Spacy which allows us to use custom colors for named entity visualization. I'm trying to use the same options in scispacy for the named entities. I simply created two lists of `entities` and randomly generated `colors` and put them in `options` dictionary like the following:. `options = {""ents"": entities, ""colors"": colors}`. Where `entities` is a list of NEs in scispacy NER models and `colors` is a list of the same size. But using such an option in either `displacy.serve` or `displacy.render (for jupyter)` does not work. I'm using the options like the following:. `displacy.serve(doc, style=""ent"", options=options)`. I wonder if using the color option only works for predefined named entities in the Spacy or there's something wrong with the way I'm using the option?",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/141
https://github.com/allenai/scispacy/issues/142:106,availability,robust,robustness,106,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:11,deployability,depend,dependency,11,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:124,deployability,depend,dependency,124,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:11,integrability,depend,dependency,11,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:124,integrability,depend,dependency,124,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:11,modifiability,depend,dependency,11,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:124,modifiability,depend,dependency,124,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:106,reliability,robust,robustness,106,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:11,safety,depend,dependency,11,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:106,safety,robust,robustness,106,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:124,safety,depend,dependency,124,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:11,testability,depend,dependency,11,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/142:124,testability,depend,dependency,124,"How to get dependency parse annotation from OntoNotes 5.0 corpus?; As mention in paper:. `To increase the robustness of the dependency parser and POS tagger to generic text,. we make use of the OntoNotes 5.0 corpus`. I can only find the Constituency parse annotation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/142
https://github.com/allenai/scispacy/issues/143:182,availability,avail,available,182,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:65,deployability,build,building,65,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:182,reliability,availab,available,182,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:182,safety,avail,available,182,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:269,safety,compl,complete,269,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:44,security,team,team,44,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:182,security,availab,available,182,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:269,security,compl,complete,269,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:128,usability,help,helpful,128,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:195,usability,learn,learn,195,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/143:288,usability,document,documentation,288,"More Tutorials for SciSpacy; Hello SciSpacy team,. Thank you for building sci-spacy. I just wanted to say that it would be very helpful if there were more examples/jupyter notebooks available to learn diverse use cases of sci-spacy. Please let me know where can I find complete sci-spacy documentation.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/143
https://github.com/allenai/scispacy/issues/144:503,availability,Error,Errors,503,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:655,availability,Error,Errors,655,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:280,deployability,modul,module,280,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:2170,energy efficiency,estimat,estimator,2170," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:522,integrability,compon,component,522,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1239,integrability,transform,transform,1239,"ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.s",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1404,integrability,transform,transform,1404,"f, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1466,integrability,transform,transform,1466," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1519,integrability,transform,transform,1519," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1671,integrability,transform,transform,1671," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:515,interoperability,format,format,515,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:522,interoperability,compon,component,522,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:667,interoperability,format,format,667,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1239,interoperability,transform,transform,1239,"ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.s",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1404,interoperability,transform,transform,1404,"f, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1466,interoperability,transform,transform,1466," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1519,interoperability,transform,transform,1519," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1671,interoperability,transform,transform,1671," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:280,modifiability,modul,module,280,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:367,modifiability,pac,packages,367,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:522,modifiability,compon,component,522,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:731,modifiability,pac,packages,731,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1034,modifiability,pac,packages,1034," team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, acce",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1357,modifiability,pac,packages,1357,"/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1624,modifiability,pac,packages,1624," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1960,modifiability,pac,packages,1960," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:503,performance,Error,Errors,503,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:655,performance,Error,Errors,655,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:252,safety,input,input-,252,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:280,safety,modul,module,280,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:503,safety,Error,Errors,503,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:655,safety,Error,Errors,655,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1983,safety,valid,validation,1983," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:39,security,team,team,39,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:73,security,hack,hackathon,73,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:1983,security,validat,validation,1983," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:208,testability,Trace,Traceback,208,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:2279,testability,context,context,2279," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:252,usability,input,input-,252,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:503,usability,Error,Errors,503,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:655,usability,Error,Errors,655,"`Found array with 0 sample(s)`; Lucy's team ran into this bug during the hackathon . ```. >>> nlp(""hydroxytryptophan""). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-231-7e41c1b0131c> in <module>. ----> 1 nlp(""hydroxytryptophan""). //anaconda/envs/scispacy/lib/python3.6/site-packages/spacy/language.py in __call__(self, text, disable, component_cfg). 393 if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in ",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:2188,usability,minim,minimum,2188," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/issues/144:2417,usability,minim,minimum,2417," if not hasattr(proc, ""__call__""):. 394 raise ValueError(Errors.E003.format(component=type(proc), name=name)). --> 395 doc = proc(doc, **component_cfg.get(name, {})). 396 if doc is None:. 397 raise ValueError(Errors.E005.format(name=name)). //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/umls_linking.py in __call__(self, doc). 85 . 86 mention_strings = [x.text for x in mentions]. ---> 87 batch_candidates = self.candidate_generator(mention_strings, self.k). 88 . 89 for mention, candidates in zip(doc.ents, batch_candidates):. //anaconda/envs/scispacy/lib/python3.6/site-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 201 if self.verbose:. 202 print(f'Generating candidates for {len(mention_texts)} mentions'). --> 203 tfidfs = self.vectorizer.transform(mention_texts). 204 start_time = datetime.datetime.now(). 205 . //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, raw_documents, copy). 1679 . 1680 X = super().transform(raw_documents). -> 1681 return self._tfidf.transform(X, copy=False). 1682 . 1683 def _more_tags(self):. //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in transform(self, X, copy). 1300 vectors : sparse matrix, [n_samples, n_features]. 1301 """""". -> 1302 X = check_array(X, accept_sparse='csr', dtype=FLOAT_DTYPES, copy=copy). 1303 if not sp.issparse(X):. 1304 X = sp.csr_matrix(X, dtype=np.float64). //anaconda/envs/scispacy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 548 "" minimum of %d is required%s."". 549 % (n_samples, array.shape, ensure_min_samples,. --> 550 context)). 551 . 552 if ensure_min_features > 0 and array.ndim == 2:. ValueError: Found array with 0 sample(s) (shape=(0, 53479)) while a minimum of 1 is required. ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/144
https://github.com/allenai/scispacy/pull/146:28,energy efficiency,optim,optimizers,28,"disable pipes when creating optimizers; Fixes #140 . The issue was that we were not disabling the other pipes when we called `nlp.begin_training()` so the parser pipe was getting `begin_training` called on it. It is possible that we don't need to call `begin_training` at all when we are starting from an existing model (see https://github.com/explosion/spaCy/blob/04113a844d9042f04c1fa0bc5830f11355b9b526/spacy/cli/train.py#L208-L213), but this seems to fix the problem. EDIT: Trained without ontonotes mixed in. The results of `spacy evaluate` on genia dev are:. POS 98.62. UAS 89.13. LAS 87.56. and the results of `train_ner --run_test` on med mentions dev are:. precision-untyped: 0.6776682259805685. recall-untyped: 0.6628886010362695. f1-measure-untyped: 0.6701969409034441.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/146
https://github.com/allenai/scispacy/pull/146:314,energy efficiency,model,model,314,"disable pipes when creating optimizers; Fixes #140 . The issue was that we were not disabling the other pipes when we called `nlp.begin_training()` so the parser pipe was getting `begin_training` called on it. It is possible that we don't need to call `begin_training` at all when we are starting from an existing model (see https://github.com/explosion/spaCy/blob/04113a844d9042f04c1fa0bc5830f11355b9b526/spacy/cli/train.py#L208-L213), but this seems to fix the problem. EDIT: Trained without ontonotes mixed in. The results of `spacy evaluate` on genia dev are:. POS 98.62. UAS 89.13. LAS 87.56. and the results of `train_ner --run_test` on med mentions dev are:. precision-untyped: 0.6776682259805685. recall-untyped: 0.6628886010362695. f1-measure-untyped: 0.6701969409034441.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/146
https://github.com/allenai/scispacy/pull/146:744,energy efficiency,measur,measure-untyped,744,"disable pipes when creating optimizers; Fixes #140 . The issue was that we were not disabling the other pipes when we called `nlp.begin_training()` so the parser pipe was getting `begin_training` called on it. It is possible that we don't need to call `begin_training` at all when we are starting from an existing model (see https://github.com/explosion/spaCy/blob/04113a844d9042f04c1fa0bc5830f11355b9b526/spacy/cli/train.py#L208-L213), but this seems to fix the problem. EDIT: Trained without ontonotes mixed in. The results of `spacy evaluate` on genia dev are:. POS 98.62. UAS 89.13. LAS 87.56. and the results of `train_ner --run_test` on med mentions dev are:. precision-untyped: 0.6776682259805685. recall-untyped: 0.6628886010362695. f1-measure-untyped: 0.6701969409034441.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/146
https://github.com/allenai/scispacy/pull/146:28,performance,optimiz,optimizers,28,"disable pipes when creating optimizers; Fixes #140 . The issue was that we were not disabling the other pipes when we called `nlp.begin_training()` so the parser pipe was getting `begin_training` called on it. It is possible that we don't need to call `begin_training` at all when we are starting from an existing model (see https://github.com/explosion/spaCy/blob/04113a844d9042f04c1fa0bc5830f11355b9b526/spacy/cli/train.py#L208-L213), but this seems to fix the problem. EDIT: Trained without ontonotes mixed in. The results of `spacy evaluate` on genia dev are:. POS 98.62. UAS 89.13. LAS 87.56. and the results of `train_ner --run_test` on med mentions dev are:. precision-untyped: 0.6776682259805685. recall-untyped: 0.6628886010362695. f1-measure-untyped: 0.6701969409034441.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/146
https://github.com/allenai/scispacy/pull/146:314,security,model,model,314,"disable pipes when creating optimizers; Fixes #140 . The issue was that we were not disabling the other pipes when we called `nlp.begin_training()` so the parser pipe was getting `begin_training` called on it. It is possible that we don't need to call `begin_training` at all when we are starting from an existing model (see https://github.com/explosion/spaCy/blob/04113a844d9042f04c1fa0bc5830f11355b9b526/spacy/cli/train.py#L208-L213), but this seems to fix the problem. EDIT: Trained without ontonotes mixed in. The results of `spacy evaluate` on genia dev are:. POS 98.62. UAS 89.13. LAS 87.56. and the results of `train_ner --run_test` on med mentions dev are:. precision-untyped: 0.6776682259805685. recall-untyped: 0.6628886010362695. f1-measure-untyped: 0.6701969409034441.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/146
https://github.com/allenai/scispacy/pull/147:107,performance,perform,performing,107,"Add resolve abbreviations to readme; @lucylw asked me if it was possible to resolve abbreviations prior to performing linking to prevent creating spurious candidates for acronyms. Since this feature already exists, I thought we should document it.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/147
https://github.com/allenai/scispacy/pull/147:129,safety,prevent,prevent,129,"Add resolve abbreviations to readme; @lucylw asked me if it was possible to resolve abbreviations prior to performing linking to prevent creating spurious candidates for acronyms. Since this feature already exists, I thought we should document it.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/147
https://github.com/allenai/scispacy/pull/147:129,security,preven,prevent,129,"Add resolve abbreviations to readme; @lucylw asked me if it was possible to resolve abbreviations prior to performing linking to prevent creating spurious candidates for acronyms. Since this feature already exists, I thought we should document it.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/147
https://github.com/allenai/scispacy/pull/147:107,usability,perform,performing,107,"Add resolve abbreviations to readme; @lucylw asked me if it was possible to resolve abbreviations prior to performing linking to prevent creating spurious candidates for acronyms. Since this feature already exists, I thought we should document it.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/147
https://github.com/allenai/scispacy/pull/147:235,usability,document,document,235,"Add resolve abbreviations to readme; @lucylw asked me if it was possible to resolve abbreviations prior to performing linking to prevent creating spurious candidates for acronyms. Since this feature already exists, I thought we should document it.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/147
https://github.com/allenai/scispacy/issues/149:507,deployability,pipelin,pipeline,507,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:895,deployability,pipelin,pipeline,895,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:30,energy efficiency,load,loaded,30,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:238,energy efficiency,load,load,238,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:339,energy efficiency,load,load,339,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:680,energy efficiency,load,load,680,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:507,integrability,pipelin,pipeline,507,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:895,integrability,pipelin,pipeline,895,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:30,performance,load,loaded,30,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:238,performance,load,load,238,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:339,performance,load,load,339,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:680,performance,load,load,680,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:286,reliability,doe,does,286,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:546,reliability,doe,does,546,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:66,usability,command,commands,66,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/149:226,usability,command,commands,226,"Sentence segmenter can not be loaded; Hello,. I ran the following commands to train the parser:. ```sh. bash ./scripts/base_model.sh small base_model. bash ./scripts/parser.sh base_model parser. ```. When I used the following commands to load the trained parser, the sentence segmenter does not work:. ```python. import spacy. nlp = spacy.load('parser/best'). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. However, when I followed the code and added the segmenter to the pipeline, the sentense segmenter still does not work:. ```python. import spacy. from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter. nlp = spacy.load('parser/best'). nlp.add_pipe(combined_rule_sentence_segmenter, first=True). x = nlp('Hello. Hello.'). print(len(list(x.sents)) # Output: 1, Expected: 2. ```. What should I do to add the sentence segmenter into pipeline? . Thanks!",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/149
https://github.com/allenai/scispacy/issues/150:426,reliability,doe,does,426,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:41,safety,test,test,41,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:248,safety,detect,detector,248,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:598,safety,detect,detector,598,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:248,security,detect,detector,248,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:267,security,ident,identifies,267,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:598,security,detect,detector,598,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:41,testability,test,test,41,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:537,usability,document,document,537,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1008,usability,document,document-level,1008,"Abbreviations and UMLS linking; Here's a test sentence:. Human induced pluripotent stem cells (hiPSC) are generated from reprogrammed fibroblasts by overexpression of pluripotency factors (Takahashi et al., 2007; Yu et al., 2007). The abbreviation detector correctly identifies hiPSC and ""Human induced pluripotent stem cells"". Also, ""Human induced pluripotent stem cells"" is in UMLS as CUI C3658289. However, the UMLS linker does not find that code. Instead of the long form of the abbreviation being used (which is associated with the document), the linker is using the entities from the mention detector. In this case it had found the mentions (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors, Takahashi). . The result is that the abbreviation hiPSC gets candidate codes C2717959 and C0872076, which are for 'Induced Pluripotent Stem Cells' and 'Pluripotent Stem Cells', respectively. It may be good to have an early step in the UMLS linker that looks for document-level abbreviations. If it finds some then exclude those spans from consideration when looking for non-abbreviated mentions. (Or maybe let people ask for nested concepts, in which case the abbreviation spans would not be excluded).",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/151:20,integrability,filter,filtering,20,"Override definition filtering for exact match; Entity linker defaults to filtering out entities that don't have definitions in UMLS, we should at least override this filtering when a mention is an exact match for a UMLS entity.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/151
https://github.com/allenai/scispacy/issues/151:73,integrability,filter,filtering,73,"Override definition filtering for exact match; Entity linker defaults to filtering out entities that don't have definitions in UMLS, we should at least override this filtering when a mention is an exact match for a UMLS entity.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/151
https://github.com/allenai/scispacy/issues/151:166,integrability,filter,filtering,166,"Override definition filtering for exact match; Entity linker defaults to filtering out entities that don't have definitions in UMLS, we should at least override this filtering when a mention is an exact match for a UMLS entity.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/151
https://github.com/allenai/scispacy/issues/152:45,safety,detect,detector,45,"Merging abbreviation long forms; The mention detector might break up an abbreviation long form into multiple mentions, as described in #150. We may want to think about merging the long forms into single mentions since we know with very high probability that the long form should be one entity.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/152
https://github.com/allenai/scispacy/issues/152:45,security,detect,detector,45,"Merging abbreviation long forms; The mention detector might break up an abbreviation long form into multiple mentions, as described in #150. We may want to think about merging the long forms into single mentions since we know with very high probability that the long form should be one entity.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/152
https://github.com/allenai/scispacy/pull/154:17,deployability,pipelin,pipeline,17,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:56,deployability,updat,updated,56,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:185,deployability,updat,updating,185,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:6,energy efficiency,model,model,6,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:42,energy efficiency,model,model,42,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:203,energy efficiency,model,models,203,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:288,energy efficiency,model,models,288,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:17,integrability,pipelin,pipeline,17,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:117,integrability,sub,subset,117,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:56,safety,updat,updated,56,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:185,safety,updat,updating,185,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:6,security,model,model,6,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:42,security,model,model,42,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:56,security,updat,updated,56,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:185,security,updat,updating,185,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:203,security,model,models,203,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:288,security,model,models,288,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/154:221,usability,minim,minimum,221,"Large model; Add pipeline stuff for large model. Also I updated the freq statistics to be calculated based on a 36GB subset of gorc, which is much larger than previously. This required updating the base models to use new minimum word freq stats so as not to be massively large. . The new models will have:. `en_core_sci_lg`: Vocab = 785k, vectors=600k, 600mb. `en_core_sci_md`: Vocab = 363k, vectors=50k, 96mb. `en_core_sci_sm`: Vocab = 100k, vectors=0k, 12mb.",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/154
https://github.com/allenai/scispacy/pull/156:0,deployability,Releas,Release,0,Release v0.2.3; Update docs and readme for new release,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/156
https://github.com/allenai/scispacy/pull/156:16,deployability,Updat,Update,16,Release v0.2.3; Update docs and readme for new release,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/156
https://github.com/allenai/scispacy/pull/156:47,deployability,releas,release,47,Release v0.2.3; Update docs and readme for new release,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/156
https://github.com/allenai/scispacy/pull/156:16,safety,Updat,Update,16,Release v0.2.3; Update docs and readme for new release,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/156
https://github.com/allenai/scispacy/pull/156:16,security,Updat,Update,16,Release v0.2.3; Update docs and readme for new release,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/156
https://github.com/allenai/scispacy/pull/157:18,energy efficiency,model,model,18,fix link to large model;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/157
https://github.com/allenai/scispacy/pull/157:18,security,model,model,18,fix link to large model;,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/157
https://github.com/allenai/scispacy/issues/158:67,deployability,modul,module,67,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:108,deployability,observ,observations,108,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:779,deployability,observ,observations,779,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:218,energy efficiency,reduc,reductions,218,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:658,energy efficiency,load,load,658,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:894,energy efficiency,reduc,reductions,894,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:67,modifiability,modul,module,67,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:658,performance,load,load,658,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:67,safety,modul,module,67,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:108,testability,observ,observations,108,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/158:779,testability,observ,observations,779,"Abbreviations confused by (citation)s; Hi,. Using the abbreviation module I processed the sentence ""The PVO observations showed that the total transterminator flux was 23% of that at solar maximum and that the largest reductions in the number of ions transported antisunward occurred at the highest altitudes (Spenner et al., 1995)"". Printing the abbreviations and the long forms, it produced:. highest altitudes 	 Spenner et al., 1995. So, citations that use '(' are throwing it off. . Code follows. ```. # Problem - Confuses a citation for an abbreviation. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). text1 = ""The PVO observations showed that the total transterminator flux ""\. ""was 23% of that at solar maximum and that the largest reductions in the ""\. ""number of ions transported antisunward occurred at the highest altitudes ""\. ""(Spenner et al., 1995)."". # Process the text and print the abbreviations. doc = nlp(text1). for abrv in doc._.abbreviations:. print(abrv, ""\t"", abrv._.long_form). ```",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/158
https://github.com/allenai/scispacy/issues/161:586,energy efficiency,optim,optimal,586,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:679,energy efficiency,optim,optimal,679,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:860,integrability,repositor,repositories,860,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:942,integrability,repositor,repositories,942,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:959,integrability,repositor,repositories,959,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1083,integrability,repositor,repository,1083,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1095,integrability,repositor,repository,1095,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1106,integrability,discover,discovery,1106,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1125,integrability,repositor,repository,1125,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1136,integrability,discover,discovery,1136,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1150,integrability,repositor,repositories,1150,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1274,integrability,repositor,repository,1274,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:860,interoperability,repositor,repositories,860,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:942,interoperability,repositor,repositories,942,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:959,interoperability,repositor,repositories,959,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1083,interoperability,repositor,repository,1083,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1095,interoperability,repositor,repository,1095,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1106,interoperability,discover,discovery,1106,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1125,interoperability,repositor,repository,1125,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1136,interoperability,discover,discovery,1136,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1150,interoperability,repositor,repositories,1150,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1274,interoperability,repositor,repository,1274,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:109,safety,detect,detector,109,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:109,security,detect,detector,109,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:594,security,control,control,594,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:687,security,control,control,687,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:594,testability,control,control,594,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:687,testability,control,control,687,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:835,usability,User,Users,835,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:917,usability,User,Users,917,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1072,usability,user,users,1072,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1106,usability,discov,discovery,1106,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1136,usability,discov,discovery,1136,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/issues/161:1263,usability,user,users,1263,"Special cases in abbreviation algorithm; There seem to be some low hanging fruit for making the abbreviation detector work better on paper body text. Storing examples here in case we want to make some easy fixes at some point:. ```. (text --- short form --- long form). (""H2)]+(14)s.t. (1), (4).Similarly"" --- 1 --- H2)]+(14)s.t.). ("".(21)In (21), λ"" --- 21 --- .(21)In). (""map expX (·) : R"" --- . --- map expX). (""0,(3)with the following data: (3-i) (q̄"" --- 3-i --- 0,(3)with the following data:). ( ""Φg(h),ThΦg(v) ) , (h, v)"" --- h, v --- Φg(h),ThΦg(v) ) ,). (""dimension;(S-iii) The optimal control problem obtained in (S-ii) is con-verted"" --- S-ii --- dimension;(S-iii) The optimal control problem obtained in). (""z), πut (z)) )"" --- z) --- z), πut). (""is equivalent to (iv) of Theorem"" --- iv --- is equivalent to). (""or to fork.Users work more on their repositories (owners) than on"" --- owners --- or to fork.Users work more on their repositories). (""repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository (repository discovery) is"" --- repository discovery --- repositories he/she already worked with or from previous collaborators. Nevertheless, 88% of the first action of users to a repository). ```. and so on and so forth",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/161
https://github.com/allenai/scispacy/pull/162:24,availability,down,download,24,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/162:0,deployability,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/162:0,safety,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/162:0,security,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/163:24,availability,down,download,24,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/163
https://github.com/allenai/scispacy/pull/163:0,deployability,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/163
https://github.com/allenai/scispacy/pull/163:0,safety,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/163
https://github.com/allenai/scispacy/pull/163:0,security,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/163
https://github.com/allenai/scispacy/pull/164:24,availability,down,download,24,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/164
https://github.com/allenai/scispacy/pull/164:0,deployability,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/164
https://github.com/allenai/scispacy/pull/164:0,safety,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/164
https://github.com/allenai/scispacy/pull/164:0,security,Updat,Update,0,Update README.md; Conda download link was broken,MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/164
https://github.com/allenai/scispacy/issues/165:290,availability,error,error,290,"Import UmlsEntityLinker fails due to nmslib; I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. However, when I try to import UmlsEntityLinker, I get the following error: . `ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE. `. Trace is the following: . `from scispacy.umls_linking import UmlsEntityLinker` -> `from scispacy.candidate_generation import CandidateGenerator` -> `import nmslib`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:24,deployability,fail,fails,24,"Import UmlsEntityLinker fails due to nmslib; I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. However, when I try to import UmlsEntityLinker, I get the following error: . `ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE. `. Trace is the following: . `from scispacy.umls_linking import UmlsEntityLinker` -> `from scispacy.candidate_generation import CandidateGenerator` -> `import nmslib`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:59,deployability,instal,install,59,"Import UmlsEntityLinker fails due to nmslib; I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. However, when I try to import UmlsEntityLinker, I get the following error: . `ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE. `. Trace is the following: . `from scispacy.umls_linking import UmlsEntityLinker` -> `from scispacy.candidate_generation import CandidateGenerator` -> `import nmslib`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:135,integrability,Sub,Subsequently,135,"Import UmlsEntityLinker fails due to nmslib; I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. However, when I try to import UmlsEntityLinker, I get the following error: . `ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE. `. Trace is the following: . `from scispacy.umls_linking import UmlsEntityLinker` -> `from scispacy.candidate_generation import CandidateGenerator` -> `import nmslib`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:356,modifiability,pac,packages,356,"Import UmlsEntityLinker fails due to nmslib; I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. However, when I try to import UmlsEntityLinker, I get the following error: . `ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE. `. Trace is the following: . `from scispacy.umls_linking import UmlsEntityLinker` -> `from scispacy.candidate_generation import CandidateGenerator` -> `import nmslib`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:290,performance,error,error,290,"Import UmlsEntityLinker fails due to nmslib; I used pip to install scispacy into my conda environment and exported that to a yml file. Subsequently, I created this conda environment in another machine using this yml file. However, when I try to import UmlsEntityLinker, I get the following error: . `ImportError: /envs/<conda_directory>/lib/python3.6/site-packages/nmslib.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZTINSt6thread6_StateE. `. Trace is the following: . `from scispacy.umls_linking import UmlsEntityLinker` -> `from scispacy.candidate_generation import CandidateGenerator` -> `import nmslib`",MatchSource.ISSUE,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
