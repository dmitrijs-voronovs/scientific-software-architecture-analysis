id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1941:107,usability,confirm,confirmed,107,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:190,usability,confirm,confirmed,190,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:761,usability,Error,Error,761,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:904,usability,input,input-,904,"can't plot filtered DEGs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:. ```. #use this. sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). ```. Error:. ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-16-30381f660d76> in <module>. 1 #use this. ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True). 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)). 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 659 tl.dendrogram. 660 """""". --> 661 return _rank_genes_groups_plot(. 662 adata,. 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 578 from .._anndata import heatmap. 579 . --> 580 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/pull/1942:32,integrability,filter,filtered,32,Fix _rank_genes_groups_plot for filtered genes; https://github.com/theislab/scanpy/issues/1941,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1942
https://github.com/scverse/scanpy/issues/1944:535,availability,cluster,cluster,535,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:572,availability,cluster,cluster,572,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:535,deployability,cluster,cluster,535,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:572,deployability,cluster,cluster,572,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:186,integrability,sub,subsequent,186,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:303,integrability,sub,subsequent,303,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:1254,performance,Memor,Memory,1254,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:86,reliability,doe,doesn,86,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:1399,safety,compl,completely,1399,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:197,security,modif,modifications,197,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:1399,security,compl,completely,1399,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:1254,usability,Memor,Memory,1254,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1944:1459,usability,guid,guided,1459,"unable to recapitulate dendrogram leaf labels with ivl; the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```. import numpy as np. import pandas as pd. import scanpy as sc. from scipy.cluster import hierarchy. from scipy.cluster.hierarchy import dendrogram, linkage. import matplotlib.pyplot as plt. # import adata. adata = sc.datasets.pbmc68k_reduced(). sc.pp.normalize_total(adata, target_sum = 1e4). sc.pp.log1p(adata). groupCat = ""bulk_labels"". sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat. Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram. sc.pl.dendrogram(adata, groupby = groupCat,. orientation = ""right"",. dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists. I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/pull/1945:12,deployability,releas,release,12,Start 1.8.2 release notes file;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1945
https://github.com/scverse/scanpy/issues/1946:93,availability,error,error,93,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:284,availability,fault,fault,284,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2836,availability,Error,Error,2836,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2907,availability,error,error,2907,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3128,availability,Error,Error,3128,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3201,availability,fault,fault,3201,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3620,availability,error,error,3620,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:40,deployability,Updat,Update,40,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:60,deployability,build,build,60,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:318,deployability,build,build,318,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:351,deployability,fail,fails,351,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2429,deployability,api,api,2429,"s.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2590,deployability,releas,release-notes,2590,".. loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2615,deployability,releas,release-notes,2615,"ventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2640,deployability,releas,release-notes,2640,".scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this att",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2665,deployability,releas,release-notes,2665,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2690,deployability,releas,release-notes,2690,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2715,deployability,releas,release-notes,2715,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2740,deployability,releas,release-notes,2740,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2765,deployability,releas,release-notes,2765,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2779,deployability,releas,release-latest,2779,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3010,deployability,build,builder-inited,3010,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3499,deployability,version,versions,3499,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3519,deployability,build,builds,3519,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:284,energy efficiency,fault,fault,284,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:461,energy efficiency,load,loading,461,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:552,energy efficiency,load,loading,552,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:641,energy efficiency,load,loading,641,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:721,energy efficiency,load,loading,721,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:802,energy efficiency,load,loading,802,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:893,energy efficiency,load,loading,893,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:986,energy efficiency,load,loading,986,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1084,energy efficiency,load,loading,1084,to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1157,energy efficiency,load,loading,1157,solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://doc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1262,energy efficiency,load,loading,1262,r scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1345,energy efficiency,load,loading,1345,0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stabl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1440,energy efficiency,load,loading,1440,"g Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1524,energy efficiency,load,loading,1524,"n/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1600,energy efficiency,load,loading,1600,"dthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1693,energy efficiency,load,loading,1693,"g/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1770,energy efficiency,load,loading,1770,"rg/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1852,energy efficiency,load,loading,1852,"dthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3201,energy efficiency,fault,fault,3201,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3220,energy efficiency,Current,Currently,3220,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2429,integrability,api,api,2429,"s.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3003,integrability,event,event,3003,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3499,integrability,version,versions,3499,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2429,interoperability,api,api,2429,"s.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2897,modifiability,Extens,Extension,2897,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3241,modifiability,paramet,parameter,3241,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3499,modifiability,version,versions,3499,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:93,performance,error,error,93,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:284,performance,fault,fault,284,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:461,performance,load,loading,461,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:552,performance,load,loading,552,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:641,performance,load,loading,641,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:721,performance,load,loading,721,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:802,performance,load,loading,802,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:893,performance,load,loading,893,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:986,performance,load,loading,986,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1084,performance,load,loading,1084,to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1157,performance,load,loading,1157,solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://doc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1200,performance,network,networkx,1200,closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1233,performance,network,networkx-,1233, the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1262,performance,load,loading,1262,r scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1345,performance,load,loading,1345,0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stabl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1440,performance,load,loading,1440,"g Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1524,performance,load,loading,1524,"n/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1600,performance,load,loading,1600,"dthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1693,performance,load,loading,1693,"g/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1770,performance,load,loading,1770,"rg/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1852,performance,load,loading,1852,"dthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1993,performance,network,networkx,1993,"ersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2026,performance,network,networkx-,2026,"uvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2063,performance,network,networkx,2063,"t/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type objec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2090,performance,network,networkx-,2090,"ersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2836,performance,Error,Error,2836,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2907,performance,error,error,2907,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3128,performance,Error,Error,3128,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3201,performance,fault,fault,3201,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3620,performance,error,error,3620,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:13,reliability,doe,doesn,13,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:284,reliability,fault,fault,284,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:351,reliability,fail,fails,351,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3201,reliability,fault,fault,3201,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:40,safety,Updat,Update,40,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:93,safety,error,error,93,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:284,safety,fault,fault,284,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2836,safety,Error,Error,2836,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2907,safety,error,error,2907,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3035,safety,except,exception,3035,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3046,safety,except,exception,3046,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3128,safety,Error,Error,3128,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3201,safety,fault,fault,3201,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3620,safety,error,error,3620,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:40,security,Updat,Update,40,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1200,security,network,networkx,1200,closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1233,security,network,networkx-,1233, the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1993,security,network,networkx,1993,"ersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2026,security,network,networkx-,2026,"uvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2063,security,network,networkx,2063,"t/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type objec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2090,security,network,networkx-,2090,"ersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:93,usability,error,error,93,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:204,usability,close,closed,204,Sphinx 4.1.0 doesn't like ScanpyConfig; Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://network,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1219,usability,document,documentation,1219,ous to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>. <summary> </summary>. ```sh. $ make html. Running Sphinx v4.1.0. loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv... loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv... loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1820,usability,learn,learn,1820,"nventory from https://ipython.readthedocs.io/en/stable/objects.inv... loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-pri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2012,usability,document,documentation,2012,"m https://louvain-igraph.readthedocs.io/en/latest/objects.inv... loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2076,usability,document,documentation,2076," loading intersphinx inventory from https://matplotlib.org/objects.inv... loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv... loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv... loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv... loading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2518,usability,document,documentation,2518,"oading intersphinx inventory from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2550,usability,tool,tools,2550," from https://docs.python.org/3/objects.inv... loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2836,usability,Error,Error,2836,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2907,usability,error,error,2907,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3128,usability,Error,Error,3128,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3273,usability,document,documentation,3273,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3620,usability,error,error,3620,".org/doc/scipy/reference/objects.inv... loading intersphinx inventory from https://seaborn.pydata.org/objects.inv... loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv... loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv... intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv. intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv. intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv. [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst. Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):. Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'). make: *** [html] Error 2. ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`. * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/pull/1947:47,deployability,releas,release,47,Backport PR #1945 on branch 1.8.x (Start 1.8.2 release notes file); Backport PR #1945: Start 1.8.2 release notes file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947
https://github.com/scverse/scanpy/pull/1947:99,deployability,releas,release,99,Backport PR #1945 on branch 1.8.x (Start 1.8.2 release notes file); Backport PR #1945: Start 1.8.2 release notes file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947
https://github.com/scverse/scanpy/issues/1949:766,deployability,log,logging,766,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:375,safety,prevent,prevent,375,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:703,safety,input,input,703,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:766,safety,log,logging,766,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:375,security,preven,prevent,375,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:766,security,log,logging,766,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:766,testability,log,logging,766,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:292,usability,support,support,292,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:499,usability,support,support,499,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/issues/1949:703,usability,input,input,703,"gex_only=True defaults in sc.read_10x_h5; This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/pull/1950:251,safety,review,review,251,Add PASTE to Scanpy ecosystem.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/pull/1950:251,testability,review,review,251,Add PASTE to Scanpy ecosystem.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/pull/1950:102,usability,guid,guidelines,102,Add PASTE to Scanpy ecosystem.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/pull/1950:133,usability,guid,guide,133,Add PASTE to Scanpy ecosystem.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/pull/1950:229,usability,workflow,workflow,229,Add PASTE to Scanpy ecosystem.; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/issues/1951:83,availability,error,error,83,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3199,availability,error,errors,3199," epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._im",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1574,deployability,modul,module,1574,"at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:273,energy efficiency,core,core,273,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:535,energy efficiency,CPU,CPUDispatcher,535,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2730,energy efficiency,core,core,2730,"a_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3028,energy efficiency,core,core,3028,"ors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3347,energy efficiency,core,core,3347,"65 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3596,energy efficiency,core,core,3596,"ng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overlo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3834,energy efficiency,core,core,3834,"), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4079,energy efficiency,core,core,4079,"**kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4205,energy efficiency,reduc,reduce,4205,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4344,energy efficiency,core,core,4344,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4555,energy efficiency,core,core,4555,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4866,energy efficiency,core,core,4866,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4807,integrability,protocol,protocol,4807,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4969,integrability,protocol,protocol,4969,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4807,interoperability,protocol,protocol,4807,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4969,interoperability,protocol,protocol,4969,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:258,modifiability,pac,packages,258,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1574,modifiability,modul,module,1574,"at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1678,modifiability,pac,packages,1678,"dx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1988,modifiability,pac,packages,1988,"t,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/loca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2260,modifiability,pac,packages,2260,"xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2494,modifiability,pac,packages,2494,"ack (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2715,modifiability,pac,packages,2715,"t(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3013,modifiability,pac,packages,3013,".py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3332,modifiability,pac,packages,3332," 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3581,modifiability,pac,packages,3581,". 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3819,modifiability,pac,packages,3819,"tr(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4064,modifiability,pac,packages,4064,"self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4329,modifiability,pac,packages,4329,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4540,modifiability,pac,packages,4540,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4851,modifiability,pac,packages,4851,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:83,performance,error,error,83,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:278,performance,cach,caching,278,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:535,performance,CPU,CPUDispatcher,535,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3199,performance,error,errors,3199," epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._im",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3839,performance,cach,caching,3839,"_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4084,performance,cach,caching,4084," 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4349,performance,cach,caching,4349,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4560,performance,cach,caching,4560,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4871,performance,cach,caching,4871,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:83,safety,error,error,83,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:412,safety,except,except,412,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1442,safety,except,exception,1442,"(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1461,safety,except,exception,1461,"ay(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1547,safety,input,input-,1547,"function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_gra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1574,safety,modul,module,1574,"at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2194,safety,test,test,2194,"-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3192,safety,except,except,3192,"est, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3199,safety,error,errors,3199," epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._im",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2965,security,sign,signature,2965,"ib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:193,testability,Trace,Traceback,193,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1492,testability,Trace,Traceback,1492,", 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2194,testability,test,test,2194,"-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4272,testability,context,contextlib,4272,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4283,testability,context,contextmanager,4283,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4994,testability,context,contextlib,4994,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:5005,testability,context,contextmanager,5005,"types.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._impl.reduce(data). --> 681 self._cache_file.save(key, data). 682 . 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 494 break. 495 overloads[key] = data_name. --> 496 self._save_index(overloads). 497 self._save_data(data_name, data). 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads). 540 def _save_index(self, overloads):. 541 data = self._source_stamp, overloads. --> 542 data = self._dump(data). 543 with self._open_for_write(self._index_path) as f:. 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj). 568 . 569 def _dump(self, obj):. --> 570 return pickle.dumps(obj, protocol=-1). 571 . 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:83,usability,error,error,83,"Questions about running ingest now; Now if I intend to run ingest, I will get this error:. running ingest. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data). 486 # If key already exists, we will overwrite the file. --> 487 data_name = overloads[key]. 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1547,usability,input,input-,1547,"function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_gra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:1694,usability,tool,tools,1694,"vx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2004,usability,tool,tools,2004,"movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last). 13 frames. <ipython-input-22-9176945aef7f> in <module>(). ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 131 . 132 if obs is not None:. --> 133 ing.neighbors(**kwargs). 134 for i, col in enumerate(obs):. 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state). 469 self._nnd_idx.search_rng_state = rng_state. 470 . --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3199,usability,error,errors,3199," epsilon). 472 . 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon). 1564 """""". 1565 if not hasattr(self, ""_search_graph""):. -> 1566 self._init_search_graph(). 1567 . 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self). 1061 self._distance_func,. 1062 self.rng_state,. -> 1063 self.diversify_prob,. 1064 ). 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 433 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 434 raise e. 435 . 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws). 365 argtypes.append(self.typeof_pyval(a)). 366 try:. --> 367 return self.compile(tuple(argtypes)). 368 except errors.ForceLiteralArg as e:. 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig). 823 raise e.bind_fold_arguments(folded). 824 self.add_overload(cres). --> 825 self._cache.save_overload(sig, cres). 826 return cres.entry_point. 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data). 669 """""". 670 with self._guard_against_spurious_io_errors():. --> 671 self._save_overload(sig, data). 672 . 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data). 679 key = self._index_key(sig, _get_codegen(data)). 680 data = self._im",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/pull/1952:67,integrability,filter,filtered,67,Backport PR #1942 on branch 1.8.x (Fix _rank_genes_groups_plot for filtered genes); Backport PR #1942: Fix _rank_genes_groups_plot for filtered genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1952
https://github.com/scverse/scanpy/pull/1952:135,integrability,filter,filtered,135,Backport PR #1942 on branch 1.8.x (Fix _rank_genes_groups_plot for filtered genes); Backport PR #1942: Fix _rank_genes_groups_plot for filtered genes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1952
https://github.com/scverse/scanpy/pull/1953:25,modifiability,pac,package,25,"Add dandelion, scBCR-seq package to scanpy ecosystem; Please thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1953
https://github.com/scverse/scanpy/issues/1954:56,usability,user,user-images,56,"sc.pl.umap bug; hello, there is a bug. ![image](https://user-images.githubusercontent.com/49113803/126420393-c1d56228-470a-439e-9b5f-bb1370f1e18b.png). ![image](https://user-images.githubusercontent.com/49113803/126420376-3986f6fd-ae17-4143-9106-5f78dc7f4899.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1954
https://github.com/scverse/scanpy/issues/1954:169,usability,user,user-images,169,"sc.pl.umap bug; hello, there is a bug. ![image](https://user-images.githubusercontent.com/49113803/126420393-c1d56228-470a-439e-9b5f-bb1370f1e18b.png). ![image](https://user-images.githubusercontent.com/49113803/126420376-3986f6fd-ae17-4143-9106-5f78dc7f4899.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1954
https://github.com/scverse/scanpy/issues/1955:8,deployability,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,deployability,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,deployability,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:8,integrability,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,integrability,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,integrability,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:8,interoperability,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,interoperability,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,interoperability,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:8,modifiability,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:49,modifiability,paramet,parameters,49,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:326,modifiability,pac,package,326,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,modifiability,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,modifiability,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:8,reliability,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,reliability,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,reliability,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:8,security,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:427,security,access,accessible,427,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,security,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,security,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:8,testability,integr,integration,8,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:131,testability,simpl,simple,131,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:556,testability,integr,integrate,556,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:692,testability,integr,integrated,692,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:123,usability,tool,tool,123,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:131,usability,simpl,simple,131,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:147,usability,tool,tool,147,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:195,usability,tool,tools,195,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:295,usability,tool,tools,295,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:645,usability,tool,tool,645,"diffxpy integration; . - [x] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1956:485,safety,avoid,avoid,485,"Split dotplot; I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)? ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png). This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:. ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1956:429,security,control,control,429,"Split dotplot; I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)? ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png). This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:. ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1956:429,testability,control,control,429,"Split dotplot; I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)? ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png). This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:. ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1956:187,usability,user,user-images,187,"Split dotplot; I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)? ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png). This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:. ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1956:327,usability,visual,visualizing,327,"Split dotplot; I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)? ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png). This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:. ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1956:592,usability,user,user-images,592,"Split dotplot; I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)? ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png). This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:. ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1957:38,availability,error,error,38,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:166,deployability,version,version,166,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:830,deployability,observ,observe,830,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:1177,deployability,contain,contain,1177,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:394,energy efficiency,current,current,394,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:969,energy efficiency,current,currently,969,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:166,integrability,version,version,166,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:402,integrability,wrap,wrapper,402,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:402,interoperability,wrapper,wrapper,402,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:166,modifiability,version,version,166,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:440,modifiability,layer,layer,440,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:873,modifiability,layer,layers,873,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:918,modifiability,layer,layers,918,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:994,modifiability,layer,layers,994,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:1024,modifiability,layer,layers,1024,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:1072,modifiability,layer,layer,1072,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:1267,modifiability,layer,layer,1267,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:38,performance,error,error,38,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:1169,reliability,doe,doesn,1169,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:38,safety,error,error,38,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:315,testability,simul,simulation,315,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:830,testability,observ,observe,830,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:1138,testability,simul,simulate,1138,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:38,usability,error,error,38,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:126,usability,confirm,confirmed,126,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:209,usability,confirm,confirmed,209,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:296,usability,document,documentation,296,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:644,usability,Minim,Minimal,644,"sc.external.pp.scurblet normalization error; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python. import scanpy. adata = scanpy.datasets.pbmc3k(). scanpy.external.pp.scrublet(adata). ```. and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:. ```python. adata_obs.layers['raw'] = adata_obs.X. print(adata_obs.layers['raw']). pp.normalize_total(adata_obs) <--- currently normalizes all layers and X. print(adata_obs.layers['raw']). ```. ---. ### Impact. The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python. adata_sim = scrublet_simulate_doublets(. adata_obs,. layer='raw',. sim_doublet_ratio=sim_doublet_ratio,. synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,. ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1958:170,deployability,version,version,170,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:296,energy efficiency,heat,heatmap,296,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:170,integrability,version,version,170,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:170,modifiability,version,version,170,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:130,usability,confirm,confirmed,130,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:213,usability,confirm,confirmed,213,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:440,usability,user,user-images,440,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1958:643,usability,command,command,643,"repeating genes in pl.rank_genes_groups_heatmap; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. It seems the heatmap generated by `pl.rank_genes_groups_heatmap` is showing repeated genes, as seem in the picture below. ![image_2021-07-26_095102](https://user-images.githubusercontent.com/72106661/126991532-eb645e13-41db-40d1-b7f7-65075fb982df.png). This occured in 1.7.1, which I had to use because of #1941 . I assume this is not working as intended. The command I have used is `sc.pl.rank_genes_groups_heatmap(adata, n_genes=5, standard_scale='var', swap_axes=True)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1958
https://github.com/scverse/scanpy/issues/1959:99,availability,sli,slightly,99,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:9,deployability,updat,update,9,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:82,deployability,updat,update,82,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:968,deployability,updat,updating,968,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:29,integrability,Discover,Discovered,29,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:29,interoperability,Discover,Discovered,29,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:743,interoperability,coordinat,coordinates,743,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:914,interoperability,coordinat,coordinates,914,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:0,performance,network,networkx,0,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:73,performance,network,networkx,73,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:1050,performance,network,networkx,1050,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:1079,performance,network,networkx,1079,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:1088,performance,network,networkx,1088,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:99,reliability,sli,slightly,99,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:9,safety,updat,update,9,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:82,safety,updat,update,82,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:968,safety,updat,updating,968,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:0,security,network,networkx,0,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:9,security,updat,update,9,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:73,security,network,networkx,73,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:82,security,updat,update,82,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:968,security,updat,updating,968,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:1050,security,network,networkx,1050,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:1079,security,network,networkx,1079,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:1088,security,network,networkx,1088,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:29,usability,Discov,Discovered,29,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:262,usability,user,user-images,262,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:374,usability,user,user-images,374,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:493,usability,user,user-images,493,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/issues/1959:630,usability,user,user-images,630,"networkx update breaking CI; Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png). ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/pull/1960:55,deployability,Updat,Updates,55,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:176,deployability,modul,module,176,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:256,deployability,fail,fails,256,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:176,modifiability,modul,module,176,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:23,performance,network,networkx,23,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:114,performance,network,networkx,114,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:256,reliability,fail,fails,256,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:13,safety,test,tests,13,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:55,safety,Updat,Updates,55,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:153,safety,test,tests,153,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:176,safety,modul,module,176,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:209,safety,test,tests,209,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:23,security,network,networkx,23,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:55,security,Updat,Updates,55,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:114,security,network,networkx,114,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:13,testability,test,tests,13,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:153,testability,test,tests,153,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:209,testability,test,tests,209,Fix plotting tests for networkx >= 2.6.2; Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1961:58,performance,network,networkx,58,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:120,performance,network,networkx,120,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:48,safety,test,tests,48,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:110,safety,test,tests,110,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:58,security,network,networkx,58,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:120,security,network,networkx,120,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:48,testability,test,tests,48,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/pull/1961:110,testability,test,tests,110,Backport PR #1960 on branch 1.8.x (Fix plotting tests for networkx >= 2.6.2); Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/issues/1963:891,deployability,version,version,891,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:966,deployability,continu,continuous,966,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:247,energy efficiency,green,green,247,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:515,integrability,batch,batch,515,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:717,integrability,batch,batch,717,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:891,integrability,version,version,891,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:19,interoperability,specif,specific,19,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:866,interoperability,format,format,866,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:996,interoperability,specif,specific,996,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:158,modifiability,design decis,design decisions,158,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:891,modifiability,version,version,891,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:515,performance,batch,batch,515,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:717,performance,batch,batch,717,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:56,usability,help,help,56,"why cannot set the specific color?; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. ... colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',. 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']. adata = sc.AnnData(embedding). adata.obs[""category""] = label.astype(np.int). adata.obs[""domain""] = batch.astype(np.int). sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10). adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]). adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]). sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],. show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/pull/1965:453,deployability,automat,automatically,453,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:14,integrability,batch,batch-aware,14,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:66,integrability,batch,batch,66,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:147,integrability,batch,batches,147,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:241,integrability,batch,batch,241,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:436,integrability,batch,batches,436,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:14,performance,batch,batch-aware,14,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:66,performance,batch,batch,66,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:147,performance,batch,batches,147,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:241,performance,batch,batch,241,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:436,performance,batch,batches,436,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:453,testability,automat,automatically,453,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1965:512,usability,user,user-images,512,"Make Scrublet batch-aware; This PR makes adjustments for handling batch correctly while running Scrublet:. - Run scrublet separately on individual batches where applicable. Where this is the case, results stored in .uns are further keyed by batch (e.g. thershold selected etc), while the doublet scores are stored together in .obs. - Scrublet plotting function needs to account for the changes in the object, and will plot the multiple batches together automatically. ![scrublet_score_distributionfinal](https://user-images.githubusercontent.com/5775915/127359452-08e8339c-79b1-4cc1-8b51-c843f998c812.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1965
https://github.com/scverse/scanpy/pull/1966:60,modifiability,pac,package,60,"Backport PR #1953 on branch 1.8.x (Add dandelion, scBCR-seq package to scanpy ecosystem); Backport PR #1953: Add dandelion, scBCR-seq package to scanpy ecosystem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1966
https://github.com/scverse/scanpy/pull/1966:134,modifiability,pac,package,134,"Backport PR #1953 on branch 1.8.x (Add dandelion, scBCR-seq package to scanpy ecosystem); Backport PR #1953: Add dandelion, scBCR-seq package to scanpy ecosystem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1966
https://github.com/scverse/scanpy/issues/1967:659,availability,error,error,659,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:172,deployability,version,version,172,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:172,integrability,version,version,172,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:172,modifiability,version,version,172,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:659,performance,error,error,659,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:659,safety,error,error,659,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:132,usability,confirm,confirmed,132,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:215,usability,confirm,confirmed,215,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:306,usability,guid,guide,306,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:361,usability,minim,minimal-bug-reports,361,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:659,usability,error,error,659,"Edit on GitHub forwarding to non-existing webpage; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1968:131,modifiability,paramet,parameters,131,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:408,modifiability,pac,package,408,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:213,testability,simpl,simple,213,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:205,usability,tool,tool,205,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:213,usability,simpl,simple,213,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:229,usability,tool,tool,229,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:277,usability,tool,tools,277,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1968:377,usability,tool,tools,377,"Pass delimiter in `scanpy.read` to `read_csv`; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/pull/1969:140,usability,Close,Closes,140,"Pass delimiter to `read_csv`; ## Changes. * To read from CSV files more flexibly, the delimiter is passed to `read_csv`. ## Related issues. Closes #1968.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1969
https://github.com/scverse/scanpy/issues/1970:180,deployability,version,version,180,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:583,energy efficiency,current,current,583,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:180,integrability,version,version,180,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:180,modifiability,version,version,180,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:33,reliability,doe,does,33,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:140,usability,confirm,confirmed,140,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:223,usability,confirm,confirmed,223,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:456,usability,tool,tools,456,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1970:882,usability,tool,tools,882,"sc.tl.score_genes use_raw = None does not default to True; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. Hi, in `sc.tl.score_genes`, there's nothing to catch `use_raw=None` before this line:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L102. Hence `use_raw = None` is the same as `use_raw = False`, even if `_check_raw` happens later. . The current description says:. ```python. use_raw . Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present. . ```. Linking the relevant code from the start of function to line of issue:. https://github.com/theislab/scanpy/blob/4e4e6abe9f073bcf87db4f3f3d9c8964765c8921/scanpy/tools/_score_genes.py#L40-L111",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1970
https://github.com/scverse/scanpy/issues/1971:347,availability,error,error,347,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1188,availability,error,error,1188," scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1504,availability,cluster,clusters,1504,"omething to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1631,availability,error,error,1631," to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:181,deployability,version,version,181,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:293,deployability,updat,updating,293,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:764,deployability,version,version,764,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1504,deployability,cluster,clusters,1504,"omething to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3094,deployability,modul,module,3094,"uster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3738,deployability,Version,Versions,3738,"in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6023,deployability,log,logical,6023,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6077,deployability,updat,updated,6077,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4181,energy efficiency,cloud,cloudpickle,4181,"nce=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6031,energy efficiency,CPU,CPU,6031,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6035,energy efficiency,core,cores,6035,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:181,integrability,version,version,181,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:619,integrability,event,eventually,619,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:764,integrability,version,version,764,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3738,integrability,Version,Versions,3738,"in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5741,integrability,wrap,wrapt,5741,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:181,modifiability,version,version,181,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:764,modifiability,version,version,764,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1321,modifiability,variab,variable,1321,"s 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3094,modifiability,modul,module,3094,"uster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3310,modifiability,pac,packages,3310,"alf:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3738,modifiability,Version,Versions,3738,"in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4313,modifiability,deco,decorator,4313,"/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. so",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4905,modifiability,pac,packaging,4905,04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5902,modifiability,pac,packaged,5902,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:347,performance,error,error,347,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1188,performance,error,error,1188," scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1631,performance,error,error,1631," to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4216,performance,concurren,concurrent,4216,"es=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4791,performance,network,networkx,4791, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6031,performance,CPU,CPU,6031,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1165,reliability,doe,doesn,1165,"n the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pair",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:11,safety,prevent,preventing,11,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:293,safety,updat,updating,293,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:347,safety,error,error,347,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1188,safety,error,error,1188," scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1631,safety,error,error,1631," to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3094,safety,modul,module,3094,"uster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6023,safety,log,logical,6023,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6077,safety,updat,updated,6077,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:11,security,preven,preventing,11,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:293,security,updat,updating,293,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:489,security,ident,identical,489,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1678,security,ident,identical,1678," not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1858,security,Control,Control,1858," that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4107,security,certif,certifi,4107,"nk_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4791,security,network,networkx,4791, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5316,security,soc,socks,5316,"tor 5.0.9. defusedxml 0.7.1. encodings NA. et_xmlfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6023,security,log,logical,6023,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6057,security,Session,Session,6057,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6077,security,updat,updated,6077,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:461,testability,trace,traceback,461,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:832,testability,simpl,simple,832,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1061,testability,simpl,simple,1061,"] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1858,testability,Control,Control,1858," that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDir",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3003,testability,Trace,Traceback,3003,"irs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5364,testability,spy,spyder,5364,"lfile 1.0.1. flatbuffers NA. fsspec 2021.07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), beca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5400,testability,spy,spydercustomize,5400,"07.0. gast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6023,testability,log,logical,6023,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:141,usability,confirm,confirmed,141,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:224,usability,confirm,confirmed,224,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:347,usability,error,error,347,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:832,usability,simpl,simple,832,"data types preventing sc.tl.rank_genes_groups from running; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('catego",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1061,usability,simpl,simple,1061,"] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1188,usability,error,error,1188," scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].ast",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1631,usability,error,error,1631," to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1733,usability,Minim,Minimal,1733,"py, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python. cluster_method='leiden'. n_genes=1000. g1n='Control'. adata.obs['condition']=adata.obs['condition'].astype('category'). adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'). pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])). adata.obs['pairs_'+cluster_method]=pairs. adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'). pairs_set = list(set(pairs)). s = sorted(pairs_set). half = int((len(s)/2)). list1 = s[:half]. list2 = s[half:]. lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:3326,usability,tool,tools,3326,"er_method = list(zip(list1, list2)). cat = pd.DataFrame(). for i in lz_cluster_method:. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pval_table = pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals_adj']}).head(n_genes). cat = pd.concat([cat, pval_table], axis=1). cat.to_excel(os.path.join(BaseDirectory, 'DiffExp_Upregulated_' + g1n + '_' + method + '_' + cluster_method + '_' + str(n_genes) + 'genes_rawData_adjP.xlsx')). ```. ```pytb. Traceback (most recent call last):. File ""/tmp/ipykernel_40769/1343034691.py"", line 3, in <module>. sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups. raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)]. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. 2f7ece400a652629565c523b34ee61b04afa385c NA. ACWS_filterCells NA. PIL 8.3.1. PyQt5 NA. absl NA. anndata 0.7.6. appdirs 1.4.4. astunparse 1.6.3. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.0. cloudpickle 1.6.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.0. dateutil 2.8.2. decorator 5.0.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5619,usability,tool,toolz,5619,"ast NA. genericpath NA. google NA. gprofiler 1.0.0. h5py 3.3.0. idna 3.1. igraph 0.9.6. imagecodecs 2021.6.8. imageio 2.9.0. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 1.0.1. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. networkx 2.5. ntpath NA. numba 0.53.1. numexpr 2.7.3. numpy 1.21.1. opcode NA. openpyxl 3.0.7. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pooch v1.4.0. posixpath NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydoc_data NA. pyexpat NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. requests 2.26.0. scanpy 1.8.1. scipy 1.7.0. seaborn 0.11.1. sinfo 0.3.1. sip NA. six 1.16.0. skimage 0.18.2. sklearn 0.24.2. socks 1.7.1. soupsieve 2.0.1. sphinxcontrib NA. spyder 5.0.5. spyder_kernels 2.0.5. spydercustomize NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tensorboard 2.5.0. tensorflow 2.5.0. termcolor 1.1.0. texttable 1.6.4. tifffile 2021.7.2. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.61.2. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. urllib3 1.26.6. wcwidth 0.2.5. wrapt 1.12.1. wurlitzer 2.1.0. xlsxwriter 1.4.4. yaml 5.4.1. zmq 22.1.0. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. -----. Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]. Linux-5.4.0-72-generic-x86_64-with-glibc2.27. 40 logical CPU cores, x86_64. -----. Session information updated at 2021-07-29 21:02. </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1972:146,deployability,version,version,146,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:247,deployability,Version,Version,247,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:146,integrability,version,version,146,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:247,integrability,Version,Version,247,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:146,modifiability,version,version,146,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:247,modifiability,Version,Version,247,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:106,usability,confirm,confirmed,106,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:189,usability,confirm,confirmed,189,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/issues/1972:287,usability,custom,custom,287,"PAGA plot resets colors; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. I set custom colors for my obs col in uns, but when I use pl.paga or pl.paga_compare a different set of colours is used and the uns is changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1972
https://github.com/scverse/scanpy/pull/1974:16,deployability,instal,installation,16,add conda-forge installation instructions; Signed-off-by: zethson <lukas.heumos@posteo.net>. Fixes #1912 #1142 #990 #1243,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1974
https://github.com/scverse/scanpy/pull/1974:43,security,Sign,Signed-off-by,43,add conda-forge installation instructions; Signed-off-by: zethson <lukas.heumos@posteo.net>. Fixes #1912 #1142 #990 #1243,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1974
https://github.com/scverse/scanpy/issues/1975:9,availability,error,error,9,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:224,deployability,version,version,224,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:335,deployability,updat,updating,335,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:980,deployability,modul,module,980,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:2404,deployability,Version,Versions,2404,".obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.6 pynndescent==0.5.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:224,integrability,version,version,224,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1491,integrability,compon,components,1491,"). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:2404,integrability,Version,Versions,2404,".obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.6 pynndescent==0.5.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1491,interoperability,compon,components,1491,"). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:224,modifiability,version,version,224,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:980,modifiability,modul,module,980,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1085,modifiability,pac,packages,1085,"ategories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1297,modifiability,pac,packages,1297,"aster branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1491,modifiability,compon,components,1491,"). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1503,modifiability,layer,layer,1503,"map(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-lea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:1950,modifiability,pac,packages,1950,".obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.6 pynndescent==0.5.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:2404,modifiability,Version,Versions,2404,".obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.6 pynndescent==0.5.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:9,performance,error,error,9,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:9,safety,error,error,9,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:335,safety,updat,updating,335,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:953,safety,input,input-,953,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:980,safety,modul,module,980,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:335,security,updat,updating,335,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:909,testability,Trace,Traceback,909,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:9,usability,error,error,9,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:184,usability,confirm,confirmed,184,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:267,usability,confirm,confirmed,267,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:953,usability,input,input-,953,"Plotting error after creating new category: 'Float64Index' object has no attribute 'add_categories'; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When updating a category or creating a new one, it is not possible to plot the associated umap with the new category. . ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.pl.umap(pbmc, color = 'phase'). new_cluster_names = [. 'A', 'B', 'C']. pbmc.obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1975:2503,usability,learn,learn,2503,".obs['cell_types'] = pbmc.obs['phase']. pbmc.obs['cell_types'].cat.categories = new_cluster_names. sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names). sc.pl.umap(pbmc, color=['phase']). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-82-890b788bf078> in <module>. ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 255 color_source_vector,. 256 palette=palette,. --> 257 na_color=na_color,. 258 ). 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color). 1275 # Set color to 'missing color' for all missing values. 1276 if color_vector.isna().any():. -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]). 1278 color_vector = color_vector.fillna(to_hex(na_color)). 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.6 pynndescent==0.5.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1976:411,availability,error,error,411,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:270,energy efficiency,predict,predict,270,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:48,integrability,batch,batch,48,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:316,integrability,batch,batch,316,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:48,performance,batch,batch,48,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:316,performance,batch,batch,316,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:411,performance,error,error,411,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:270,safety,predict,predict,270,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:411,safety,error,error,411,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:141,usability,user,user-images,141,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:245,usability,tool,tool,245,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:411,usability,error,error,411,"Can Ingest solve some problems for dataset with batch effect?; I wonder for datasets whose umap results looking like this:. ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1977:173,availability,error,errors,173,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:70,deployability,observ,observations,70,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:106,integrability,batch,batch,106,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:200,integrability,coupl,couple,200,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:200,modifiability,coupl,couple,200,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:28,performance,memor,memory,28,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:98,performance,perform,perform,98,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:106,performance,batch,batch,106,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:166,performance,memor,memory,166,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:173,performance,error,errors,173,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:228,performance,memor,memory,228,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:314,performance,memor,memory,314,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:173,safety,error,errors,173,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:70,testability,observ,observations,70,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:200,testability,coupl,couple,200,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:239,testability,understand,understanding,239,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:28,usability,memor,memory,28,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:98,usability,perform,perform,98,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:166,usability,memor,memory,166,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:173,usability,error,errors,173,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:228,usability,memor,memory,228,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:314,usability,memor,memory,314,"sc.pp.combat runtime/out of memory; I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory. Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1978:93,availability,error,error,93,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:573,availability,error,error,573,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:0,deployability,modul,module,0,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:115,deployability,modul,module,115,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:698,deployability,modul,module,698,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1024,deployability,version,version,1024,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1059,deployability,version,version,1059,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1158,deployability,modul,module,1158,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1279,deployability,depend,dependency,1279,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1024,integrability,version,version,1024,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1059,integrability,version,version,1059,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1279,integrability,depend,dependency,1279,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:0,modifiability,modul,module,0,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:115,modifiability,modul,module,115,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:698,modifiability,modul,module,698,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:807,modifiability,pac,packages,807,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1024,modifiability,version,version,1024,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1059,modifiability,version,version,1059,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1158,modifiability,modul,module,1158,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1271,modifiability,pac,package,1271,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1279,modifiability,depend,dependency,1279,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:93,performance,error,error,93,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:573,performance,error,error,573,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:0,safety,modul,module,0,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:93,safety,error,error,93,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:115,safety,modul,module,115,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:573,safety,error,error,573,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:672,safety,input,input-,672,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:698,safety,modul,module,698,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1158,safety,modul,module,1158,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1279,safety,depend,dependency,1279,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:628,testability,Trace,Traceback,628,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1279,testability,depend,dependency,1279,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:93,usability,error,error,93,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:573,usability,error,error,573,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:672,usability,input,input-,672,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:823,usability,tool,tools,823,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1329,usability,help,help,1329,"module 'umap' has no attribute '__version__'; Hey! I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```. import pandas as pd. #pd.set_option(""display.max_columns"", None). import numpy as np. import anndata. import scanpy as sc. %store -r df. adata = anndata.AnnData(df). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata). sc.pl.paga(adata, plot=False). sc.tl.umap(adata, init_pos='paga'). ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```. AttributeError Traceback (most recent call last). <ipython-input-7-7cfb2fb3103e> in <module>. ----> 1 sc.tl.umap(adata, init_pos='paga'). 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 141 import umap. 142 . --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):. 144 . 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'. ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1980:270,deployability,version,version,270,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:916,deployability,modul,module,916,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1470,deployability,Version,Versions,1470,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1519,deployability,log,logging,1519,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:270,integrability,version,version,270,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1470,integrability,Version,Versions,1470,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:270,modifiability,version,version,270,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:916,modifiability,modul,module,916,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1024,modifiability,pac,packages,1024,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1208,modifiability,pac,packages,1208,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1470,modifiability,Version,Versions,1470,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:916,safety,modul,module,916,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1519,safety,log,logging,1519,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1519,security,log,logging,1519,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:821,testability,Trace,Traceback,821,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1519,testability,log,logging,1519,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:230,usability,confirm,confirmed,230,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:313,usability,confirm,confirmed,313,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:404,usability,guid,guide,404,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:459,usability,minim,minimal-bug-reports,459,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:565,usability,Minim,Minimal,565,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:1040,usability,tool,tools,1040,"SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import pandas as pd. import scanpy as sc. import os. import sys. data = sc.read(""data_bbknn_umap.h5ad""). sc.tl.louvain(data,resolution=res). ```. ```pytb. Traceback (most recent call last):. File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>. sc.tl.louvain(dat_merge,resolution=res). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain. g = _utils.get_igraph_from_adjacency(adjacency, directed=directed). File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency. g.es['weight'] = weights. SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1981:1034,availability,error,error,1034,"ttribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3548,availability,down,downgrade,3548," None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3732,availability,sli,slightly,3732,"ig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. nume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:178,deployability,version,version,178,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1443,deployability,modul,module,1443,"to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:2989,deployability,Version,Versions,2989,"ette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3206,deployability,log,logging,3206,", save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3527,deployability,instal,installs,3527,"gs.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_serv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3664,deployability,instal,install,3664,"onda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5719,deployability,log,logical,5719,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5771,deployability,updat,updated,5771,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:4082,energy efficiency,cloud,cloudpickle,4082,"learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5727,energy efficiency,CPU,CPU,5727,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5731,energy efficiency,core,cores,5731,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:178,integrability,version,version,178,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:567,integrability,coupl,couple,567,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1928,integrability,compon,components,1928,"dir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. Attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:2989,integrability,Version,Versions,2989,"ette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3425,integrability,discover,discoverable,3425,"ages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3609,integrability,messag,message,3609,"=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5467,integrability,wrap,wrapt,5467,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1928,interoperability,compon,components,1928,"dir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. Attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3425,interoperability,discover,discoverable,3425,"ages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3609,interoperability,messag,message,3609,"=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:178,modifiability,version,version,178,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:567,modifiability,coupl,couple,567,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1443,modifiability,modul,module,1443,"to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1540,modifiability,pac,packages,1540,"his code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1734,modifiability,pac,packages,1734,"pyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1928,modifiability,compon,components,1928,"dir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. Attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1940,modifiability,layer,layer,1940,"h/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:2427,modifiability,pac,packages,2427,"753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discov",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:2693,modifiability,pac,packages,2693,". ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:2989,modifiability,Version,Versions,2989,"ette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3352,modifiability,pac,package,3352," if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igrap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3477,modifiability,pac,package,3477,"writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsons",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:4212,modifiability,deco,decorator,4212,"nt_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:4761,modifiability,pac,packaging,4761,"est README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session informa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1034,performance,error,error,1034,"ttribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3994,performance,bottleneck,bottleneck,3994,"scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5727,performance,CPU,CPU,5727,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1058,reliability,doe,doesn,1058," I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3732,reliability,sli,slightly,3732,"ig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. nume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1034,safety,error,error,1034,"ttribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1416,safety,input,input-,1416,"cessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1443,safety,modul,module,1443,"to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3206,safety,log,logging,3206,", save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3508,safety,avoid,avoid,3508,"). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3752,safety,review,review,3752,"xt). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5719,safety,log,logical,5719,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5771,safety,updat,updated,5771,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3206,security,log,logging,3206,", save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:4034,security,certif,certifi,4034,"1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5178,security,soc,socks,5178,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5719,security,log,logical,5719,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5751,security,Session,Session,5751,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5771,security,updat,updated,5771,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:567,testability,coupl,couple,567,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1372,testability,Trace,Traceback,1372,"g-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3206,testability,log,logging,3206,", save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3752,testability,review,review,3752,"xt). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5719,testability,log,logical,5719,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:138,usability,confirm,confirmed,138,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:221,usability,confirm,confirmed,221,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:312,usability,guid,guide,312,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:367,usability,minim,minimal-bug-reports,367,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:473,usability,Minim,Minimal,473,"AttributeError: 'str' object has no attribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1034,usability,error,error,1034,"ttribute 'mkdir'; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:1416,usability,input,input-,1416,"cessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up? **(1) when I do:** . sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,. save = '_test2.png'. ). I get an AttributeError: 'str' object has no attribute 'mkdir'. . **(2) when I do:**. sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,. save = '_test2.png'. ). then nothing happens there is no error and the directory doesn't actually change. ```python. sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,. save = '_test2.png'. ). ```. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-11-fd106b753fe2> in <module>. ----> 1 sc.pl.umap(Tgd,. 2 save = '_test2.png'. 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 657 tl.umap. 658 """""". --> 659 return embedding(adata, 'umap', **kwargs). 660 . 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3088,usability,learn,learn,3088,"d_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 447 return fig. 448 axs = axs if grid else ax. --> 449 _utils.savefig_or_show(basis, show=show, save=save). 450 if show is False:. 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpick",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3425,usability,discov,discoverable,3425,"ages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save). 310 show = settings.autoshow if show is None else show. 311 if save:. --> 312 savefig(writekey, dpi=dpi, ext=ext). 313 if show:. 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext). 280 else:. 281 dpi = rcParams['savefig.dpi']. --> 282 settings.figdir.mkdir(parents=True, exist_ok=True). 283 if ext is None:. 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'. ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5317,usability,tool,toolz,5317,"joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. bioservices 1.7.12. bottleneck 1.3.2. brotli NA. bs4 4.9.3. certifi 2021.05.30. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. colorlog NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.07.2. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. docutils 0.17.1. easydev 0.11.1. fsspec 2021.07.0. gseapy 0.10.5. h5py 2.10.0. html5lib 1.1. idna 2.10. igraph 0.9.4. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.6.1. kiwisolver 1.3.1. leidenalg 0.8.4. llvmlite 0.36.0. louvain 0.7.0. lxml 4.6.3. markupsafe 2.0.1. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numexpr 2.7.3. numpy 1.18.5. packaging 21.0. pandas 1.1.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.9.0. pylab NA. pynndescent 0.5.2. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. requests_cache 0.6.4. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.16.0. sklearn 0.24.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.3. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.1. url_normalize 1.4.3. urllib3 1.26.6. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.4.0. -----. Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:24.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1982:0,availability,Error,Error,0,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:296,availability,error,error,296,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:400,availability,error,error,400,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:518,availability,error,error,518,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1146,availability,error,error,1146," exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3090,availability,error,error,3090,"y/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4010,availability,error,error,4010,"f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4101,availability,error,error,4101,"hile writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5923,availability,error,error,5923,"11 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6045,availability,error,error,6045,"et_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6136,availability,error,error,6136,"t_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6227,availability,error,error,6227,"/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. nume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:171,deployability,version,version,171,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4340,deployability,modul,module,4340,"a/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6400,deployability,Version,Versions,6400," = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8178,deployability,log,logical,8178,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8230,deployability,updat,updated,8230,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:364,energy efficiency,load,loaded,364,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:457,energy efficiency,load,loading,457,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6657,energy efficiency,cloud,cloudpickle,6657,"e, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8186,energy efficiency,CPU,CPU,8186,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8190,energy efficiency,core,cores,8190,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:171,integrability,version,version,171,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2079,integrability,wrap,wrapper,2079,"ite_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2135,integrability,wrap,wrapper,2135,"is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5271,integrability,wrap,wrapper,5271,"ack (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6400,integrability,Version,Versions,6400," = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2079,interoperability,wrapper,wrapper,2079,"ite_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2135,interoperability,wrapper,wrapper,2135,"is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5271,interoperability,wrapper,wrapper,5271,"ack (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:171,modifiability,version,version,171,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1246,modifiability,pac,packages,1246," from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above ex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1453,modifiability,pac,packages,1453,"loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1673,modifiability,pac,packages,1673,"op/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1864,modifiability,pac,packages,1864,"_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2391,modifiability,pac,packages,2391,"xcept Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2598,modifiability,pac,packages,2598,"ata=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2873,modifiability,pac,packages,2873,"/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3328,modifiability,pac,packages,3328,"most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3535,modifiability,pac,packages,3535,"except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3793,modifiability,pac,packages,3793,"s, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4340,modifiability,modul,module,4340,"a/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4494,modifiability,pac,packages,4494,". ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4742,modifiability,pac,packages,4742,"rgs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5496,modifiability,pac,packages,5496,"es/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5731,modifiability,pac,packages,5731,"8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6400,modifiability,Version,Versions,6400," = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6774,modifiability,deco,decorator,6774,"em, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. termin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:7255,modifiability,pac,packaging,7255,"ar' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. <",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:0,performance,Error,Error,0,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:296,performance,error,error,296,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:364,performance,load,loaded,364,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:400,performance,error,error,400,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:457,performance,load,loading,457,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:518,performance,error,error,518,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1146,performance,error,error,1146," exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3090,performance,error,error,3090,"y/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4010,performance,error,error,4010,"f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4101,performance,error,error,4101,"hile writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5923,performance,error,error,5923,"11 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6045,performance,error,error,6045,"et_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6136,performance,error,error,6136,"t_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6227,performance,error,error,6227,"/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. nume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6580,performance,bottleneck,bottleneck,6580," if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8186,performance,CPU,CPU,8186,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:524,reliability,doe,does,524,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:0,safety,Error,Error,0,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:296,safety,error,error,296,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:400,safety,error,error,400,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:518,safety,error,error,518,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1146,safety,error,error,1146," exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1394,safety,except,except,1394,"he error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1401,safety,Except,Exception,1401,"appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2248,safety,except,exception,2248,"s/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2296,safety,except,exception,2296,", val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2539,safety,except,except,2539,"to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2546,safety,Except,Exception,2546,"len_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3090,safety,error,error,3090,"y/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3185,safety,except,exception,3185,"r: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3233,safety,except,exception,3233,"The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the foll",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3476,safety,except,except,3476,". --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3483,safety,Except,Exception,3483," return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4010,safety,error,error,4010,"f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4101,safety,error,error,4101,"hile writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4196,safety,except,exception,4196,"e direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4244,safety,except,exception,4244,"imeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4313,safety,input,input-,4313,"hon3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4340,safety,modul,module,4340,"a/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5815,safety,except,except,5815,"dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5822,safety,Except,Exception,5822,"taset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_ver",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5923,safety,error,error,5923,"11 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6045,safety,error,error,6045,"et_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6136,safety,error,error,6136,"t_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6227,safety,error,error,6227,"/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. nume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8178,safety,log,logical,8178,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8230,safety,updat,updated,8230,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:484,security,modif,modifications,484,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6609,security,certif,certifi,6609,"]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:7680,security,soc,socks,7680,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8178,security,log,logical,8178,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8210,security,Session,Session,8210,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8230,security,updat,updated,8230,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1176,testability,Trace,Traceback,1176," scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). Ru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2321,testability,Trace,Traceback,2321,"208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3258,testability,Trace,Traceback,3258,"he direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. Runtime",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4269,testability,Trace,Traceback,4269,"recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8178,testability,log,logical,8178,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:0,usability,Error,Error,0,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:131,usability,confirm,confirmed,131,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:296,usability,error,error,296,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:400,usability,error,error,400,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:518,usability,error,error,518,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:598,usability,Minim,Minimal,598,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:659,usability,User,Users,659,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:768,usability,User,Users,768,"Error When Saving File as .h5ad with adata.write; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1094,usability,User,Users,1094,"ready been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1146,usability,error,error,1146," exists on the latest version of scanpy. ---. Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python. zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""). zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""). t2g.index = t2g.gene_id. t2g = t2g.loc[~t2g.index.duplicated(keep='first')]. zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]). zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ```. Here is the error:. ```pytb. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs). 184 value = _to_hdf5_vlen_strings(value). --> 185 f.create_dataset(key, data=value, **dataset_kwargs). 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 138 if name is not None:. --> 139 self[name] = dset. 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj). 372 if isinstance(obj, HLObject):. --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl). 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3090,usability,error,error,3090,"y/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs). 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs). --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs). 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4010,usability,error,error,4010,"f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4101,usability,error,error,4101,"hile writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4313,usability,input,input-,4313,"hon3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 208 try:. --> 209 return func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4424,usability,User,Users,4424,"eturn func(elem, key, val, *args, **kwargs). 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs). 262 for col_name, (_, series) in zip(col_names, df.items()):. --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs). 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last). <ipython-input-21-ded14f7730cd> in <module>. 8 zf_48.var.index = zf_48.var[""gene_name""]. 9 . ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1903 filename = self.filename. 1904 . -> 1905 _write_h5ad(. 1906 Path(filename),. 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__nam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5923,usability,error,error,5923,"11 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6045,usability,error,error,6045,"et_kwargs=dataset_kwargs). 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6136,usability,error,error,6136,"t_kwargs). 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6227,usability,error,error,6227,"/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. nume",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6386,usability,command,command,6386,". 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 128 if key in f:. 129 del f[key]. --> 130 _write_method(type(value))(f, key, value, *args, **kwargs). 131 . 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 210 except Exception as e:. 211 parent = _get_parent(elem). --> 212 raise type(e)(. 213 f""{e}\n\n"". 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:7819,usability,tool,toolz,7819,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command? #### Versions. <details>. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.2.0. anndata2ri 1.0.6. anyio NA. appnope 0.1.2. attr 20.3.0. babel 2.9.0. backcall 0.2.0. backports NA. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.5. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. decorator 5.0.6. dunamai 1.6.0. fsspec 0.9.0. get_version 3.5. h5py 2.10.0. idna 2.10. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 2.11.3. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.35.0. markupsafe 1.1.1. matplotlib 3.3.4. mkl 2.3.0. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.52.0. numexpr 2.7.3. numpy 1.20.1. packaging 20.9. pandas 1.2.4. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.1. requests 2.25.1. rpy2 3.4.5. samalg 0.8.6. scipy 1.6.2. seaborn 0.11.1. send2trash NA. six 1.15.0. sklearn 0.24.1. skmisc 0.1.4. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tables 3.6.1. tblib 1.7.0. terminado 0.9.4. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.0.5. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. yaml 5.4.1. zmq 20.0.0. zope NA. -----. IPython 7.22.0. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-08-16 12:25. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1983:443,availability,error,errors,443,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:699,availability,error,error,699,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3724,availability,error,error,3724,"vities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4099,availability,down,downgrade,4099,"nectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4283,availability,sli,slightly,4283,"t(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:221,deployability,version,version,221,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:566,deployability,manag,managed,566,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1442,deployability,Log,Logarithmized,1442," when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neigh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1834,deployability,modul,module,1834,"imal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3797,deployability,Version,Versions,3797,"s,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4078,deployability,instal,installs,4078,"_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4215,deployability,instal,install,4215,"elo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. torn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5519,deployability,log,logical,5519,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5573,deployability,updat,updated,5573,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:566,energy efficiency,manag,managed,566,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3638,energy efficiency,CPU,CPUDispatcher,3638,"' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5527,energy efficiency,CPU,CPU,5527,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5531,energy efficiency,core,cores,5531,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:221,integrability,version,version,221,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1295,integrability,Filter,Filtered,1295,"ster branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_ne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3797,integrability,Version,Versions,3797,"s,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3976,integrability,discover,discoverable,3976,"_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. picklesh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4160,integrability,messag,message,4160,",. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1349,interoperability,share,shared,1349,"ts, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3976,interoperability,discover,discoverable,3976,"_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. picklesh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4160,interoperability,messag,message,4160,",. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:221,modifiability,version,version,221,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1426,modifiability,variab,variable,1426,"etting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1834,modifiability,modul,module,1834,"imal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:2043,modifiability,pac,packages,2043,"c.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:2428,modifiability,pac,packages,2428,"le genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:2880,modifiability,pac,packages,2880,"dense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_he",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3242,modifiability,pac,packages,3242,"bors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3797,modifiability,Version,Versions,3797,"s,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3903,modifiability,pac,package,3903,"_init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4028,modifiability,pac,package,4028," 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4556,modifiability,deco,decorator,4556,"ighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4916,modifiability,pac,packaging,4916,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5386,modifiability,pac,packaged,5386,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:443,performance,error,errors,443,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:699,performance,error,error,699,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3638,performance,CPU,CPUDispatcher,3638,"' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3724,performance,error,error,3724,"vities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3735,performance,time,time,3735,"compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4475,performance,bottleneck,bottleneck,4475,"loat32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5527,performance,CPU,CPU,5527,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5602,performance,time,time,5602,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4283,reliability,sli,slightly,4283,"t(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:443,safety,error,errors,443,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:566,safety,manag,managed,566,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:699,safety,error,error,699,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:781,safety,test,test,781,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1329,safety,detect,detected,1329,"ies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1442,safety,Log,Logarithmized,1442," when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neigh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1653,safety,except,exception,1653," However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1701,safety,except,exception,1701,"hen running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._dist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1834,safety,modul,module,1834,"imal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3724,safety,error,error,3724,"vities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4059,safety,avoid,avoid,4059," ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4303,safety,review,review,4303,"andom_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. ju",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5519,safety,log,logical,5519,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5573,safety,updat,updated,5573,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1329,security,detect,detected,1329,"ies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1442,security,Log,Logarithmized,1442," when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neigh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5519,security,log,logical,5519,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5553,security,Session,Session,5553,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5573,security,updat,updated,5573,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:781,testability,test,test,781,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1442,testability,Log,Logarithmized,1442," when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neigh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1546,testability,Trace,Traceback,1546,"omps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, wr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1725,testability,Trace,Traceback,1725,"bors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4303,testability,review,review,4303,"andom_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. ju",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5519,testability,log,logical,5519,"nn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pygments 2.9.0. pyparsing 2.4.7. pytz 2021.1. scipy 1.6.2. scvelo 0.2.3. six 1.16.0. sklearn 0.24.2. storemagic NA. tables 3.6.1. texttable 1.6.4. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. zipp NA. zmq 22.1.0. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10. 96 logical CPU cores, x86_64. -----. Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00). ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:181,usability,confirm,confirmed,181,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:264,usability,confirm,confirmed,264,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:443,usability,error,errors,443,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:699,usability,error,error,699,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:834,usability,Minim,Minimal,834,"TypeError: expected dtype object, got 'numpy.dtype[float64]' when running scanpy on scvelo objects; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated! ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_panc = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1982,usability,user,users,1982,"a_panc, n_top_genes=3000, min_shared_counts=20). del adata_panc.obsm['X_pca']. del adata_panc.obsm['X_umap']. del adata_panc.obsp['distances']. del adata_panc.obsp['connectivities']. adata_panc.X = np.array(adata_panc.X.todense()). sc.pp.pca(adata_panc, n_comps=50). sc.pp.neighbors(adata_panc). ```. ```pytb. Filtered out 20801 genes that are detected 20 counts (shared). Normalized count data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_ne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:2367,usability,user,users,2367,"ount data: X, spliced, unspliced. Extracted 3000 highly variable genes. Logarithmized X. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angula",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:2819,usability,user,users,2819,"7197.py in <module>. 7 adata_panc.X = np.array(adata_panc.X.todense()). 8 sc.pp.pca(adata_panc, n_comps=50). ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3181,usability,user,users,3181,"ded, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 806 # we need self._distances also for method == 'gauss' if we didn't. 807 # use dense distances. --> 808 self._distances, self._connectivities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3724,usability,error,error,3724,"vities = _compute_connectivities_umap(. 809 knn_indices,. 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3976,usability,discov,discoverable,3976,"_neighbors, set_op_mix_ratio, local_connectivity). 388 . 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)). --> 390 connectivities = fuzzy_simplicial_set(. 391 X,. 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose). 600 knn_dists = knn_dists.astype(np.float32). 601 . --> 602 sigmas, rhos = smooth_knn_dist(. 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),. 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00). ```. #### Versions. <details>. ```pytb. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 8.3.1. autotime 0.3.1. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipykernel 6.0.3. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. leidenalg 0.8.7. llvmlite 0.33.0. loompy 3.0.6. louvain 0.7.0. matplotlib 3.4.2. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. numba 0.50.1. numexpr 2.7.3. numpy 1.20.3. numpy_groupies 0.9.13. packaging 21.0. pandas 1.3.0. parso 0.8.2. pexpect 4.8.0. picklesh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1984:249,energy efficiency,current,currently,249,"Difference between distances and connectivities in adata.obsp; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. I am currently working with `sc.pp.neighbours()` and when obtaining the `adata.obsp['distances']` and `adata.obsp['connectivities']` matrices I see some differences that I would like to know why do they happen. For instance, for the pbmc3k dataset, the results I get are:. `object_triku.obsp['distances']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 37800 stored elements in Compressed Sparse Row format>`. and. `object_triku.obsp['connectivities']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 61672 stored elements in Compressed Sparse Row format>`. Mainly, in distance matrix all elements are zero, except n_neighbors elements that are non zero. In connectivities matrices I see that the elements that are nonzero are in the same positions as the nonzero elements from the distance matrix, although sometimes they are more, sometimes they are fewer. This is strange to me because there are cases where the elements in the distances are zero, but its connectivity value is 1. From that point, my question is: which matrix should I value most to get the neighbour graph?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984
https://github.com/scverse/scanpy/issues/1984:666,interoperability,format,format,666,"Difference between distances and connectivities in adata.obsp; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. I am currently working with `sc.pp.neighbours()` and when obtaining the `adata.obsp['distances']` and `adata.obsp['connectivities']` matrices I see some differences that I would like to know why do they happen. For instance, for the pbmc3k dataset, the results I get are:. `object_triku.obsp['distances']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 37800 stored elements in Compressed Sparse Row format>`. and. `object_triku.obsp['connectivities']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 61672 stored elements in Compressed Sparse Row format>`. Mainly, in distance matrix all elements are zero, except n_neighbors elements that are non zero. In connectivities matrices I see that the elements that are nonzero are in the same positions as the nonzero elements from the distance matrix, although sometimes they are more, sometimes they are fewer. This is strange to me because there are cases where the elements in the distances are zero, but its connectivity value is 1. From that point, my question is: which matrix should I value most to get the neighbour graph?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984
https://github.com/scverse/scanpy/issues/1984:835,interoperability,format,format,835,"Difference between distances and connectivities in adata.obsp; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. I am currently working with `sc.pp.neighbours()` and when obtaining the `adata.obsp['distances']` and `adata.obsp['connectivities']` matrices I see some differences that I would like to know why do they happen. For instance, for the pbmc3k dataset, the results I get are:. `object_triku.obsp['distances']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 37800 stored elements in Compressed Sparse Row format>`. and. `object_triku.obsp['connectivities']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 61672 stored elements in Compressed Sparse Row format>`. Mainly, in distance matrix all elements are zero, except n_neighbors elements that are non zero. In connectivities matrices I see that the elements that are nonzero are in the same positions as the nonzero elements from the distance matrix, although sometimes they are more, sometimes they are fewer. This is strange to me because there are cases where the elements in the distances are zero, but its connectivity value is 1. From that point, my question is: which matrix should I value most to get the neighbour graph?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984
https://github.com/scverse/scanpy/issues/1984:189,modifiability,design decis,design decisions,189,"Difference between distances and connectivities in adata.obsp; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. I am currently working with `sc.pp.neighbours()` and when obtaining the `adata.obsp['distances']` and `adata.obsp['connectivities']` matrices I see some differences that I would like to know why do they happen. For instance, for the pbmc3k dataset, the results I get are:. `object_triku.obsp['distances']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 37800 stored elements in Compressed Sparse Row format>`. and. `object_triku.obsp['connectivities']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 61672 stored elements in Compressed Sparse Row format>`. Mainly, in distance matrix all elements are zero, except n_neighbors elements that are non zero. In connectivities matrices I see that the elements that are nonzero are in the same positions as the nonzero elements from the distance matrix, although sometimes they are more, sometimes they are fewer. This is strange to me because there are cases where the elements in the distances are zero, but its connectivity value is 1. From that point, my question is: which matrix should I value most to get the neighbour graph?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984
https://github.com/scverse/scanpy/issues/1984:895,safety,except,except,895,"Difference between distances and connectivities in adata.obsp; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. I am currently working with `sc.pp.neighbours()` and when obtaining the `adata.obsp['distances']` and `adata.obsp['connectivities']` matrices I see some differences that I would like to know why do they happen. For instance, for the pbmc3k dataset, the results I get are:. `object_triku.obsp['distances']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 37800 stored elements in Compressed Sparse Row format>`. and. `object_triku.obsp['connectivities']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 61672 stored elements in Compressed Sparse Row format>`. Mainly, in distance matrix all elements are zero, except n_neighbors elements that are non zero. In connectivities matrices I see that the elements that are nonzero are in the same positions as the nonzero elements from the distance matrix, although sometimes they are more, sometimes they are fewer. This is strange to me because there are cases where the elements in the distances are zero, but its connectivity value is 1. From that point, my question is: which matrix should I value most to get the neighbour graph?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984
https://github.com/scverse/scanpy/issues/1984:87,usability,help,help,87,"Difference between distances and connectivities in adata.obsp; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. I am currently working with `sc.pp.neighbours()` and when obtaining the `adata.obsp['distances']` and `adata.obsp['connectivities']` matrices I see some differences that I would like to know why do they happen. For instance, for the pbmc3k dataset, the results I get are:. `object_triku.obsp['distances']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 37800 stored elements in Compressed Sparse Row format>`. and. `object_triku.obsp['connectivities']`. `<2700x2700 sparse matrix of type '<class 'numpy.float64'>'`. `with 61672 stored elements in Compressed Sparse Row format>`. Mainly, in distance matrix all elements are zero, except n_neighbors elements that are non zero. In connectivities matrices I see that the elements that are nonzero are in the same positions as the nonzero elements from the distance matrix, although sometimes they are more, sometimes they are fewer. This is strange to me because there are cases where the elements in the distances are zero, but its connectivity value is 1. From that point, my question is: which matrix should I value most to get the neighbour graph?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1984
https://github.com/scverse/scanpy/pull/1985:156,availability,error,error,156,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:655,deployability,fail,fail,655,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:272,integrability,sub,subset,272,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:447,integrability,sub,subsetting,447,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:156,performance,error,error,156,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:655,reliability,fail,fail,655,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:156,safety,error,error,156,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:560,safety,test,tests,560,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:560,testability,test,tests,560,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:156,usability,error,error,156,"Account for case when there are fewer dispersed genes than n_top_genes; Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/issues/1986:20,deployability,fail,fails,20,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:180,deployability,version,version,180,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:643,deployability,fail,fails,643,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:933,deployability,modul,module,933,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1401,deployability,Version,Versions,1401,"] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2664,deployability,log,logical,2664,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2710,deployability,updat,updated,2710,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:779,energy efficiency,core,core,779,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1293,energy efficiency,core,core,1293,"de sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pypa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2672,energy efficiency,CPU,CPU,2672,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2676,energy efficiency,core,cores,2676,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:180,integrability,version,version,180,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:399,integrability,batch,batch,399,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:553,integrability,batch,batch,553,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:632,integrability,batch,batch,632,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1004,integrability,batch,batch,1004,".pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1401,integrability,Version,Versions,1401,"] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:180,modifiability,version,version,180,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:762,modifiability,pac,packages,762,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:933,modifiability,modul,module,933,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1076,modifiability,pac,packages,1076,"that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1277,modifiability,pac,packages,1277,"### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndesce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1401,modifiability,Version,Versions,1401,"] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1704,modifiability,deco,decorator,1704,"me/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1977,modifiability,pac,packaging,1977,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2536,modifiability,pac,packaged,2536,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:399,performance,batch,batch,399,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:553,performance,batch,batch,553,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:632,performance,batch,batch,632,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1004,performance,batch,batch,1004,".pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2672,performance,CPU,CPU,2672,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:20,reliability,fail,fails,20,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:643,reliability,fail,fails,643,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:896,safety,input,input-,896,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:933,safety,modul,module,933,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2664,safety,log,logical,2664,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2710,safety,updat,updated,2710,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1344,security,hash,hash,1344,"anpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2664,security,log,logical,2664,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2690,security,Session,Session,2690,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2710,security,updat,updated,2710,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:664,testability,Trace,Traceback,664,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2664,testability,log,logical,2664,"8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas 1.3.1. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. psutil 5.8.0. ptyprocess 0.7.0. pycparser 2.20. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.9.0. pynndescent 0.5.4. pyparsing 2.4.7. pytz 2021.1. scanpy 1.8.1. scipy 1.7.0. sinfo 0.3.1. sitecustomize NA. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. texttable 1.6.4. tqdm 4.61.2. traitlets 5.0.5. umap 0.5.1. wcwidth 0.2.5. -----. Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]. Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10. 16 logical CPU cores. -----. Session information updated at 2021-08-26 10:01. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:140,usability,confirm,confirmed,140,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:223,usability,confirm,confirmed,223,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:285,usability,Minim,Minimal,285,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:784,usability,interact,interactiveshell,784,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:896,usability,input,input-,896,"`scanpy.pl.scatter` fails if list is provided for `color`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. adata = sc.datasets.paul15(). adata.obs['batch'] = np.random.randint(3, size=adata.n_obs). adata.obs['X'] = adata.X[:,1]. adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails. ```. ```pytb. Traceback (most recent call last):. File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-52-9844c466c985>"", line 1, in <module>. sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter. and (color is None or color in adata.obs.keys() or color in adata.var.index). File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__. hash(key). TypeError: unhashable type: 'list'. ```. #### Versions. <details>. ```. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. IPython 7.25.0. PIL 8.3.1. anndata 0.7.6. backcall 0.2.0. backend_interagg NA. beta_ufunc NA. binom_ufunc NA. cffi 1.14.6. colorama 0.4.4. console_thrift NA. cycler 0.10.0. cython_runtime NA. datalore NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.7.1. h5py 2.10.0. igraph 0.9.6. ipython_genutils 0.2.0. jedi 0.18.0. joblib 1.0.1. kiwisolver 1.3.1. llvmlite 0.36.0. louvain 0.7.0. matplotlib 3.4.2. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.18.1. packaging 20.9. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1987:346,availability,error,error,346,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:11,deployability,version,version,11,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:150,deployability,manag,management,150,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:442,deployability,modul,module,442,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1070,deployability,modul,module,1070,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1653,deployability,Modul,ModuleNotFoundError,1653,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1677,deployability,modul,module,1677,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1746,deployability,instal,install,1746,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1801,deployability,instal,install,1801,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1839,deployability,updat,update,1839,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:150,energy efficiency,manag,management,150,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:11,integrability,version,version,11,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:219,integrability,rout,routine,219,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:11,modifiability,version,version,11,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:442,modifiability,modul,module,442,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:553,modifiability,pac,packages,553,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:700,modifiability,pac,packages,700,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:896,modifiability,pac,packages,896,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1070,modifiability,modul,module,1070,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1181,modifiability,pac,packages,1181,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1328,modifiability,pac,packages,1328,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1524,modifiability,pac,packages,1524,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1653,modifiability,Modul,ModuleNotFoundError,1653,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1677,modifiability,modul,module,1677,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1720,modifiability,pac,package,1720,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:346,performance,error,error,346,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:150,safety,manag,management,150,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:346,safety,error,error,346,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:442,safety,modul,module,442,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1070,safety,modul,module,1070,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1653,safety,Modul,ModuleNotFoundError,1653,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1677,safety,modul,module,1677,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1839,safety,updat,update,1839,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1839,security,updat,update,1839,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:357,testability,Trace,Traceback,357,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1790,testability,simpl,simply,1790,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:346,usability,error,error,346,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1759,usability,learn,learn,1759,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1790,usability,simpl,simply,1790,"Solved; My version of scanpy:. scanpy 1.8.1 pyhd8ed1ab_0 conda-forge. I'm working on a linux system based server, and uses miniconda3 for environment management. After some changes in my environment, I tried to run the routine process of my analysis. But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):. File ""/data1/exhaustT/process.py"", line 118, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. File ""/data1/exhaustT/umap.py"", line 48, in <module>. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors. neighbors.compute_neighbors(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors. self._distances, self._connectivities = _compute_connectivities_umap(. File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap. from umap.umap_ import fuzzy_simplicial_set. ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1988:130,deployability,version,version,130,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:271,deployability,version,version,271,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:312,deployability,version,version,312,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:466,deployability,version,version,466,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:804,deployability,Version,Versions,804,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2266,deployability,log,logical,2266,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2312,deployability,updat,updated,2312,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2274,energy efficiency,CPU,CPU,2274,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2278,energy efficiency,core,cores,2278,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:130,integrability,version,version,130,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:271,integrability,version,version,271,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:312,integrability,version,version,312,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:466,integrability,version,version,466,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:804,integrability,Version,Versions,804,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:130,modifiability,version,version,130,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:271,modifiability,version,version,271,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:312,modifiability,version,version,312,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:466,modifiability,version,version,466,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:804,modifiability,Version,Versions,804,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:1074,modifiability,deco,decorator,1074,"[ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:1433,modifiability,pac,packaging,1433,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2146,modifiability,pac,packaged,2146,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2274,performance,CPU,CPU,2274,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2266,safety,log,logical,2266,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2312,safety,updat,updated,2312,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:558,security,modif,modifies,558,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2266,security,log,logical,2266,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2292,security,Session,Session,2292,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2312,security,updat,updated,2312,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:1775,testability,simpl,simplegeneric,1775,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2266,testability,log,logical,2266,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:90,usability,confirm,confirmed,90,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:173,usability,confirm,confirmed,173,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:698,usability,user,user-images,698,"pl.umap; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I started today using a newer version of scanpy (1.7.2). Before I used version 1.6.0. When I plot the UMAP I realised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:1775,usability,simpl,simplegeneric,1775,"alised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python. scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'). ```. ```pytb. ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png). ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. MulticoreTSNE NA. PIL 8.0.1. anndata 0.7.5. annoy NA. attr 20.3.0. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. idna 2.10. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. jsonschema 3.2.0. kaleido 0.2.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. nbformat 5.1.3. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.14.3. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pvectorc NA. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pyrsistent NA. pytz 2020.4. retrying NA. scanpy 1.7.2. scipy 1.5.3. scvi 0.6.8. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. solo 0.1. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. torch 1.8.1+cu102. tornado 6.1. tqdm 4.54.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-08-30 15:50. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1989:269,availability,error,error,269,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:149,deployability,version,version,149,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:332,deployability,version,version,332,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:778,deployability,modul,module,778,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2870,deployability,updat,update,2870,"seq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:3785,deployability,Version,Versions,3785,"rn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5033,deployability,log,logical,5033," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5079,deployability,updat,updated,5079," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5041,energy efficiency,CPU,CPU,5041," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5045,energy efficiency,core,cores,5045," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:149,integrability,version,version,149,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:332,integrability,version,version,332,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:3785,integrability,Version,Versions,3785,"rn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:149,modifiability,version,version,149,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:332,modifiability,version,version,332,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:778,modifiability,modul,module,778,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:1037,modifiability,pac,packages,1037,"checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=met",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:1453,modifiability,pac,packages,1453,"(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:1909,modifiability,pac,packages,1909,"ap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2161,modifiability,pac,packages,2161,"pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2457,modifiability,pac,packages,2457,"/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2775,modifiability,pac,packages,2775," 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2907,modifiability,paramet,parameters,2907,"kages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cach",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:3047,modifiability,pac,packages,3047,"306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:3785,modifiability,Version,Versions,3785,"rn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:4024,modifiability,deco,decorator,4024,"ib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:4323,modifiability,pac,packaging,4323," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:4913,modifiability,pac,packaged,4913," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:269,performance,error,error,269,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:1685,performance,parallel,parallel,1685,"-----. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5041,performance,CPU,CPU,5041," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:269,safety,error,error,269,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:751,safety,input,input-,751,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:778,safety,modul,module,778,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2798,safety,valid,validation,2798,"= 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2870,safety,updat,update,2870,"seq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:3206,safety,Valid,Valid,3206,"out(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:3379,safety,Valid,Valid,3379," else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5033,safety,log,logical,5033," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5079,safety,updat,updated,5079," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2798,security,validat,validation,2798,"= 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2870,security,updat,update,2870,"seq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 metric_kwds=metric_kwds,. 307 ). 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds). 191 random_state,. 192 metric=metric,. --> 193 metric_kwds=metric_kwds,. 194 ). 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds). 120 else:. 121 distance_matrix = pairwise_distances(. --> 122 component_centroids, metric=metric, **metric_kwds. 123 ). 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs). 70 FutureWarning). 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}). ---> 72 return f(**kwargs). 73 return inner_f. 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5033,security,log,logical,5033," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5059,security,Session,Session,5059," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5079,security,updat,updated,5079," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:707,testability,Trace,Traceback,707,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:4584,testability,simpl,simplegeneric,4584," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5033,testability,log,logical,5033," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:109,usability,confirm,confirmed,109,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:192,usability,confirm,confirmed,192,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:269,usability,error,error,269,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:351,usability,Minim,Minimal,351,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:751,usability,input,input-,751,"scanpy.tl.umap after bbknn; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:1053,usability,tool,tools,1053,"is issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). . ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-73-a5a2e6833485> in <module>(). 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True). ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 205 neigh_params.get('metric', 'euclidean'),. 206 neigh_params.get('metric_kwds', {}),. --> 207 verbose=settings.verbosity > 3,. 208 ). 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose). 1037 random_state,. 1038 metric=metric,. -> 1039 metric_kwds=metric_kwds,. 1040 ). 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds). 304 random_state,. 305 metric=metric,. --> 306 m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:4584,usability,simpl,simplegeneric,4584," n_jobs, force_all_finite, **kwds). 1738 raise ValueError(""Unknown metric %s. "". 1739 ""Valid metrics are %s, or 'precomputed', or a "". -> 1740 ""callable"" % (metric, _VALID_METRICS)). 1741 . 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.5. annoy NA. bbknn NA. cached_property 1.5.1. cairo 1.20.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. louvain 0.6.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 1.0.15. psutil 5.8.0. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. scanpy 1.7.2. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. simplegeneric NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. zipp NA. zmq 20.0.0. -----. IPython 5.8.0. jupyter_client 6.1.7. jupyter_core 4.7.0. -----. Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]. Linux-4.9.0-16-amd64-x86_64-with-debian-9.13. 8 logical CPU cores. -----. Session information updated at 2021-09-01 08:49. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1990:172,availability,error,error,172,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:911,availability,cluster,cluster,911,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:992,availability,cluster,cluster,992,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1698,availability,sli,slice,1698,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:445,deployability,modul,module,445,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:663,deployability,log,log,663,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:911,deployability,cluster,cluster,911,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:992,deployability,cluster,cluster,992,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1099,energy efficiency,core,core,1099,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1380,energy efficiency,core,core,1380,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1625,energy efficiency,core,core,1625,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:185,integrability,Filter,Filtering,185,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:445,modifiability,modul,module,445,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:561,modifiability,pac,packages,561,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1083,modifiability,pac,packages,1083,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1364,modifiability,pac,packages,1364,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1609,modifiability,pac,packages,1609,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:172,performance,error,error,172,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:1698,reliability,sli,slice,1698,"not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:172,safety,error,error,172,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:445,safety,modul,module,445,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:663,safety,log,log,663,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:663,security,log,log,663,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:371,testability,Trace,Traceback,371,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:663,testability,log,log,663,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:172,usability,error,error,172,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:577,usability,tool,tools,577,"KeyError: 'True: boolean label can not be used without a boolean index'; I was running this:. `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`. Which gave me this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /tmp/ipykernel_30806/3135920018.py in <module>. ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the. 587 # structure of the gene_names dataFrame. --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values. 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values. 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key). 929 . 930 maybe_callable = com.apply_if_callable(key, self.obj). --> 931 return self._getitem_axis(maybe_callable, axis=axis). 932 . 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1161 . 1162 # fall thru to straight lookup. -> 1163 self._validate_key(key, axis). 1164 return self._get_label(key, axis=axis). 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis). 970 # boolean not in slice and with boolean index. 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):. --> 972 raise KeyError(. 973 f""{key}: boolean label can not be used without a boolean index"". 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```. Any ideas? I'm using Sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1991:22,performance,network,network,22,"How to write out paga network datas?; Hi,. Is there a way to write out the resulting network file (either adjacency matrix, or edge list, etc). Could someone please point me to an example? Thanks in advance! Best,. Kun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1991
https://github.com/scverse/scanpy/issues/1991:85,performance,network,network,85,"How to write out paga network datas?; Hi,. Is there a way to write out the resulting network file (either adjacency matrix, or edge list, etc). Could someone please point me to an example? Thanks in advance! Best,. Kun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1991
https://github.com/scverse/scanpy/issues/1991:22,security,network,network,22,"How to write out paga network datas?; Hi,. Is there a way to write out the resulting network file (either adjacency matrix, or edge list, etc). Could someone please point me to an example? Thanks in advance! Best,. Kun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1991
https://github.com/scverse/scanpy/issues/1991:85,security,network,network,85,"How to write out paga network datas?; Hi,. Is there a way to write out the resulting network file (either adjacency matrix, or edge list, etc). Could someone please point me to an example? Thanks in advance! Best,. Kun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1991
https://github.com/scverse/scanpy/issues/1992:125,modifiability,paramet,parameters,125,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:402,modifiability,pac,package,402,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:207,testability,simpl,simple,207,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:199,usability,tool,tool,199,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:207,usability,simpl,simple,207,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:223,usability,tool,tool,223,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:271,usability,tool,tools,271,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:371,usability,tool,tools,371,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1992:623,usability,user,user-images,623,"how to select cells manually in scanpy?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... I want to save h5ad object without cells in the red circle, how to do that in scanpy? Thank you. ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/issues/1993:183,deployability,version,version,183,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:284,deployability,Version,Version,284,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:183,integrability,version,version,183,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:284,integrability,Version,Version,284,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:431,integrability,sub,subsequent,431,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:183,modifiability,version,version,183,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:284,modifiability,Version,Version,284,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:525,reliability,doe,does,525,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:143,usability,confirm,confirmed,143,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:226,usability,confirm,confirmed,226,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:913,usability,user,user-images,913,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1993:1226,usability,user,user-images,1226,"Different connectivties and UMAP if using data in X or obsm; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Version: '1.8.0.dev70+g560bd5d3'. ---. I have made adata with same data in X and obsm. Then I used either of those two matrices for neighbours and subsequent UMAP. The connectives and UMAPs however look different despite same starting data (does not seem to be due to randomness as I get same UMAPs with same representations on multiple runs). ```. # Adata. adata_pb=sc.AnnData(latent_pb). adata_pb.obsm['X_integrated']=latent_pb. # From rep=X. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X'). c_x=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199693-d4f5deb4-9ea4-4ccb-a279-55d672861471.png). ```. # From rep=obsm. sc.pp.neighbors(adata_pb,n_pcs=0,use_rep='X_integrated'). c_o=adata_pb.obsp['connectivities']. sc.tl.umap(adata_pb). rcParams['figure.figsize']=(6,6). sc.pl.umap(adata_pb). ```. ![image](https://user-images.githubusercontent.com/47607471/132199742-a1536ec2-f57f-423e-8de0-19de61623e62.png). ```. np.allclose(c_x.A, c_o.A). False. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1993
https://github.com/scverse/scanpy/issues/1995:14,availability,error,error,14,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2408,availability,error,error,2408,"values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:169,deployability,version,version,169,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:622,deployability,automat,automatically,622,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1053,deployability,modul,module,1053,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1084,deployability,automat,automatically,1084,"t already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2429,deployability,Version,Versions,2429,",. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3980,deployability,log,logical,3980,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:4032,deployability,updat,updated,4032,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:0,energy efficiency,CPU,CPUDispatcher,0,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2311,energy efficiency,CPU,CPUDispatcher,2311,"_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2617,energy efficiency,cloud,cloudpickle,2617,", layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3988,energy efficiency,CPU,CPU,3988,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3992,energy efficiency,core,cores,3992,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:169,integrability,version,version,169,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:604,integrability,sub,subset,604,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:636,integrability,sub,subset,636,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1066,integrability,sub,subset,1066,"that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1098,integrability,sub,subset,1098,"been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1377,integrability,sub,subset,1377,"etailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1440,integrability,sub,subset,1440,"roduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1447,integrability,sub,subset,1447,"your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1676,integrability,sub,subset,1676,"flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2429,integrability,Version,Versions,2429,",. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:32,modifiability,variab,variable,32,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:169,modifiability,version,version,169,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:662,modifiability,layer,layer,662,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1053,modifiability,modul,module,1053,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1126,modifiability,layer,layer,1126,"confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1207,modifiability,pac,packages,1207," confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1295,modifiability,layer,layer,1295,"this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1526,modifiability,pac,packages,1526,"a). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1625,modifiability,layer,layer,1625,"tically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1824,modifiability,pac,packages,1824,"ll last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2105,modifiability,pac,packages,2105,"he 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2429,modifiability,Version,Versions,2429,",. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2730,modifiability,deco,decorator,2730,"nces'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3076,modifiability,pac,packaging,3076,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:0,performance,CPU,CPUDispatcher,0,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:14,performance,error,error,14,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2311,performance,CPU,CPUDispatcher,2311,"_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2408,performance,error,error,2408,"values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2586,performance,bottleneck,bottleneck,2586,"y_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3988,performance,CPU,CPU,3988,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:14,safety,error,error,14,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:910,safety,except,exception,910,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:958,safety,except,exception,958,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1026,safety,input,input-,1026,"ly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1053,safety,modul,module,1053,"have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2408,safety,error,error,2408,"values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3980,safety,log,logical,3980,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:4032,safety,updat,updated,4032,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3980,security,log,logical,3980,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:4012,security,Session,Session,4012,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:4032,security,updat,updated,4032,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:622,testability,automat,automatically,622,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:803,testability,Trace,Traceback,803,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:982,testability,Trace,Traceback,982,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1084,testability,automat,automatically,1084,"t already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3414,testability,simpl,simplejson,3414,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3980,testability,log,logical,3980,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:14,usability,error,error,14,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:129,usability,confirm,confirmed,129,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:212,usability,confirm,confirmed,212,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:303,usability,guid,guide,303,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:358,usability,minim,minimal-bug-reports,358,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:464,usability,Minim,Minimal,464,"CPUDispatcher error with highly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:1026,usability,input,input-,1026,"ly variable genes; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.highly_variable_genes(. adata,. n_top_genes=4000,. # subset=True, # to automatically subset to the 4000 genes. layer=""counts"",. flavor=""seurat_v3"". ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last). <ipython-input-15-144c5f8e718e> in <module>. 4 # subset=True, # to automatically subset to the 4000 genes. 5 layer=""counts"",. ----> 6 flavor=""seurat_v3"". 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2408,usability,error,error,2408,"values). 425 span=span,. 426 subset=subset,. --> 427 inplace=inplace,. 428 ). 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 65 ). 66 . ---> 67 df['means'], df['variances'] = _get_mean_var(X). 68 . 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis). 6 def _get_mean_var(X, *, axis=0):. 7 if sparse.issparse(X):. ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis). 9 else:. 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3414,usability,simpl,simplejson,3414,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3595,usability,tool,toolz,3595,". ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis). 40 ). 41 else:. ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64). 43 . 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set. ```. #### Versions. <details>. -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 6.2.0. absl NA. attr 19.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.2.1. cffi 1.12.3. cloudpickle 1.2.2. colorama 0.4.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.0. dask 2.5.2. dateutil 2.8.0. decorator 4.4.0. deprecate 0.3.0. fsspec 2021.08.1. google NA. h5py 2.10.0. ipykernel 5.1.2. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.15.1. joblib 0.13.2. kiwisolver 1.1.0. llvmlite 0.29.0. matplotlib 3.4.3. more_itertools NA. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.45.1. numexpr 2.7.0. numpy 1.21.2. opt_einsum v3.3.0. packaging 21.0. pandas 1.3.2. parso 0.5.1. pexpect 4.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 2.0.10. psutil 5.6.3. ptyprocess 0.6.0. pycparser 2.19. pygments 2.10.0. pyparsing 2.4.2. pyro 1.7.0. pytorch_lightning 1.3.8. pytz 2019.3. rich NA. scipy 1.7.1. scvi 0.13.0. seaborn 0.9.0. setuptools 41.4.0. setuptools_scm NA. simplejson 3.17.2. six 1.12.0. sklearn 0.24.2. skmisc 0.1.4. sphinxcontrib NA. statsmodels 0.10.1. storemagic NA. tables 3.5.2. tblib 1.4.0. tensorboard 2.6.0. threadpoolctl 2.2.0. toolz 0.10.0. torch 1.9.0. torchmetrics 0.5.1. tornado 6.0.3. tqdm 4.56.0. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.1.2. zipp NA. zmq 18.1.0. -----. IPython 7.8.0. jupyter_client 5.3.3. jupyter_core 4.5.0. jupyterlab 1.1.4. notebook 6.0.1. -----. Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]. Darwin-20.5.0-x86_64-i386-64bit. 8 logical CPU cores, i386. -----. Session information updated at 2021-09-08 10:28. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1996:332,availability,down,downgrade,332,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:514,availability,sli,slightly,514,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:311,deployability,instal,installs,311,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:448,deployability,instal,install,448,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:211,integrability,discover,discoverable,211,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:393,integrability,messag,message,393,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:211,interoperability,discover,discoverable,211,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:393,interoperability,messag,message,393,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:140,modifiability,pac,package,140,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:261,modifiability,pac,package,261,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:514,reliability,sli,slightly,514,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:292,safety,avoid,avoid,292,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:534,safety,review,review,534,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:534,testability,review,review,534,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:211,usability,discov,discoverable,211,"sinfo is now session_info; https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1997:2851,availability,down,downgrading,2851,".2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.nod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3261,availability,down,downgrade,3261,"0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3333,availability,down,downgrading,3333,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:180,deployability,instal,installation,180,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:223,deployability,version,version,223,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:884,deployability,Version,Versions,884,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:956,deployability,log,logging,956,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2579,deployability,log,logical,2579,"ort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2677,deployability,updat,updated,2677,"kaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2732,deployability,stack,stackoverflow,2732," pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_soli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2755,deployability,stack,stackoverflow,2755,"pt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2875,deployability,version,version,2875,"ythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3025,deployability,modul,module,3025,"A. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3163,deployability,stack,stackoverflow,3163,"0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3407,deployability,stack,stackoverflow,3407,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3459,deployability,modul,module-matplotlib-cbook-has-no-attribute-iterable,3459,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3611,deployability,instal,installation,3611,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1240,energy efficiency,cloud,cloudpickle,1240,"orkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2587,energy efficiency,CPU,CPU,2587,"1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2591,energy efficiency,core,cores,2591,"networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2615,energy efficiency,Model,Model,2615,"tsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy install",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3279,energy efficiency,current,current,3279,"gs 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3304,energy efficiency,current,current,3304,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:223,integrability,version,version,223,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:884,integrability,Version,Versions,884,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2875,integrability,version,version,2875,"ythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:25,interoperability,format,format,25,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:143,interoperability,format,format,143,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2951,interoperability,incompatib,incompatibility,2951," sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_soli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:223,modifiability,version,version,223,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:688,modifiability,pac,packages,688,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:884,modifiability,Version,Versions,884,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1354,modifiability,deco,decorator,1354,"sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1678,modifiability,pac,packaging,1678,"site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information update",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2875,modifiability,version,version,2875,"ythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3025,modifiability,modul,module,3025,"A. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3459,modifiability,modul,module-matplotlib-cbook-has-no-attribute-iterable,3459,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:908,performance,network,networkx,908,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1169,performance,bottleneck,bottleneck,1169,"y own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1594,performance,network,networkx,1594,"ne, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2587,performance,CPU,CPU,2587,"1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/pag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2866,performance,network,networkx,2866," 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2975,performance,network,networkx,2975," sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['labe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3120,performance,network,networkx,3120,"bles 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3350,performance,network,networkx,3350,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:956,safety,log,logging,956,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2579,safety,log,logical,2579,"ort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2677,safety,updat,updated,2677,"kaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3025,safety,modul,module,3025,"A. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3459,safety,modul,module-matplotlib-cbook-has-no-attribute-iterable,3459,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:908,security,network,networkx,908,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:956,security,log,logging,956,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1594,security,network,networkx,1594,"ne, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2579,security,log,logical,2579,"ort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2615,security,Model,Model,2615,"tsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy install",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2657,security,Session,Session,2657,"1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2677,security,updat,updated,2677,"kaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2866,security,network,networkx,2866," 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2975,security,network,networkx,2975," sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['labe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3120,security,network,networkx,3120,"bles 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3350,security,network,networkx,3350,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:956,testability,log,logging,956,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2031,testability,spy,spyder,2031,"nt_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2067,testability,spy,spydercustomize,2067,"1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2579,testability,log,logical,2579,"ort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3093,testability,trace,traces,3093,"ls 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3628,testability,simpl,simply,3628,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:292,usability,Minim,Minimal,292,"Exporting a PAGA to gexf format: AttributeError: 'Graph' object has no attribute 'node'; Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date). Minimal working example:. ```python. import scanpy as sc. paul15 = sc.datasets.paul15(). sc.pp.recipe_zheng17(paul15). sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20). sc.tl.paga(paul15, groups='paul15_clusters'). sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph. nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```. #### Versions. scanpy 1.8.1. networkx 2.6.2. matplotlib 3.4.3. <details>. sc.logging.print_versions(). WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.8.1. sinfo 0.3.1. -----. PIL 8.0.1. PyQt5 NA. anndata 0.7.6. autoreload NA. backcall 0.2.0. bottleneck 1.3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2178,usability,tool,toolz,2178,".3.2. bs4 4.9.3. cairo 1.20.1. cffi 1.14.3. chardet 3.0.4. cloudpickle 1.6.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. h5py 2.10.0. html5lib 1.1. igraph 0.9.6. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.1. joblib 1.0.1. kiwisolver 1.3.0. leidenalg 0.8.7. llvmlite 0.34.0. lxml 4.6.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 7.1.1. networkx 2.6.2. nt NA. ntsecuritycon NA. numba 0.51.2. numexpr 2.7.1. numpy 1.20.3. packaging 20.4. pandas 1.3.2. parso 0.7.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. pyarrow 0.16.0. pycparser 2.20. pygments 2.7.2. pynndescent 0.5.2. pyparsing 2.4.7. pythoncom NA. pytz 2020.1. pywintypes NA. scanpy 1.8.1. scipy 1.5.2. sinfo 0.3.1. sip NA. six 1.15.0. sklearn 0.23.2. soupsieve 2.0.1. sphinxcontrib NA. spyder 4.1.5. spyder_kernels 1.9.4. spydercustomize NA. statsmodels 0.12.0. storemagic NA. tables 3.6.1. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. wcwidth 0.2.5. webencodings 0.5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow sugg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3628,usability,simpl,simply,3628,".5.1. win32api NA. win32com NA. win32security NA. yaml 5.3.1. zmq 19.0.2. zope NA. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.19041-SP0. 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel. -----. Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb. AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'. ```. . which traces back to an issue in networkx rather than scanpy. The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: . After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.node[count]['label'] = str(node_labels[count]). nx_g_solid.node[count]['color'] = str(colors[count]). nx_g_solid.node[count]['viz'] = dict(. ```. to. ```python. for count, n in enumerate(nx_g_solid.nodes()):. nx_g_solid.nodes[count]['label'] = str(node_labels[count]). nx_g_solid.nodes[count]['color'] = str(colors[count]). nx_g_solid.nodes[count]['viz'] = dict(. ```. which apparently solved the issue. ```pytb. gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). WARNING: exporting to write\paga_graph.gexf. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1998:936,availability,state,state,936,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:180,deployability,api,api,180,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:1084,deployability,scale,scaled,1084,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:1084,energy efficiency,scale,scaled,1084,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:1204,energy efficiency,current,currently,1204,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:180,integrability,api,api,180,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:936,integrability,state,state,936,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:180,interoperability,api,api,180,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:243,modifiability,paramet,parameter,243,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:1084,modifiability,scal,scaled,1084,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:1084,performance,scale,scaled,1084,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:290,reliability,doe,does,290,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:927,reliability,doe,does,927,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:34,usability,visual,visualisation,34,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:124,usability,visual,visualising,124,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:184,usability,document,documentation,184,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:253,usability,document,documentation,253,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:307,usability,clear,clear,307,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:667,usability,help,helpful,667,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:818,usability,visual,visualisation,818,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:896,usability,visual,visualizing-marker-genes,896,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/issues/1998:999,usability,visual,visualisations,999,"recommended/default data type for visualisation is obscure; I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/pull/1999:612,availability,error,error,612,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:419,integrability,sub,subset,419,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:618,integrability,messag,message,618,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:618,interoperability,messag,message,618,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:612,performance,error,error,612,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:262,safety,review,review,262,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:612,safety,error,error,612,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:262,testability,review,review,262,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:113,usability,guid,guidelines,113,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:144,usability,guid,guide,144,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:240,usability,workflow,workflow,240,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:612,usability,error,error,612,"Fix use_raw=None in scanpy.tl.score_genes; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names. Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/issues/2000:0,deployability,Depend,Dependencies,0,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:113,deployability,depend,dependencies,113,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:223,deployability,instal,installation,223,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:418,deployability,version,version,418,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:608,deployability,instal,install,608,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1064,deployability,modul,module,1064,"oompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1077,deployability,instal,installed,1077,"iomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1140,deployability,modul,module,1140,"package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1153,deployability,instal,installed,1153,"st in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1491,deployability,Modul,ModuleNotFoundError,1491,"branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1515,deployability,modul,module,1515," ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1548,deployability,Version,Versions,1548,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2441,deployability,log,logical,2441,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2493,deployability,updat,updated,2493,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:938,energy efficiency,core,core,938,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1383,energy efficiency,core,core,1383,"ed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2449,energy efficiency,CPU,CPU,2449,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2453,energy efficiency,core,cores,2453,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:0,integrability,Depend,Dependencies,0,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:113,integrability,depend,dependencies,113,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:418,integrability,version,version,418,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1548,integrability,Version,Versions,1548,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:0,modifiability,Depend,Dependencies,0,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:33,modifiability,pac,package,33,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:113,modifiability,depend,dependencies,113,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:143,modifiability,pac,package,143,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:418,modifiability,version,version,418,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:962,modifiability,pac,packages,962,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1064,modifiability,modul,module,1064,"oompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1140,modifiability,modul,module,1140,"package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1407,modifiability,pac,packages,1407,"latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1491,modifiability,Modul,ModuleNotFoundError,1491,"branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1515,modifiability,modul,module,1515," ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1548,modifiability,Version,Versions,1548,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2081,modifiability,pac,packaging,2081,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1746,performance,bottleneck,bottleneck,1746,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2449,performance,CPU,CPU,2449,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:0,safety,Depend,Dependencies,0,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:113,safety,depend,dependencies,113,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1064,safety,modul,module,1064,"oompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1140,safety,modul,module,1140,"package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1491,safety,Modul,ModuleNotFoundError,1491,"branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1515,safety,modul,module,1515," ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2441,safety,log,logical,2441,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2493,safety,updat,updated,2493,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2441,security,log,logical,2441,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2473,security,Session,Session,2473,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2493,security,updat,updated,2493,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:0,testability,Depend,Dependencies,0,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:113,testability,depend,dependencies,113,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2441,testability,log,logical,2441,"de sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]. Darwin-20.4.0-x86_64-i386-64bit. 12 logical CPU cores, i386. -----. Session information updated at 2021-09-15 10:41. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:378,usability,confirm,confirmed,378,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:461,usability,confirm,confirmed,461,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:523,usability,Minim,Minimal,523,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:900,usability,User,Users,900,"Dependencies missing in bioconda package; Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now . the package (at least in bioconda) is not fully functional and requieres some extra installation. steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1345,usability,User,Users,1345,"y been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data). ```bash. conda install -c bioconda scanpy. ````. ```python. import scanpy as sc. annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]). ```. ```pytb. line 108, in biomart_annotations. return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query. ""This method requires the `pybiomart` module to be installed."". ImportError: This method requires the `pybiomart` module to be installed. ```. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). adata.write_loom('dummy.loom'). ```. ```pytb. write_loom(filename, self, write_obsm_varm=write_obsm_varm). File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom. from loompy import create. ModuleNotFoundError: No module named 'loompy'. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.6. scanpy 1.7.2. sinfo 0.3.1. -----. PIL 8.3.1. anndata 0.7.6. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.6. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. dunamai 1.6.0. get_version 3.5. h5py 2.10.0. joblib 1.0.1. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. llvmlite 0.36.0. matplotlib 3.4.2. mkl 2.4.0. mpl_toolkits NA. natsort 7.1.1. nbinom_ufunc NA. numba 0.53.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.3.2. pkg_resources NA. pyparsing 2.4.7. pytz 2021.1. scanpy 1.7.2. scipy 1.7.1. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 0.24.2. sphinxcontrib NA. tables 3.6.1. tqdm 4.62.1. typing_extensions NA. yaml 5.4.1. zipp NA. -----. Python ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2001:810,availability,Error,Error,810,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:7,deployability,fail,fails,7,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:197,deployability,version,version,197,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:993,deployability,modul,module,993,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1669,deployability,Version,Versions,1669,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1693,deployability,log,logging,1693,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:197,integrability,version,version,197,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:816,integrability,messag,message,816,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1669,integrability,Version,Versions,1669,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:461,interoperability,share,share,461,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:816,interoperability,messag,message,816,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:197,modifiability,version,version,197,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:993,modifiability,modul,module,993,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1472,modifiability,Variab,Variables,1472,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1526,modifiability,variab,variables,1526,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1573,modifiability,Variab,Variables,1573,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1619,modifiability,variab,variables,1619,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1669,modifiability,Version,Versions,1669,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:810,performance,Error,Error,810,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:7,reliability,fail,fails,7,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:810,safety,Error,Error,810,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:966,safety,input,input-,966,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:993,safety,modul,module,993,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1693,safety,log,logging,1693,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1693,security,log,logging,1693,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:922,testability,Trace,Traceback,922,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1693,testability,log,logging,1693,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:157,usability,confirm,confirmed,157,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:241,usability,confirm,confirmed,241,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:493,usability,Minim,Minimal,493,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:810,usability,Error,Error,810,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:966,usability,input,input-,966,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1081,usability,tool,tools,1081,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1343,usability,tool,tools,1343,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1822,usability,learn,learn,1822,"Ingest fails when features are not 100% the same for both adata objects.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master). I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.datasets.paul15(). sc.pp.pca(adata_ref). sc.pp.neighbors(adata_ref). sc.tl.leiden(adata_ref). adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes. sc.tl.ingest(adata, adata_ref, obs='leiden'). ```. Error message. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-37-b3cd11e67810> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 125 . 126 ing = Ingest(adata_ref, neighbors_key). --> 127 ing.fit(adata). 128 . 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new). 437 . 438 if not ref_var_names.equals(new_var_names):. --> 439 raise ValueError(. 440 'Variables in the new adata are different '. 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata. ```. --- . #### Versions. <details>. sc.logging.print_header(). scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2002:114,modifiability,paramet,parameters,114,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:391,modifiability,pac,package,391,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:196,testability,simpl,simple,196,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:661,testability,plan,plan,661,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:188,usability,tool,tool,188,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:196,usability,simpl,simple,196,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:212,usability,tool,tool,212,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:260,usability,tool,tools,260,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2002:360,usability,tool,tools,360,"scanorama corrected matrices; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hi,. ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. . Thanks! Hurley.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2003:0,availability,Error,Error,0,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:399,availability,error,error,399,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:167,deployability,version,version,167,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1097,deployability,modul,module,1097,"een reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3642,deployability,patch,patch,3642,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3929,deployability,Log,LogNorm,3929,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4080,deployability,scale,scaled,4080,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4135,deployability,scale,scaled,4135,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4605,deployability,Version,Versions,4605,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3078,energy efficiency,draw,drawedges,3078," **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3911,energy efficiency,Power,PowerNorm,3911,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4080,energy efficiency,scale,scaled,4080,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4135,energy efficiency,scale,scaled,4135,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:167,integrability,version,version,167,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2653,integrability,wrap,wrapper,2653,"41 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\user",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2850,integrability,wrap,wrapper,2850,"deep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4605,integrability,Version,Versions,4605,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:16,interoperability,ontolog,ontology,16,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:303,interoperability,ontolog,ontology,303,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2653,interoperability,wrapper,wrapper,2653,"41 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\user",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2850,interoperability,wrapper,wrapper,2850,"deep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3070,interoperability,format,format,3070," mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3149,interoperability,format,formatter,3149,"b.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3161,interoperability,format,format,3161,"ormal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3185,interoperability,Format,Formatter,3185,"\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:167,modifiability,version,version,167,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1097,modifiability,modul,module,1097,"een reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1567,modifiability,pac,packages,1567,"rk/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1907,modifiability,pac,packages,1907,"idth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2239,modifiability,pac,packages,2239,"6 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2609,modifiability,pac,packages,2609,", mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2684,modifiability,paramet,parameter,2684,"v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\progra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2761,modifiability,paramet,parameter,2761,"lorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_value",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2926,modifiability,pac,packages,2926,"orbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3046,modifiability,exten,extend,3046," 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3097,modifiability,exten,extendfrac,3097,"1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3109,modifiability,exten,extendrect,3109,"appable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3332,modifiability,pac,packages,3332,"pable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3473,modifiability,exten,extend,3473,"229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3635,modifiability,exten,extend,3635,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3717,modifiability,pac,packages,3717,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4008,modifiability,pac,packages,4008,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4080,modifiability,scal,scaled,4080,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4135,modifiability,scal,scaled,4135,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4292,modifiability,pac,packages,4292,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4605,modifiability,Version,Versions,4605,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:0,performance,Error,Error,0,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:399,performance,error,error,399,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4080,performance,scale,scaled,4080,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4135,performance,scale,scaled,4135,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:0,safety,Error,Error,0,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:399,safety,error,error,399,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1070,safety,input,input-,1070,"his issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1097,safety,modul,module,1097,"een reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1162,safety,input,input-,1162,"t version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3642,safety,patch,patch,3642,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3929,safety,Log,LogNorm,3929,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3642,security,patch,patch,3642,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3929,security,Log,LogNorm,3929,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1026,testability,Trace,Traceback,1026,"ment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwarg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3441,testability,unit,units,3441,".__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3559,testability,unit,units,3559,"ppdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3929,testability,Log,LogNorm,3929,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:0,usability,Error,Error,0,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:127,usability,confirm,confirmed,127,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:210,usability,confirm,confirmed,210,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:399,usability,error,error,399,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:488,usability,help,help,488,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:530,usability,guid,guide,530,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:585,usability,minim,minimal-bug-reports,585,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:691,usability,Minim,Minimal,691,"Error with gene ontology enrichment analysis; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = Color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1070,usability,input,input-,1070,"his issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1162,usability,input,input-,1162,"t version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1503,usability,user,users,1503,"te**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:1843,usability,user,users,1843,"s('p_value').iloc[:,[2,5,7,10,1]. pd.set_option(""display.max_colwidth"", 800). first_enrichment_results.iloc[:50,:]. plot_enrich(first_enrichment_results). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-28-72ef52261ce6> in <module>. ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 ret",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2175,usability,user,users,2175,"1a548> in plot_enrich(data, n_terms, save). 75 fig = plt.gcf(). 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]). ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes). 78 cbar.ax.set_yticklabels(ticks_labs). 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2545,usability,user,users,2545,"\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2341 'panchor']. 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}. -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw). 2344 . 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2862,usability,user,users,2862,"a\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs). 1732 cb = ColorbarPatch(cax, mappable, **kwargs). 1733 else:. -> 1734 cb = Colorbar(cax, mappable, **kwargs). 1735 . 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3268,usability,user,users,3268,"in __init__(self, ax, mappable, **kwargs). 1226 if isinstance(mappable, martist.Artist):. 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()). -> 1228 ColorbarBase.__init__(self, ax, **kwargs). 1229 . 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3653,usability,user,users,3653,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3944,usability,user,users,3944,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:4228,usability,user,users,4228,"precation.py in wrapper(*args, **kwargs). 449 ""parameter will become keyword-only %(removal)s."",. 450 name=name, obj_type=f""parameter of {func.__name__}()""). --> 451 return func(*args, **kwargs). 452 . 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label). 489 else:. 490 self.formatter = format # Assume it is a Formatter or None. --> 491 self.draw_all(). 492 . 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self). 506 # sets self._boundaries and self._values in real data units. 507 # takes into account extend values:. --> 508 self._process_values(). 509 # sets self.vmin and vmax in data units, but just for the part of the. 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b). 961 expander=0.1). 962 . --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)). 964 . 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value). 1218 if not self.scaled():. 1219 raise ValueError(""Not invertible until scaled""). -> 1220 self._check_vmin_vmax(). 1221 vmin, vmax = self.vmin, self.vmax. 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self). 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""). 1180 elif self.vmin <= 0:. -> 1181 raise ValueError(""minvalue must be positive""). 1182 . 1183 def __call__(self, value, clip=None):. ValueError: minvalue must be positive. ```. #### Versions. <details>. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2004:6,deployability,integr,integrates,6,"bbknn integrates multiple variables; Dear author,. Can bbknn integrate multiple variablessuch as Platform and Individual. Looking forward your reply. Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn. return bbknn(. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn. if batch_key not in adata.obs:. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__. return key in self._info_axis. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__. hash(key). TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:61,deployability,integr,integrate,61,"bbknn integrates multiple variables; Dear author,. Can bbknn integrate multiple variablessuch as Platform and Individual. Looking forward your reply. Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn. return bbknn(. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn. if batch_key not in adata.obs:. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__. return key in self._info_axis. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__. hash(key). TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:362,deployability,modul,module,362,"bbknn integrates multiple variables; Dear author,. Can bbknn integrate multiple variablessuch as Platform and Individual. Looking forward your reply. Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn. return bbknn(. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn. if batch_key not in adata.obs:. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__. return key in self._info_axis. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__. hash(key). TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:693,energy efficiency,core,core,693,"bbknn integrates multiple variables; Dear author,. Can bbknn integrate multiple variablessuch as Platform and Individual. Looking forward your reply. Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn. return bbknn(. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn. if batch_key not in adata.obs:. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__. return key in self._info_axis. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__. hash(key). TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:836,energy efficiency,core,core,836,"bbknn integrates multiple variables; Dear author,. Can bbknn integrate multiple variablessuch as Platform and Individual. Looking forward your reply. Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn. return bbknn(. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn. if batch_key not in adata.obs:. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__. return key in self._info_axis. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__. hash(key). TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:6,integrability,integr,integrates,6,"bbknn integrates multiple variables; Dear author,. Can bbknn integrate multiple variablessuch as Platform and Individual. Looking forward your reply. Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn. return bbknn(. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn. if batch_key not in adata.obs:. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__. return key in self._info_axis. File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__. hash(key). TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
