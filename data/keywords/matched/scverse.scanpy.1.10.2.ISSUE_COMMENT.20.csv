id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/1512:1579,interoperability,API,API,1579,"y generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1851,modifiability,scal,scalefactors,1851,"l had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, cr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1916,modifiability,scal,scalefactors,1916,"[image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2489,modifiability,paramet,parameter,2489,"99dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""lowres""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=None). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1851,performance,scale,scalefactors,1851,"l had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, cr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1916,performance,scale,scalefactors,1916,"[image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2362,safety,except,exception,2362,"99dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""lowres""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=None). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2620,security,control,control,2620,"99dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""lowres""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=None). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2620,testability,control,control,2620,"99dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""lowres""). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=None). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:650,usability,user,user-images,650,"Are the squidpy notebooks ready? It would be good to make sure any changes I make don't mess with how you're using this function over there. ------------------------------. A few changes I would like to get your opinion on:. ## Similar cropping regardless of img (even with img=None). This code:. ```python. with plt.rc_context({""figure.dpi"": 120}):. sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""hires""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""lowres""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=None). ```. <details>. <summary> Currently generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:796,usability,consist,consistently,796,"Are the squidpy notebooks ready? It would be good to make sure any changes I make don't mess with how you're using this function over there. ------------------------------. A few changes I would like to get your opinion on:. ## Similar cropping regardless of img (even with img=None). This code:. ```python. with plt.rc_context({""figure.dpi"": 120}):. sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""hires""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""lowres""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=None). ```. <details>. <summary> Currently generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:938,usability,user,user-images,938,"Are the squidpy notebooks ready? It would be good to make sure any changes I make don't mess with how you're using this function over there. ------------------------------. A few changes I would like to get your opinion on:. ## Similar cropping regardless of img (even with img=None). This code:. ```python. with plt.rc_context({""figure.dpi"": 120}):. sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""hires""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""lowres""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=None). ```. <details>. <summary> Currently generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1060,integrability,coupl,couple,1060,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:668,interoperability,heterogen,heterogeneity,668,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:933,interoperability,coordinat,coordinates,933,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1060,modifiability,coupl,couple,1060,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:515,testability,understand,understand,515,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:649,testability,context,context,649,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:777,testability,simpl,simply,777,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1060,testability,coupl,couple,1060,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:777,usability,simpl,simply,777,"looks really great, I'd say Yes! to pretty much everything, thanks for looking into this. > Getting the spot size even if the image isn't used. so this is something we are going back and forth a lot, I still think it has pros and cons, and also agree with the point below re having a separate argument `spot_size`. . If `sc.pl.spatial` *always* plot `circles` and not `scatter`, then the size of the radius needs to be inferred from the data: this makes me a bit worried for the different cases that could arise. I understand that is much nicer that the function returns always the same type of plot (circles), but it might be a bit forcing in this context (given the heterogeneity of the data). What I would agree instead is to pass the `size_spot` and use circles, otherwise simply use scatter (and then set size). What do you think? . > Using ax.set_aspect(""equal"") when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). this is really nice, I'd say yes in principle, would like to try it out though for couple of plots. > If crop_coords is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. this is also fine and probably cleaner than having an heuristic for the offset. > I feel like it would make sense for these to crop to the same part of the image or embedding:. missed this, ok yes it makes sense, then metric of `crop_coord` is the same as `adata.obsm[""spatial""]`. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:80,availability,down,down,80,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:23,deployability,fail,failing,23,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:34,deployability,build,build,34,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:23,reliability,fail,failing,23,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:165,reliability,doe,does,165,"Merging this, docs are failing to build from intersphinx since numpy's docs are down. This commit has built on read the docs before, so I'm happy to assume it still does. Thanks @giovp!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/issues/1513:1710,availability,mainten,maintenance,1710,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:572,deployability,continu,continue,572,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1693,deployability,depend,dependency,1693,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1816,deployability,depend,dependency,1816,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1693,integrability,depend,dependency,1693,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1816,integrability,depend,dependency,1816,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1693,modifiability,depend,dependency,1693,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1816,modifiability,depend,dependency,1816,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1639,performance,time,time,1639,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1710,reliability,mainten,maintenance,1710,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1723,reliability,doe,doesn,1723,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1693,safety,depend,dependency,1693,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1816,safety,depend,dependency,1816,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1693,testability,depend,dependency,1693,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1816,testability,depend,dependency,1816,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1164,usability,behavi,behaviour,1164,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1376,usability,user,user-images,1376,"I've used it a bit, and have gotten nice results. I think I've mentioned it before (#938), but that was on an unrelated issue so it's good to have. The results are nice:. <details>. <summary> Example usage </summary>. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). if ax is None:. texts = [. plt.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 300, ""figure.frameon"": False}):. ax = sc.pl.umap(pbmc, color=""Low-level celltypes"", show=False, legend_loc=None, frameon=False). gen_mpl_labels(. pbmc,. ""Low-level celltypes"",. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=14),. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```. </details>. ![image](https://user-images.githubusercontent.com/8238804/100496350-81af9780-31a7-11eb-8b38-2eb7f914c1a1.png). I believe you're also supposed to be able to make the text repel from points, so they don't sit on top of your data, but I had some trouble getting that working at the time. I'm a bit antsy about having this as a required dependency since maintenance [doesn't seem too active](https://pypi.org/project/adjustText/#history). Could be an optional dependency, used with `legend_loc=""adjust_text""`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:384,availability,down,down,384,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:350,energy efficiency,Current,Current,350,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:111,modifiability,paramet,parameters,111,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:478,modifiability,paramet,parameterization,478,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:160,usability,user,user,160,"I have been unable to get this to look good by default. It can be made to look good by playing around with the parameters, but then we're not really saving the user much effort. A strategy that seemed to work okay was to repel the labels from the points, followed by a second repulsion from other labels. But then I had to redraw the lines manually. Current thoughts are to punt this down the road. Maybe there will be a better solution in the future, or maybe there's a clever parameterization fix I hadn't thought of.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:68,energy efficiency,optim,optimization,68,"I never get adjustText to work without numerous rounds of parameter optimization, so yeah, I agree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:58,modifiability,paramet,parameter,58,"I never get adjustText to work without numerous rounds of parameter optimization, so yeah, I agree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:68,performance,optimiz,optimization,68,"I never get adjustText to work without numerous rounds of parameter optimization, so yeah, I agree.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:83,availability,cluster,cluster,83,Would love to see this works in scanpy. Some thoughts on auto. Can we pretend each cluster is a huge size dot (get the center by averaging it and get the size by get the volume of the cluster)? then we can use put text aiming to not overlap with that huge size dot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:184,availability,cluster,cluster,184,Would love to see this works in scanpy. Some thoughts on auto. Can we pretend each cluster is a huge size dot (get the center by averaging it and get the size by get the volume of the cluster)? then we can use put text aiming to not overlap with that huge size dot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:83,deployability,cluster,cluster,83,Would love to see this works in scanpy. Some thoughts on auto. Can we pretend each cluster is a huge size dot (get the center by averaging it and get the size by get the volume of the cluster)? then we can use put text aiming to not overlap with that huge size dot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:184,deployability,cluster,cluster,184,Would love to see this works in scanpy. Some thoughts on auto. Can we pretend each cluster is a huge size dot (get the center by averaging it and get the size by get the volume of the cluster)? then we can use put text aiming to not overlap with that huge size dot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:123,modifiability,maintain,maintained,123,"Maybe this library would help? https://github.com/TutteInstitute/datamapplot. It is pretty new, but looks promising and is maintained by @lmcinnes, the author of UMAP",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:123,safety,maintain,maintained,123,"Maybe this library would help? https://github.com/TutteInstitute/datamapplot. It is pretty new, but looks promising and is maintained by @lmcinnes, the author of UMAP",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:152,security,auth,author,152,"Maybe this library would help? https://github.com/TutteInstitute/datamapplot. It is pretty new, but looks promising and is maintained by @lmcinnes, the author of UMAP",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:25,usability,help,help,25,"Maybe this library would help? https://github.com/TutteInstitute/datamapplot. It is pretty new, but looks promising and is maintained by @lmcinnes, the author of UMAP",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:476,deployability,continu,continue,476,"I also modified the code of @ivirshup a bit to colorize labels by their color on the scanpy plots:. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None, color_by_group=False. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). # Fill the text colors dictionary. text_colors = {group: None for group in adata.obs[groupby].cat.categories}. if color_by_group and groupby + ""_colors"" in adata.uns:. for i, group in enumerate(adata.obs[groupby].cat.categories):. if group in exclude:. continue. text_colors[group] = adata.uns[groupby + ""_colors""][i]. if ax is None:. texts = [. plt.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). ```. Looks a bit more readable when several labels are close to each other . ![aefd35ba-4f00-4ed8-93a4-dc2b312f800a](https://github.com/scverse/scanpy/assets/35199218/87cda709-44fb-482a-bc67-799be2c57f52)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:800,deployability,continu,continue,800,"I also modified the code of @ivirshup a bit to colorize labels by their color on the scanpy plots:. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None, color_by_group=False. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). # Fill the text colors dictionary. text_colors = {group: None for group in adata.obs[groupby].cat.categories}. if color_by_group and groupby + ""_colors"" in adata.uns:. for i, group in enumerate(adata.obs[groupby].cat.categories):. if group in exclude:. continue. text_colors[group] = adata.uns[groupby + ""_colors""][i]. if ax is None:. texts = [. plt.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). ```. Looks a bit more readable when several labels are close to each other . ![aefd35ba-4f00-4ed8-93a4-dc2b312f800a](https://github.com/scverse/scanpy/assets/35199218/87cda709-44fb-482a-bc67-799be2c57f52)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:7,security,modif,modified,7,"I also modified the code of @ivirshup a bit to colorize labels by their color on the scanpy plots:. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None, color_by_group=False. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). # Fill the text colors dictionary. text_colors = {group: None for group in adata.obs[groupby].cat.categories}. if color_by_group and groupby + ""_colors"" in adata.uns:. for i, group in enumerate(adata.obs[groupby].cat.categories):. if group in exclude:. continue. text_colors[group] = adata.uns[groupby + ""_colors""][i]. if ax is None:. texts = [. plt.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). ```. Looks a bit more readable when several labels are close to each other . ![aefd35ba-4f00-4ed8-93a4-dc2b312f800a](https://github.com/scverse/scanpy/assets/35199218/87cda709-44fb-482a-bc67-799be2c57f52)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:1194,usability,close,close,1194,"I also modified the code of @ivirshup a bit to colorize labels by their color on the scanpy plots:. ```python. from adjustText import adjust_text. def gen_mpl_labels(. adata, groupby, exclude=(), ax=None, adjust_kwargs=None, text_kwargs=None, color_by_group=False. ):. if adjust_kwargs is None:. adjust_kwargs = {""text_from_points"": False}. if text_kwargs is None:. text_kwargs = {}. medians = {}. for g, g_idx in adata.obs.groupby(groupby).groups.items():. if g in exclude:. continue. medians[g] = np.median(adata[g_idx].obsm[""X_umap""], axis=0). # Fill the text colors dictionary. text_colors = {group: None for group in adata.obs[groupby].cat.categories}. if color_by_group and groupby + ""_colors"" in adata.uns:. for i, group in enumerate(adata.obs[groupby].cat.categories):. if group in exclude:. continue. text_colors[group] = adata.uns[groupby + ""_colors""][i]. if ax is None:. texts = [. plt.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items(). ]. else:. texts = [ax.text(x=x, y=y, s=k, color=text_colors[k], **text_kwargs) for k, (x, y) in medians.items()]. adjust_text(texts, **adjust_kwargs). ```. Looks a bit more readable when several labels are close to each other . ![aefd35ba-4f00-4ed8-93a4-dc2b312f800a](https://github.com/scverse/scanpy/assets/35199218/87cda709-44fb-482a-bc67-799be2c57f52)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:179,availability,cluster,cluster,179,@VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:179,deployability,cluster,cluster,179,@VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:335,usability,behavi,behaviour,335,"@GirayEryilmaz , sure! Here's how I used it:. ```python. with plt.rc_context({""figure.figsize"": (8, 8), ""figure.dpi"": 150, ""figure.frameon"": False}):. ax = sc.pl.umap(adata, color=cell_type_key, show=False, legend_loc=None, frameon=False). gen_mpl_labels(. adata,. cell_type_key,. exclude=(""None"",), # This was before we had the `nan` behaviour. ax=ax,. adjust_kwargs=dict(arrowprops=dict(arrowstyle='-', color='black')),. text_kwargs=dict(fontsize=12, path_effects=[pe.withStroke(linewidth=1, foreground=""darkgray"")]),. color_by_group=True. ). fig = ax.get_figure(). fig.tight_layout(). plt.show(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:181,availability,cluster,cluster,181,> @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! Have you solved this problem? I still can't show the lines pointing to the cluster centers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:281,availability,cluster,cluster,281,> @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! Have you solved this problem? I still can't show the lines pointing to the cluster centers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:181,deployability,cluster,cluster,181,> @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! Have you solved this problem? I still can't show the lines pointing to the cluster centers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:281,deployability,cluster,cluster,281,> @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! Have you solved this problem? I still can't show the lines pointing to the cluster centers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:183,availability,cluster,cluster,183,"> > @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! > . > Have you solved this problem? I still can't show the lines pointing to the cluster centers. Hi @nnnanchen. I apologize, I forgot to add the `adjust_text` call in the very last line of the `gen_mpl_labels` above. I edited the previous message. Can you try again?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:289,availability,cluster,cluster,289,"> > @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! > . > Have you solved this problem? I still can't show the lines pointing to the cluster centers. Hi @nnnanchen. I apologize, I forgot to add the `adjust_text` call in the very last line of the `gen_mpl_labels` above. I edited the previous message. Can you try again?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:183,deployability,cluster,cluster,183,"> > @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! > . > Have you solved this problem? I still can't show the lines pointing to the cluster centers. Hi @nnnanchen. I apologize, I forgot to add the `adjust_text` call in the very last line of the `gen_mpl_labels` above. I edited the previous message. Can you try again?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:289,deployability,cluster,cluster,289,"> > @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! > . > Have you solved this problem? I still can't show the lines pointing to the cluster centers. Hi @nnnanchen. I apologize, I forgot to add the `adjust_text` call in the very last line of the `gen_mpl_labels` above. I edited the previous message. Can you try again?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:448,integrability,messag,message,448,"> > @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! > . > Have you solved this problem? I still can't show the lines pointing to the cluster centers. Hi @nnnanchen. I apologize, I forgot to add the `adjust_text` call in the very last line of the `gen_mpl_labels` above. I edited the previous message. Can you try again?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:448,interoperability,messag,message,448,"> > @VladimirShitov can you give an example of how you use the gen_mpl_labels function? I tried it and got somewhat different results. For example it lacked the lines pointing to the cluster centers. Thanks! > . > Have you solved this problem? I still can't show the lines pointing to the cluster centers. Hi @nnnanchen. I apologize, I forgot to add the `adjust_text` call in the very last line of the `gen_mpl_labels` above. I edited the previous message. Can you try again?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1514:19,deployability,Updat,Updating,19,"Hi, @brianpenghe . Updating scanpy should solve the problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:19,safety,Updat,Updating,19,"Hi, @brianpenghe . Updating scanpy should solve the problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:19,security,Updat,Updating,19,"Hi, @brianpenghe . Updating scanpy should solve the problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/pull/1516:87,deployability,build,build,87,"This is fantastic, thank you! A few things I'm unclear on:. * Why is this PR getting a build if there is no [`pr` trigger entry](https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/github?view=azure-devops&tabs=yaml#pr-triggers) in the `yaml`? * Why isn't travis running on this PR? It might be that we've turned off branch CI since it was causing double runs with branches on this repo which were being used in PRs, but I thought it would still trigger once a pr was made. I think I'm just going to try and merge this, since it seems to be working. We can fine tune it via PRs as we go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:175,deployability,pipelin,pipelines,175,"This is fantastic, thank you! A few things I'm unclear on:. * Why is this PR getting a build if there is no [`pr` trigger entry](https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/github?view=azure-devops&tabs=yaml#pr-triggers) in the `yaml`? * Why isn't travis running on this PR? It might be that we've turned off branch CI since it was causing double runs with branches on this repo which were being used in PRs, but I thought it would still trigger once a pr was made. I think I'm just going to try and merge this, since it seems to be working. We can fine tune it via PRs as we go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:175,integrability,pipelin,pipelines,175,"This is fantastic, thank you! A few things I'm unclear on:. * Why is this PR getting a build if there is no [`pr` trigger entry](https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/github?view=azure-devops&tabs=yaml#pr-triggers) in the `yaml`? * Why isn't travis running on this PR? It might be that we've turned off branch CI since it was causing double runs with branches on this repo which were being used in PRs, but I thought it would still trigger once a pr was made. I think I'm just going to try and merge this, since it seems to be working. We can fine tune it via PRs as we go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:572,performance,tune,tune,572,"This is fantastic, thank you! A few things I'm unclear on:. * Why is this PR getting a build if there is no [`pr` trigger entry](https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/github?view=azure-devops&tabs=yaml#pr-triggers) in the `yaml`? * Why isn't travis running on this PR? It might be that we've turned off branch CI since it was causing double runs with branches on this repo which were being used in PRs, but I thought it would still trigger once a pr was made. I think I'm just going to try and merge this, since it seems to be working. We can fine tune it via PRs as we go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:97,availability,down,down,97,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:27,deployability,build,build,27,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:179,deployability,automat,automatically,179,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:266,deployability,configurat,configuration,266,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:291,deployability,build,build,291,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:266,integrability,configur,configuration,266,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:266,modifiability,configur,configuration,266,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:163,safety,valid,validations,163,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:163,security,validat,validations,163,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:266,security,configur,configuration,266,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:179,testability,automat,automatically,179,"> Why is this PR getting a build if there is no `pr` trigger entry in the yaml? See 3 paragraphs down:. > If no pr triggers appear in your YAML file, pull request validations are automatically enabled for all branches, as if you wrote the following pr trigger. This configuration triggers a build when any pull request is created, and when commits come into the source branch of any active pull request. > . > ```. > pr:. > branches:. > include:. > - '*' # must quote since ""*"" is a YAML reserved character; we want a string. > ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/issues/1519:14,energy efficiency,current,current,14,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:65,safety,test,tested,65,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:151,safety,test,tested,151,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:175,security,control,controlled,175,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:65,testability,test,tested,65,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:151,testability,test,tested,151,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:175,testability,control,controlled,175,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:22,usability,behavi,behavior,22,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:242,usability,clear,clear,242,"@LisaSikkema, current behavior just changes the groups which are tested (I'd call this the ""left hand side"" in `group vs reference`) not what they are tested against. That is controlled by the `reference` argument. I agree this could be more clear. It would also be nice if `reference` was more flexible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:111,integrability,Sub,Subset,111,"I see. Yes then maybe we should change this annotation:. `groups : {‘all’}, Iterable[str] (default: 'all').`. `Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups.`. to something like:. `Subset of groups, e.g. ['g1', 'g2', 'g3'], for which differentially expressed genes should be calculated, or 'all' (default) for all groups.`. ? I could also take a look to see how we can make the reference argument more flexible, if you agree that would be a good feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:254,integrability,Sub,Subset,254,"I see. Yes then maybe we should change this annotation:. `groups : {‘all’}, Iterable[str] (default: 'all').`. `Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups.`. to something like:. `Subset of groups, e.g. ['g1', 'g2', 'g3'], for which differentially expressed genes should be calculated, or 'all' (default) for all groups.`. ? I could also take a look to see how we can make the reference argument more flexible, if you agree that would be a good feature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:92,testability,simpl,simple,92,That doc change looks good to me! For any change to `reference` it would be good to keep it simple. Maybe it could accept a list of groups?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:92,usability,simpl,simple,92,That doc change looks good to me! For any change to `reference` it would be good to keep it simple. Maybe it could accept a list of groups?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/pull/1520:116,availability,cluster,clusters,116,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:116,deployability,cluster,clusters,116,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:142,deployability,version,versions,142,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:366,deployability,pipelin,pipelines,366,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:142,integrability,version,versions,142,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:366,integrability,pipelin,pipelines,366,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:142,modifiability,version,versions,142,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:178,safety,test,test,178,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:178,testability,test,test,178,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:90,usability,user,users,90,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:288,usability,support,support,288,"AFAICT `ubuntu 16.04` is what they use in most of their examples. Considering many of our users will be on academic clusters, I think old-ish versions of linux are reasonable to test against. The alternative would probably be `ubuntu-18.04`, which we should switch to when `16` is out of support. [Here are the options](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1520:66,usability,support,support,66,"We should have used the newer LTS from the start, 16.04 is out of support in 5 months.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1520
https://github.com/scverse/scanpy/pull/1527:31,deployability,instal,install,31,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:330,deployability,instal,install,330,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:368,deployability,instal,install,368,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:500,deployability,instal,installed,500,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:561,deployability,instal,installs,561,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:845,deployability,instal,installs-runtime-layout-not-hooks,845,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:0,energy efficiency,Current,Current,0,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:510,interoperability,distribut,distributions,510,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:817,interoperability,standard,standardising-editable-mode-installs-runtime-layout-not-hooks,817,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:705,modifiability,pac,packages,705,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:69,reliability,doe,doesn,69,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:258,reliability,doe,doesn,258,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:360,reliability,doe,doesn,360,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:478,reliability,doe,doesn,478,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:486,security,ident,identify,486,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:873,testability,hook,hooks,873,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:193,usability,document,document,193,"Current problems:. - [x] `flit install --pth-file --deps=production` doesn’t work with setuptools-scm (just in conda?). - [x] it needs `setuptools_scm`, which is in the `dev` extra. We need to document this. - [x] circumvent pypa/setuptools#2531. - [x] flit doesn’t work if setup.py exists (still? where’s the issue?). - [x] `pip install -e` with the setup.py doesn’t install deps if the metadata is broken. Not a problem (to my knowledge), but because you mentioned it:. conda doesn’t identify flit installed distributions as `<develop>`. This is because flit installs a regular `.dist-info` directory instead of dumping an `.egg-info` into your dev directory and adding an `.egg-link` file to the `site-packages`. That needs to be fixed by conda, [I suggest they should parse symlinks](https://discuss.python.org/t/standardising-editable-mode-installs-runtime-layout-not-hooks/4098).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,deployability,instal,install,7,"> flit install --pth-file --deps=production doesn’t work with setuptools-scm (just in conda?). >. > Fix: it needs setuptools_scm, which is in the dev extra. We need to document this. I had run into a problem with. ```. flit install --pth-file --deps=develop. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:224,deployability,instal,install,224,"> flit install --pth-file --deps=production doesn’t work with setuptools-scm (just in conda?). >. > Fix: it needs setuptools_scm, which is in the dev extra. We need to document this. I had run into a problem with. ```. flit install --pth-file --deps=develop. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:44,reliability,doe,doesn,44,"> flit install --pth-file --deps=production doesn’t work with setuptools-scm (just in conda?). >. > Fix: it needs setuptools_scm, which is in the dev extra. We need to document this. I had run into a problem with. ```. flit install --pth-file --deps=develop. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:168,usability,document,document,168,"> flit install --pth-file --deps=production doesn’t work with setuptools-scm (just in conda?). >. > Fix: it needs setuptools_scm, which is in the dev extra. We need to document this. I had run into a problem with. ```. flit install --pth-file --deps=develop. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:256,integrability,standardiz,standardized,256,"Due to the first problem (that blocked using flit in all circumstances) being fixed and the last two standing in the way of the `setup.py` working, I think flit-only seems more likely at the moment. @ivirshup what do you think? PS: here’s some progress on standardized --editable mode https://github.com/pypa/pip/pull/8212",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:256,interoperability,standard,standardized,256,"Due to the first problem (that blocked using flit in all circumstances) being fixed and the last two standing in the way of the `setup.py` working, I think flit-only seems more likely at the moment. @ivirshup what do you think? PS: here’s some progress on standardized --editable mode https://github.com/pypa/pip/pull/8212",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:244,usability,progress,progress,244,"Due to the first problem (that blocked using flit in all circumstances) being fixed and the last two standing in the way of the `setup.py` working, I think flit-only seems more likely at the moment. @ivirshup what do you think? PS: here’s some progress on standardized --editable mode https://github.com/pypa/pip/pull/8212",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:285,interoperability,distribut,distribute,285,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:237,modifiability,concern,concerns,237,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:70,safety,test,testing,70,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:58,security,sign,significant,58,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:70,testability,test,testing,70,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:237,testability,concern,concerns,237,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:370,usability,workflow,workflow,370,"I'm not comfortable with doing an absolute switch without significant testing. I would want a few frequent contributors (Fidel, Sergei, Goecken?) to try it out, try and break it, and make sure we could get things done. I also still have concerns about the limitations of what flit can distribute, and would like to hear other's thoughts on this. If a `setuptools` based workflow can happen, then I don't think these steps are necessarily blocking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:231,deployability,build,build,231,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested! Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:134,safety,test,test,134,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested! Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:198,safety,test,tested,198,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested! Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:134,testability,test,test,134,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested! Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:198,testability,test,tested,198,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested! Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:27,usability,tool,tools,27,"Ha, got it! Seems like all tools break differently on multiline strings in the metadata. I changed the string back to single ticks to test that metadata problem and then forgot. Now it works and is tested! Also I checked and `flit build` seems to be working with `setup.py` existing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:131,security,cookie,cookiejar,131,"Huh, very interesting. Why did you choose flit over https://python-poetry.org/ ? The Theislab may soon be using https://github.com/cookiejar/cookietemple/tree/development whose cli-python template is using Poetry. Also, Poetry is much more popular (>10x more popular). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:141,security,cookie,cookietemple,141,"Huh, very interesting. Why did you choose flit over https://python-poetry.org/ ? The Theislab may soon be using https://github.com/cookiejar/cookietemple/tree/development whose cli-python template is using Poetry. Also, Poetry is much more popular (>10x more popular). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:74,deployability,instal,install,74,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:171,deployability,version,versions,171,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:340,deployability,version,version,340,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:419,deployability,instal,install,419,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:357,energy efficiency,current,currently,357,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:171,integrability,version,versions,171,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:340,integrability,version,version,340,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:141,interoperability,plug,plugins,141,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:171,modifiability,version,versions,171,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:340,modifiability,version,version,340,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:125,reliability,doe,doesn,125,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:23,safety,reme,remember,23,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:161,security,hardcod,hardcoded,161,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:373,security,hack,hacky,373,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:133,usability,support,support,133,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:348,usability,support,support,348,"Poetry is great! But i remember two problems:. 1. no good way to editably install into some env: python-poetry/poetry#34. 2. doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. Maybe @ivirshup knows more. We talked about it way back when. The things I’m missing from flit are better dynamic version support (currently a bit hacky, but a PR exists) and sth. like `poetry install --no-root`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:45,performance,time,times,45,"I've found poetry mostly a pain the last few times I've tried it. Maybe it's gotten better, but the `poetry.lock` file and use of virutalenvs seemed more restrictive than useful. My impression was that it was designed to solve problems for a very different use case than scientific computing. I like that flit is much more limited in scope, and does not try to do everything. I'd also be worried using `poetry` would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:108,performance,lock,lock,108,"I've found poetry mostly a pain the last few times I've tried it. Maybe it's gotten better, but the `poetry.lock` file and use of virutalenvs seemed more restrictive than useful. My impression was that it was designed to solve problems for a very different use case than scientific computing. I like that flit is much more limited in scope, and does not try to do everything. I'd also be worried using `poetry` would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:345,reliability,doe,does,345,"I've found poetry mostly a pain the last few times I've tried it. Maybe it's gotten better, but the `poetry.lock` file and use of virutalenvs seemed more restrictive than useful. My impression was that it was designed to solve problems for a very different use case than scientific computing. I like that flit is much more limited in scope, and does not try to do everything. I'd also be worried using `poetry` would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:108,security,lock,lock,108,"I've found poetry mostly a pain the last few times I've tried it. Maybe it's gotten better, but the `poetry.lock` file and use of virutalenvs seemed more restrictive than useful. My impression was that it was designed to solve problems for a very different use case than scientific computing. I like that flit is much more limited in scope, and does not try to do everything. I'd also be worried using `poetry` would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1106,availability,sli,slightly,1106,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:103,deployability,instal,install,103,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:199,deployability,version,versions,199,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:292,deployability,instal,install,292,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:481,deployability,depend,dependency,481,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:691,deployability,instal,install,691,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1410,deployability,instal,install,1410,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:798,energy efficiency,current,currently,798,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:199,integrability,version,versions,199,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:481,integrability,depend,dependency,481,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:169,interoperability,plug,plugins,169,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:508,interoperability,plug,plugins,508,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1375,interoperability,plug,plugin,1375,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:199,modifiability,version,versions,199,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:481,modifiability,depend,dependency,481,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:153,reliability,doe,doesn,153,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1106,reliability,sli,slightly,1106,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1134,reliability,doe,does,1134,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1191,reliability,doe,does,1191,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1230,reliability,doe,does,1230,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:49,safety,reme,remember,49,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:481,safety,depend,dependency,481,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:189,security,hardcod,hardcoded,189,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:709,security,hack,hack,709,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1120,security,intrus,intrusive,1120,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:405,testability,understand,understand,405,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:481,testability,depend,dependency,481,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:161,usability,support,support,161,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1330,usability,person,personally,1330,"All right, fair points. > Poetry is great! But i remember two problems:. > . > no good way to editably install into some env: python-poetry/poetry#34. > doesn’t support plugins yet so only hardcoded versions in static metadata: python-poetry/poetry#140. > . I also stumbled upon the editably install issue. This is not an issue that Poetry can solve at the moment as explained in the thread. I do however understand that this is an issue for scanpy (considering the strong anndata dependency etc). Regarding plugins - they are on the roadmap and should appear at some point. Considering that the community is very active whereas the main developer is not anymore this may solve the editable install with some hack as well. I agree with your points and Poetry is not yet the solution that we should currently use, but I think it is the proper solution that we should aim for. > I'd also be worried using poetry would hamper contributions from people unfamiliar with it, and I don't think bioinformaticians are going to be familiar with it. I don't think that anybody is familiar with flit either, but it is slightly less intrusive and does not fundamentally change so many things like Poetry does. However, many things that Poetry does change make a lot of sense and solve other issues that we did not discuss here yet. So yeah, I personally would wait for Poetry to get it's plugin system and for the editable install issue to get a proper PEP. But if you don't feel like waiting Flit might be fun :). Cheers",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:152,deployability,manag,management,152,"Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:152,energy efficiency,manag,management,152,"Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:92,reliability,doe,doesn,92,"Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:152,safety,manag,management,152,"Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:43,usability,learn,learn,43,"Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:269,deployability,manag,management,269,". Yeah, I agree. Go for it ;) Saturday, 23 January 2021, 11:48AM +01:00 from Philipp A. notifications@github.com :. >Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management). >—. >You are receiving this because you commented. >Reply to this email directly, view it on GitHub , or unsubscribe .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:269,energy efficiency,manag,management,269,". Yeah, I agree. Go for it ;) Saturday, 23 January 2021, 11:48AM +01:00 from Philipp A. notifications@github.com :. >Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management). >—. >You are receiving this because you commented. >Reply to this email directly, view it on GitHub , or unsubscribe .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:209,reliability,doe,doesn,209,". Yeah, I agree. Go for it ;) Saturday, 23 January 2021, 11:48AM +01:00 from Philipp A. notifications@github.com :. >Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management). >—. >You are receiving this because you commented. >Reply to this email directly, view it on GitHub , or unsubscribe .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:269,safety,manag,management,269,". Yeah, I agree. Go for it ;) Saturday, 23 January 2021, 11:48AM +01:00 from Philipp A. notifications@github.com :. >Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management). >—. >You are receiving this because you commented. >Reply to this email directly, view it on GitHub , or unsubscribe .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:160,usability,learn,learn,160,". Yeah, I agree. Go for it ;) Saturday, 23 January 2021, 11:48AM +01:00 from Philipp A. notifications@github.com :. >Flit has a very tiny surface area. You can learn its full CLI in literally 2 minutes, as it doesn’t include any kind of new concept (like Poetry’s venv management). >—. >You are receiving this because you commented. >Reply to this email directly, view it on GitHub , or unsubscribe .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:69,interoperability,conflict,conflict,69,"@Zethson as asked in your PR, can you please add a commit to fix the conflict here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:10,deployability,version,version,10,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:184,deployability,fail,fails,184,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:309,deployability,modul,module,309,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:342,deployability,instal,installation,342,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:677,deployability,instal,installs,677,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:10,integrability,version,version,10,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:114,integrability,compon,component,114,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:136,integrability,repositor,repository,136,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:114,interoperability,compon,component,114,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:136,interoperability,repositor,repository,136,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:10,modifiability,version,version,10,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:114,modifiability,compon,component,114,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:309,modifiability,modul,module,309,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:710,modifiability,pac,package,710,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:184,reliability,fail,fails,184,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:309,safety,modul,module,309,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:692,security,hack,hack,692,"About the version: That’s because `__file__` in `get_version(root='..', relative_to=__file__)` is a path where no component is in a git repository. Therefore the `setuptools_scm` code fails, we enter the `else` branch, and the (stale) metadata is used. Something like the following could make the `_metadata` module figure out we’re in a dev installation after all. (Needs some more as `here.readlink()` returns a relative path. I’m against `resolve()` as we really just want that one link to be replaced and `resolve()` is a sledge hammer). ```py. file_resolved = str(here.readlink() / f'{__name__}.py') if here.is_symlink() else __file__. ```. But the real issue is that dev installs are a hack and scanpy’s package metadata is stale.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:5,availability,failur,failures,5,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:5,deployability,fail,failures,5,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:5,performance,failur,failures,5,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:5,reliability,fail,failures,5,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:0,safety,Test,Test,0,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:0,testability,Test,Test,0,"Test failures are not mine, seems like numba breaks on python 3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,availability,failur,failures,7,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:264,availability,failur,failures,264,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,deployability,fail,failures,7,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:257,deployability,build,builds,257,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:264,deployability,fail,failures,264,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:356,interoperability,format,formatted,356,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,performance,failur,failures,7,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:264,performance,failur,failures,264,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,reliability,fail,failures,7,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:264,reliability,fail,failures,264,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2,safety,Test,Test,2,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:178,safety,avoid,avoid,178,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:198,safety,test,test,198,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:223,safety,test,test,223,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:449,safety,review,review,449,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:527,safety,review,review,527,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:574,safety,review,review,574,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2,testability,Test,Test,2,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:198,testability,test,test,198,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:223,testability,test,test,223,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:449,testability,review,review,449,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:527,testability,review,review,527,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:574,testability,review,review,574,"> Test failures are not mine. It's not numba, it's annoy #1638 (hadn't realized scrublet uses it too). Asking for a rebuild will make it go away, but we should see if we can (1) avoid annoy in that test or (2) disable that test on 3.6 in a separate PR. Doc builds failures do seem related to this, however. Something about the way the `pip` requirement is formatted? ------------------------. In future, could you not force push while responding to review? It makes it difficult for me to figure out what changed since my last review. History cleanup can happen pre or post review.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:380,availability,failur,failures,380,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:432,availability,failur,failure,432,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:373,deployability,build,builds,373,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:380,deployability,fail,failures,380,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:432,deployability,fail,failure,432,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:799,deployability,version,version,799,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:826,deployability,pipelin,pipelines,826,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:909,deployability,contain,contains,909,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:987,deployability,version,version,987,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:283,integrability,messag,message,283,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:799,integrability,version,version,799,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:826,integrability,pipelin,pipelines,826,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:987,integrability,version,version,987,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:283,interoperability,messag,message,283,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:973,interoperability,specif,specify,973,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:799,modifiability,version,version,799,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:987,modifiability,version,version,987,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:380,performance,failur,failures,380,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:432,performance,failur,failure,432,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:380,reliability,fail,failures,380,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:432,reliability,fail,failure,432,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:956,reliability,doe,doesn,956,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:119,safety,review,review,119,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:516,safety,valid,validates,516,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:600,safety,valid,valid,600,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:516,security,validat,validates,516,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:119,testability,review,review,119,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:267,usability,indicat,indicate,267,"> it's annoy. Sounds like annoy is being … annoying :smile:. > In future, could you not force push while responding to review? Okay! Hmm, generally IDK what the best approach is since I now know how I want to rebase the commits but I’ll probably forget later … Maybe indicate in the message which commit they “fixup”? Also: can we reenable squash/rebase merges soon? > Doc builds failures do seem related to this, however. The docs failure is ugly to fix, but I did it …. Since very shortly ago, (pypa/pip#9320) pip validates wheels and for some reason decided that pluses in wheel filenames are not valid (I couldn’t find that in any spec). I hope takluyver/flit#388 gets merged soon to circumvent/fix that. If we want to temporarily circumvent that we’d have to tell readthedocs to use pip 20.3.3 version (like I did in the pipelines yaml). And that’s ugly because we’d have to add a requirements file that contains just `pip==20.3.3`, since readthedocs doesn’t allow to specify a pip version or a literal list of requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:139,deployability,instal,install,139,"Came across this, and just want to add we are using poetry on scvi-tools and it's been pretty painless thus far. > no good way to editably install into some env:. If you look at our pyproject file, you can add one line that allows `pip -e .` type installation. I don't actually use poetry to create the development environment. The only issue that I haven't quite figured out is how to get the `scvi.__version__` to work on editable install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:247,deployability,instal,installation,247,"Came across this, and just want to add we are using poetry on scvi-tools and it's been pretty painless thus far. > no good way to editably install into some env:. If you look at our pyproject file, you can add one line that allows `pip -e .` type installation. I don't actually use poetry to create the development environment. The only issue that I haven't quite figured out is how to get the `scvi.__version__` to work on editable install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:433,deployability,instal,install,433,"Came across this, and just want to add we are using poetry on scvi-tools and it's been pretty painless thus far. > no good way to editably install into some env:. If you look at our pyproject file, you can add one line that allows `pip -e .` type installation. I don't actually use poetry to create the development environment. The only issue that I haven't quite figured out is how to get the `scvi.__version__` to work on editable install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:67,usability,tool,tools,67,"Came across this, and just want to add we are using poetry on scvi-tools and it's been pretty painless thus far. > no good way to editably install into some env:. If you look at our pyproject file, you can add one line that allows `pip -e .` type installation. I don't actually use poetry to create the development environment. The only issue that I haven't quite figured out is how to get the `scvi.__version__` to work on editable install.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:21,deployability,instal,install,21,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:63,deployability,depend,dependency,63,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:74,deployability,instal,installs,74,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:150,deployability,instal,install,150,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:63,integrability,depend,dependency,63,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:63,modifiability,depend,dependency,63,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:63,safety,depend,dependency,63,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:63,testability,depend,dependency,63,Okay all done. `flit install -s` was getting too messy as some dependency installs scanpy and then things can’t be symlinked …. better leave the `pip install -r` in temporarily,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:0,performance,Time,Time,0,Time to merge?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:193,modifiability,pac,packaging,193,"> I don't actually use poetry to create the development environment. @adamgayoso, I'd be interested to hear about what you like about `poetry` in this case. My impression, from skimming python packaging flame wars on HN, was handling the development environment was `poetry`'s whole thing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:152,availability,down,downloaded,152,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1788,availability,avail,available,1788,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2163,availability,robust,robust,2163,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:102,deployability,instal,install,102,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:177,deployability,depend,depends,177,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:207,deployability,releas,release,207,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:237,deployability,instal,installed,237,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:326,deployability,version,version,326,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:337,deployability,instal,install,337,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:371,deployability,instal,install,371,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:542,deployability,instal,installs,542,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,deployability,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:658,deployability,instal,install,658,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:696,deployability,instal,installs,696,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:742,deployability,instal,install,742,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:952,deployability,version,version,952,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1067,deployability,build,build,1067,"e definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1073,deployability,version,version,1073,"itely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1221,deployability,version,version,1221,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1378,deployability,version,version,1378,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1588,deployability,instal,installed,1588,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1635,deployability,depend,dependency,1635,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1780,deployability,version,version,1780,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1805,deployability,depend,dependencies,1805,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1826,deployability,instal,installed,1826,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1888,deployability,version,versioneer,1888,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:177,integrability,depend,depends,177,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:326,integrability,version,version,326,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,integrability,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:952,integrability,version,version,952,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1073,integrability,version,version,1073,"itely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1221,integrability,version,version,1221,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1378,integrability,version,version,1378,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1635,integrability,depend,dependency,1635,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1780,integrability,version,version,1780,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1805,integrability,depend,dependencies,1805,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1888,integrability,version,versioneer,1888,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:313,interoperability,incompatib,incompatible,313,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:347,interoperability,compatib,compatible,347,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:424,interoperability,compatib,compatible,424,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,interoperability,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:856,interoperability,standard,standard,856,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1229,interoperability,specif,specifiers,1229,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1358,interoperability,specif,specifiers,1358,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1874,interoperability,standard,standard,1874,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:139,modifiability,pac,package,139,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:177,modifiability,depend,depends,177,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:326,modifiability,version,version,326,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,modifiability,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:610,modifiability,pac,package,610,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:915,modifiability,concern,concerned,915,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:952,modifiability,version,version,952,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1073,modifiability,version,version,1073,"itely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1221,modifiability,version,version,1221,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1338,modifiability,pac,packages,1338,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1378,modifiability,version,version,1378,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1536,modifiability,pac,packages,1536,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1577,modifiability,pac,package,1577,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1622,modifiability,pac,package,1622,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1635,modifiability,depend,dependency,1635,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1772,modifiability,pac,package,1772,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1780,modifiability,version,version,1780,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1805,modifiability,depend,dependencies,1805,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1888,modifiability,version,versioneer,1888,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,reliability,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1788,reliability,availab,available,1788,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2163,reliability,robust,robust,2163,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:177,safety,depend,depends,177,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1635,safety,depend,dependency,1635,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1788,safety,avail,available,1788,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1805,safety,depend,dependencies,1805,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2163,safety,robust,robust,2163,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,security,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1788,security,availab,available,1788,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1919,security,hardcod,hardcode,1919,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2155,security,hack,hack,2155,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:177,testability,depend,depends,177,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:590,testability,integr,integrated,590,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:915,testability,concern,concerned,915,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1635,testability,depend,dependency,1635,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1805,testability,depend,dependencies,1805,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:29,usability,behavi,behavior,29,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:285,usability,behavi,behavior,285,"> This seems like pretty bad behavior for a development environment. We definitely don't want the dev install to be uninstalled when a new package gets downloaded. Well, scvelo depends on 1.7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2179,usability,document,documented,2179,"7 and you have a release candidate of that one installed, so what happened is the only correct behavior: It uninstalled an incompatible version to install a compatible one. If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. That’s annoying but necessary as editable installs are nonstandard and therefore not well integrated into how package metadata works. > Why not just use `pip install -e` here? Because development installs in general are nonstandard, and `pip install -e` in particular uses the deprecated `setup.py`. Tasks. -----. > - Exclude setup.py from sdist using the standard way, not via .gitignore. sounds good! > I'm a bit concerned that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. > ... > - flit mangles the build version part of wheel filenames, in a way that pip just started checking for. . No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. AFAIK nothing says there can’t be pluses in there, only that you can’t upload packages with local specifiers in their version to PyPI. Which we don’t do here, so pip should chill. If flit decides to work around that quirk, or pip relaxes, we can unpin pip. > - flit symlinked packages seem to be overwritten if a new package is installed which has the symlinked package as a dependency. Seee above. Has nothing to do with flit. What made you thing that anyway? > - There is a fairly large workaround to make the package version available if the dependencies are not installed. Is it possible to use something more standard like versioneer here? No. Either we hardcode a string constant in the `__init__.py` or we leave it like it is until flit allows an alternative. That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:15,deployability,depend,depends,15,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:45,deployability,releas,release,45,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:73,deployability,depend,depends,73,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:242,deployability,instal,install,242,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:420,deployability,instal,install,420,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:497,deployability,instal,install,497,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:526,deployability,instal,install,526,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:557,deployability,instal,installs,557,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:602,deployability,instal,install,602,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:689,deployability,version,version,689,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:749,deployability,instal,installation,749,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:840,deployability,version,version,840,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1099,deployability,contain,contain,1099,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1138,deployability,version,version,1138,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1205,deployability,version,version,1205,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:15,integrability,depend,depends,15,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:73,integrability,depend,depends,73,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:689,integrability,version,version,689,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:840,integrability,version,version,840,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:918,integrability,sub,subsequent,918,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1138,integrability,version,version,1138,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1205,integrability,version,version,1205,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:295,interoperability,compatib,compatible,295,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:739,interoperability,standard,standard,739,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:848,interoperability,specif,specifiers,848,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1213,interoperability,specif,specifiers,1213,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:15,modifiability,depend,depends,15,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:73,modifiability,depend,depends,73,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:689,modifiability,version,version,689,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:840,modifiability,version,version,840,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1138,modifiability,version,version,1138,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1205,modifiability,version,version,1205,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1491,performance,time,timeframe,1491,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:216,reliability,doe,doesn,216,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:409,reliability,Doe,Does,409,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:15,safety,depend,depends,15,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:73,safety,depend,depends,73,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1008,safety,valid,validating,1008,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1008,security,validat,validating,1008,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:15,testability,depend,depends,15,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:73,testability,depend,depends,73,"> Well, scvelo depends on 1.7 and you have a release candidate. `scvelo` depends on `scanpy>=1.5`, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? > If your install’s metadata was outdated and it was in fact a compatible one, then you forgot to refresh the metadata by reinstalling it. . I'm not sure what you mean by this. Does `flit install -s --deps=develop` not count as reinstalling? Are you counting `flit install -s` as a development install? > Because development installs in general are nonstandard, and pip install -e in particular uses the deprecated `setup.py`. I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. > No, as far as I can see, pip arbitrarily decided to not allow local version specifiers in wheel filenames. My reading of the PR in `flit` and the subsequent discussion in the `pip` and PEP threads suggests to me that the issue is `pip` validating the metadata name against the wheel, while a spec exists saying the wheel can't contain characters that are allowed by version specs. If anything, `pip` suddenly started expecting exact version specifiers in wheel filenames, while a spec exists that says how the filenames should be mangled. `flit` did the mangling, and `pip` now says that's wrong. It looks like the direction the discussion is headed is PEP 427 is wrong, and `pip` is right. I have no idea what sort of timeframe should be expected here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:9,deployability,depend,depends,9,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:201,deployability,depend,dependencies,201,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:249,deployability,instal,installed,249,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:306,deployability,configurat,configuration,306,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:323,deployability,upgrad,upgrades,323,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:405,deployability,updat,update,405,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:440,deployability,updat,update,440,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:530,deployability,instal,install,530,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:605,deployability,instal,install,605,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:633,deployability,instal,install,633,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:730,deployability,version,version,730,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:749,deployability,instal,installed,749,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:785,deployability,updat,update,785,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:903,deployability,instal,install,903,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:978,deployability,instal,install,978,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1019,deployability,instal,install,1019,"npy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1042,deployability,updat,updating,1042,"ink this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1155,deployability,instal,installing,1155,"ppen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1206,deployability,version,version,1206,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1266,deployability,instal,installation,1266,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1547,deployability,infrastructur,infrastructure,1547,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1967,deployability,version,version,1967,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1566,energy efficiency,adapt,adapted,1566,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1849,energy efficiency,current,currently,1849,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:9,integrability,depend,depends,9,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:201,integrability,depend,dependencies,201,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:306,integrability,configur,configuration,306,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:730,integrability,version,version,730,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1206,integrability,version,version,1206,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1566,integrability,adapt,adapted,1566,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1864,integrability,complian,compliant,1864,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1967,integrability,version,version,1967,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2000,integrability,complian,compliant,2000,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1256,interoperability,standard,standard,1256,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1305,interoperability,compatib,compatibility,1305,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1566,interoperability,adapt,adapted,1566,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:9,modifiability,depend,depends,9,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:201,modifiability,depend,dependencies,201,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:259,modifiability,pac,packages,259,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:306,modifiability,configur,configuration,306,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:323,modifiability,upgrad,upgrades,323,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:730,modifiability,version,version,730,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1206,modifiability,version,version,1206,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1566,modifiability,adapt,adapted,1566,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1967,modifiability,version,version,1967,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:150,reliability,doe,doesn,150,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:520,reliability,Doe,Does,520,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1432,reliability,doe,does,1432,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1812,reliability,doe,does,1812,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:9,safety,depend,depends,9,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:201,safety,depend,dependencies,201,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:405,safety,updat,update,405,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:440,safety,updat,update,440,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:785,safety,updat,update,785,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1042,safety,updat,updating,1042,"ink this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1864,safety,compl,compliant,1864,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2000,safety,compl,compliant,2000,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:306,security,configur,configuration,306,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:405,security,updat,update,405,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:440,security,updat,update,440,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:785,security,updat,update,785,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1042,security,updat,updating,1042,"ink this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1864,security,compl,compliant,1864,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2000,security,compl,compliant,2000,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:9,testability,depend,depends,9,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:201,testability,depend,dependencies,201,"> scvelo depends on scanpy>=1.5, so I don't think this is the cause. Do you know why this is happening, and can you provide counter examples where it doesn't happen? Ah weird. Pip tries to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1874,usability,behavi,behavior,1874,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2010,usability,behavi,behavior,2010,"to resolve the dependencies, and for that purpose gets all the installed packages’ metadata, then tries to figure out a configuration of upgrades that makes things work. No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? > I'm not sure what you mean by this. Does flit install -s --deps=develop not count as reinstalling? Are you counting flit install -s as a development install? Yes, that’s a reinstall in some development mode. My point was that if a scanpy pre-1.7 version really was installed, maybe pip was correct to update to 1.7 for some reason. However since we’re past 1.7 now, unless you haven’t git-pulled yet, I assume your dev install’s metadata has gone stale. I guess pip wouldn’t uninstall your dev install if you had run `git pull && flit install -s`, therefore updating the metadata. But I could be wrong, as I have no idea why pip thought it necessary to touch scanpy when installing scvelo. > I think pinning pip to an old version is worse than using a common, even if non-standard, installation method. Our setup.py is a compatibility shim solely for fallback use, not something to be relied upon in any part of our process. Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? > It looks like the direction the discussion is headed is PEP 427 is wrong, and pip is right. Accepted PEPs are specs, so only pip and flit can be right or wrong (as they implement it). If people decide that what pip does happens to be *better* than the currently spec-compliant behavior, the spec can be changed accordingly. Until then pip is wrong, so we should pin its version to one that accepts spec-compliant behavior. (we can change our approach if that happens to drag on too long). I see you already commented in pypa/pip#9628, so I guess that’s the better place for following that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1554,availability,error,error,1554,"y to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2285,availability,robust,robust,2285,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:12,deployability,instal,installs,12,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:112,deployability,updat,update,112,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:147,deployability,updat,update,147,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:285,deployability,instal,install,285,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:538,deployability,instal,install,538,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:626,deployability,instal,installation,626,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:917,deployability,infrastructur,infrastructure,917,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1017,deployability,version,version,1017,"being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1197,deployability,version,versions,1197,"s super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1389,deployability,Instal,Installing,1389,"reed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1534,deployability,instal,install,1534,"install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1628,deployability,releas,release,1628,"lation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1636,deployability,version,version,1636,"nstructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1720,deployability,instal,install,1720," you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1867,deployability,instal,install,1867,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1888,deployability,instal,install,1888,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2002,deployability,Version,Version,2002,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2320,deployability,version,version,2320,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:936,energy efficiency,adapt,adapted,936,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:936,integrability,adapt,adapted,936,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1017,integrability,version,version,1017,"being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1197,integrability,version,versions,1197,"s super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1636,integrability,version,version,1636,"nstructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2002,integrability,Version,Version,2002,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2320,integrability,version,version,2320,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:936,interoperability,adapt,adapted,936,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1312,interoperability,convers,conversation,1312,"nt. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On ho",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:936,modifiability,adapt,adapted,936,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:982,modifiability,concern,concern,982,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1017,modifiability,version,version,1017,"being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1197,modifiability,version,versions,1197,"s super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1636,modifiability,version,version,1636,"nstructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2002,modifiability,Version,Version,2002,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2320,modifiability,version,version,2320,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2417,modifiability,pac,packages,2417,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1554,performance,error,error,1554,"y to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:802,reliability,doe,does,802,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2285,reliability,robust,robust,2285,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:112,safety,updat,update,112,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:147,safety,updat,update,147,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1554,safety,error,error,1554,"y to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2285,safety,robust,robust,2285,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:112,security,updat,update,112,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:147,security,updat,update,147,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:409,security,assess,assessment,409,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2038,security,hardcod,hardcode,2038,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2277,security,hack,hack,2277,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:982,testability,concern,concern,982,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2507,testability,trace,traceback,2507,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:678,usability,behavi,behaviour,678,"### symlink installs being uninstalled **(most important)**. > No idea why it sees “1.7.0rc2” and decides “I’ll update this even when not asked to update”. Maybe raise this issue with pip? Yeah, this is super weird. I think it's also blocking for adopting `flit` as recommended way to install scanpy to a dev environment. I also raised this on the call yesterday, and I don't think anyone disagreed with this assessment. I see two paths forward here:. * You're able to solve this in this PR. * We merge mostly as is, but we add back `pip install -e` as a way to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ##",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1554,usability,error,error,1554,"y to make a development environment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1586,usability,tip,tip,1586,"ment, and add a `.. note` to the flit installation instructions warning people about this behaviour. I would also want a commitment from you to look into this issue. ### Pinning Pip on CI. > Usually when something does an arbitrary change making our life harder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_impor",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2301,usability,document,documented,2301,"rder, our approach is pinning it temporarily until it fixed that or the infrastructure has adapted to its whims, right? I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. ### PEP stuff. > I see you already commented in `pypa/pip#9628`. I think that conversation is happening in multiple places, so might be hard to track. ### Installing from the repo. As it stands:. ```python. conda create -n scanpyenv python=3.8. https://github.com/theislab/scanpy.git. cd scanpy. pip install . ```. Will error, unless the commit at the tip of master happens to be tagged with a release version. Right now I don't think this is an issue since I wouldn't expect anyone to install from github unless they were setting up a development environment. And if they are setting up a dev environment, they should be using `pip install -e` or `flit install -s`. . I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. ### Version resolution. > No. Either we hardcode a string constant in the __init__.py or we leave it like it is until flit allows an alternative. >. > That’s the only disadvantage flit has IMHO, but we discussed that at length in the past and found it to not be a problem as the hack is robust and well documented. On how version strings are handled/ generated:. I would be more comfortable using a solution that other packages used too. In particular, this looks very brittle to me:. ```python. for frame in traceback.extract_stack():. if frame.name == 'get_docstring_and_version_via_import':. return True. ```. I don't see why `flit` couldn't just change the name of a function that is called internally at any point. I also think that at the moment, you and I are the only contributors who would have any idea what was going on if this acts up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:67,deployability,version,version,67,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:172,deployability,version,version,172,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:260,deployability,version,version,260,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:281,deployability,instal,install,281,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:305,deployability,version,version,305,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:67,integrability,version,version,67,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:172,integrability,version,version,172,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:260,integrability,version,version,260,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:305,integrability,version,version,305,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:67,modifiability,version,version,67,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:172,modifiability,version,version,172,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:260,modifiability,version,version,260,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:305,modifiability,version,version,305,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:254,safety,valid,valid,254,"I believe the issues are related. I think pip is trying to get the version of the wheel by parsing it's name instead. For example, I just ran into this with where scanpy's version was being reported as: `1.8.0.dev34-g8d8039d9` – which I don't think is a valid version. I then `pip install -e`'d and got a version of `1.8.0.dev29+gc8309488` (different branches) and it worked fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:16,interoperability,conflict,conflicts,16,"Damn more merge conflicts. I’ll fix it one last time then merge this, OK? Unfortunately this needs to be a rebase, otherwise I have to resolve everything again when rebasing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:48,performance,time,time,48,"Damn more merge conflicts. I’ll fix it one last time then merge this, OK? Unfortunately this needs to be a rebase, otherwise I have to resolve everything again when rebasing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:96,deployability,instal,install,96,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:183,deployability,upgrad,upgrades,183,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:226,deployability,instal,installs,226,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:247,deployability,upgrad,upgraded,247,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:270,deployability,upgrad,upgrading,270,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:290,deployability,instal,installed,290,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:301,deployability,releas,release,301,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:375,deployability,version,version,375,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:555,deployability,version,versions,555,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1138,deployability,build,building,1138,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:375,integrability,version,version,375,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:555,integrability,version,versions,555,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:922,interoperability,conflict,conflicts,922,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:183,modifiability,upgrad,upgrades,183,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:247,modifiability,upgrad,upgraded,247,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:270,modifiability,upgrad,upgrading,270,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:340,modifiability,concern,concern,340,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:375,modifiability,version,version,375,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:555,modifiability,version,versions,555,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:975,performance,time,time,975,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:202,security,ident,identifies,202,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:340,testability,concern,concern,340,"> Yeah, this is super weird. I think it's also blocking for adopting flit as recommended way to install scanpy to a dev environment. How has that to do with flit? Will pip just block upgrades things it identifies as “editable installs” from being upgraded while happily upgrading “normally installed” release candidates? > I still have the concern that pinning pip to an old version could lead to problems, especially while pip is going through a lot of changes. But we can leave this for now. If getting this wheel issue solved drags on for multiple pip versions, we may need to reconsider. Exactly! > I'm not 100% confident this isn't an issue, and it would be good to get more opinions on this. It wasn’t an issue for the year this PR has lingered, and now it’s pypa/pip#9628 and related discussions (which are already converging). I would like to meaningfully contribute to scanpy again instead of having to fix merge conflicts in this and discussing what pip broke this time. > In particular, this looks very brittle to me:. It isn’t, as you agreed on like 8 months ago. Worst that happens is “ImportError: cannot import ‘foo’” when building, which we can fix in 5 minutes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1812,availability,error,error,1812,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:363,deployability,stack,stack,363,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1123,deployability,stack,stack,1123,"h. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1316,deployability,instal,install,1316,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1360,deployability,instal,install,1360,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1385,deployability,instal,install,1385,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1402,deployability,Instal,Install,1402,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1423,deployability,depend,depends,1423,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1491,deployability,instal,installation,1491,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1652,deployability,version,version,1652,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2058,deployability,instal,installation,2058,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2101,deployability,instal,install,2101,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:2165,deployability,instal,installations,2165,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1423,integrability,depend,depends,1423,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1652,integrability,version,version,1652,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:853,interoperability,specif,specifically,853,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1000,interoperability,convers,conversation,1000,"d also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. Ho",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:467,modifiability,pac,packaging,467,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:966,modifiability,pac,packaging,966,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1423,modifiability,depend,depends,1423,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1652,modifiability,version,version,1652,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:55,performance,time,time,55,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1812,performance,error,error,1812,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:492,reliability,pra,practical,492,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1795,reliability,doe,does,1795,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:76,safety,review,reviewing,76,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1423,safety,depend,depends,1423,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1812,safety,error,error,1812,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:424,security,team,team,424,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:76,testability,review,reviewing,76,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:377,testability,understand,understand,377,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:446,testability,understand,understanding,446,"I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1423,testability,depend,depends,1423,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1186,usability,minim,minimize,1186,"lly like to see you contributing to other things. The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be ove",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1744,usability,experien,experience,1744,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1812,usability,error,error,1812,"hat it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. > It isn’t, as you agreed on like 8 months ago. I don't recall this specifically from 8 months ago. Theres a good chance that because I don't have as great of a knowledge about how packaging works, I understood our conversation in a different way. Because this is new, there's definitley going to be bugs. These are bugs with part of the stack that we don't have a lot of expertise in, so I'd like to minimize these before they become blockers. ```. $ conda create -yn flit-deps python=3.8 flit. $ conda activate flit-deps. $ flit install -s --dep=develop # Make development install of scanpy. $ pip install scvelo # Install project that depends on scanty. ... Attempting uninstall: scanpy. Found existing installation: scanpy 1.8.0.dev49-ge715cd98. Uninstalling scanpy-1.8.0.dev49-ge715cd98:. Successfully uninstalled scanpy-1.8.0.dev49-ge715cd98. ... # Development version of scanpy has now been uninstalled. ```. This is bad, and should not be the default experience for people who want to contribute. This does not give an error, or a warning. Yes there are solutions being proposed upstream, but we don't know how long until they are implemented. Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have `pip install -e` listed, and there has to be a note saying `flit -s` installations will be overridden due to a bug in `pip`. This stuff can be removed once this is fixed upstream.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:415,deployability,stack,stack,415,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1318,deployability,Stack,StackOverflow,1318,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1456,deployability,instal,installation,1456,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1498,deployability,instal,install,1498,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1559,deployability,instal,installations,1559,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:521,modifiability,pac,packaging,521,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1191,modifiability,pac,packaging,1191,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:57,performance,time,time,57,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:942,performance,time,time,942,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:546,reliability,pra,practical,546,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:78,safety,review,reviewing,78,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1070,safety,compl,complex,1070,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:478,security,team,team,478,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1070,security,compl,complex,1070,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:78,testability,review,reviewing,78,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:429,testability,understand,understand,429,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:500,testability,understand,understanding,500,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:898,testability,simpl,simpler,898,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:1175,testability,understand,understands,1175,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:898,usability,simpl,simpler,898,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:981,usability,experien,experienced,981,"> I would also like to see this merge. I've put a lot of time and effort into reviewing it, so we can get this over and done with. > Your contributions are invaluable to the project, and I'd really like to see you contributing to other things. thank you, I really appreciate this :heart: . > The reason I'm so hard on this is that it's critical to our project (and getting new contributors), and it's a part of the stack I don't understand. > I think you're the only one on the team who has a lot of understanding of the packaging ecosystem. The practical effect of this is that when things around this break, most of us have no idea what could be going wrong. What we have on master right now pretty much works. We've run into issues before, but it's been a while. Right now it's pretty smooth to set up a dev environment and contribute. Totally understood. My motivation to use flit is that it’s simpler and therefore better both for first-time contributors (to get started) and experienced people (to debug), whereas CLI, metadata, and code of setuptools/pip is very complex and a nightmare to debug. I know that due to flit being used less, there needs to be someone who understands the packaging ecosystem to fix things when they’re broken instead of cargo-culting one of the million answers around setuptools on StackOverflow. > Here's what I propose. I think this can be merged basically as is. However, until these issues are resolved: development installation instructions has to have pip install -e listed, and there has to be a note saying flit -s installations will be overridden due to a bug in pip. This stuff can be removed once this is fixed upstream. OK, will do! Can you link me tp the upstream discussion of this problem please?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,availability,restor,restore,7,Had to restore the branch to reopen #1700 (and switch its base to master),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:7,reliability,restor,restore,7,Had to restore the branch to reopen #1700 (and switch its base to master),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1528:30,modifiability,pac,package,30,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:89,reliability,doe,doesn,89,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:13,safety,test,tests,13,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:126,safety,test,tests,126,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:190,safety,test,tests,190,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:207,safety,test,tests,207,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:283,safety,test,tests,283,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:346,safety,test,tests,346,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:362,safety,test,tests,362,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:419,safety,test,tests,419,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:437,safety,test,tests,437,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:510,safety,test,tests,510,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:690,safety,test,tests,690,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:13,testability,test,tests,13,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:126,testability,test,tests,126,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:190,testability,test,tests,190,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:207,testability,test,tests,207,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:283,testability,test,tests,283,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:346,testability,test,tests,346,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:362,testability,test,tests,362,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:419,testability,test,tests,419,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:437,testability,test,tests,437,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:510,testability,test,tests,510,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:690,testability,test,tests,690,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:471,usability,learn,learn,471,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:484,usability,learn,learn,484,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:521,usability,person,personally,521,"Why move the tests out of the package? It's what I've done in the past, but it certainly doesn't seem like the norm ([`pandas/tests`](https://github.com/pandas-dev/pandas/tree/master/pandas/tests), [`altair/tests`](https://github.com/altair-viz/altair/tree/master/altair), [`seaborn/tests`](https://github.com/mwaskom/seaborn/tree/master/seaborn/tests), [`numba/tests`](https://github.com/numba/numba/tree/master/numba/tests), [`sklearn/tests`](https://github.com/scikit-learn/scikit-learn/tree/master/sklearn/tests)). I personally think fixtures in `conftest.py` is poor style (why would these things all go in one file? Why is this the one place which gets implicitly imported in all the tests?).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:159,deployability,modul,module-level,159,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:956,deployability,automat,automatically,956,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1300,deployability,modul,module,1300,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1678,deployability,instal,installing,1678,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1966,deployability,depend,depending,1966,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:729,integrability,sub,subfolder,729,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1966,integrability,depend,depending,1966,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:10,interoperability,architectur,architecture,10,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:94,modifiability,pac,packages,94,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:159,modifiability,modul,module-level,159,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:348,modifiability,pac,packages,348,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:806,modifiability,pac,package,806,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:989,modifiability,pac,package,989,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1300,modifiability,modul,module,1300,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1828,modifiability,pac,package,1828,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1873,modifiability,concern,concerns,1873,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1931,modifiability,reu,reusable,1931,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1966,modifiability,depend,depending,1966,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:2041,modifiability,reu,reusable,2041,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1191,reliability,doe,does,1191,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1273,reliability,doe,doesn,1273,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1921,reliability,doe,does,1921,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:25,safety,test,tests,25,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:159,safety,modul,module-level,159,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:257,safety,test,tests,257,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:357,safety,except,except,357,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:428,safety,test,test,428,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:796,safety,test,testing,796,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:975,safety,test,tests,975,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1101,safety,test,tests,1101,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1173,safety,test,test,1173,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1234,safety,test,tests,1234,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1300,safety,modul,module,1300,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1368,safety,accid,accidentally,1368,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1599,safety,test,test,1599,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1701,safety,test,tests,1701,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1713,safety,test,testing,1713,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1900,safety,test,testing,1900,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1966,safety,depend,depending,1966,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1998,safety,test,tests,1998,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:2016,safety,test,tests,2016,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1557,security,misus,misuse,1557,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:25,testability,test,tests,25,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:257,testability,test,tests,257,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:428,testability,test,test,428,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:796,testability,test,testing,796,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:956,testability,automat,automatically,956,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:975,testability,test,tests,975,"## Pytest architecture. `tests` directories and `test_*.py` collections aren’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `te",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1101,testability,test,tests,1101,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1173,testability,test,test,1173,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1234,testability,test,tests,1234,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1599,testability,test,test,1599,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1701,testability,test,tests,1701,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1713,testability,test,testing,1713,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1873,testability,concern,concerns,1873,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1900,testability,test,testing,1900,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1966,testability,depend,depending,1966,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1998,testability,test,tests,1998,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:2016,testability,test,tests,2016,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1143,usability,close,close,1143,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1638,usability,user,user,1638,"’t intended to be packages, so you shouldn’t import from there. Just think about a module-level `pytest.importorskip(...)` or so. Also if there’s a `__init__.py` somewhere in your `tests` directory when using pytest, you’re doing something wrong. Yes, that means that all packages except for numba are doing it wrong, because numba also has importable test utils in there, and the others just misunderstand how pytest works. I blame setuptools, because `find_packages` finds directories that have `__init__.py`, so people just cargo-cultily started adding it without knowing what they’re doing. Fixture visibility is hierarchical, so a conftest.py in a subfolder is able to override fixtures from higher-up. So e.g. for testing a package/app that uses celery, you just define your own `celery_config` fixture, then start using the `celery_app` fixture, which will use your config automatically. ## `tests` in the package. I think it’s a good idea to have it in there if you are a huge project and like to physically split up tests into multiple directiories that are close to the source code they test. (like numpy does it). But as long as there’s only one `tests` directory with a structure that doesn’t neatly map to your module hierarchy, having it outside is cleaner because people can’t accidentally import from there. And as you can see from your links and our contributors importing stuff from `test_*` collections, a lot of projects don’t know how to use pytest, so making misuse harder is beneficial. Also we have test data, which wastes space on every user’s machine and bandwidth for people installing scanpy. ## `tests` and `testing`/`test_utils`. Given the above points, I think we should move things out to keep everything clean, and the package small. I also like the separation of concerns: `test_utils` or `testing` (like numpy does) for reusable stuff that other projects depending on you might use and `tests` for actual tests. We can import the reusable fixtures in `conftest.py`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:162,deployability,modul,modules,162,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:191,deployability,modul,modules,191,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:294,deployability,releas,releases,294,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:162,modifiability,modul,modules,162,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:191,modifiability,modul,modules,191,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:157,safety,test,test,157,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:162,safety,modul,modules,162,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:186,safety,test,test,186,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:191,safety,modul,modules,191,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:157,testability,test,test,157,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:186,testability,test,test,186,"I also just found this: https://docs.pytest.org/en/stable/pythonpath.html#import-modes. > `importlib`: new in pytest-6.0, this mode uses importlib to import test modules. > […]. > makes test modules non-importable by each other. > […]. > . > **We intend to make importlib the default in future releases.**.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:211,deployability,fail,failed,211,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:220,deployability,continu,continueOnError,220,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:694,deployability,modul,modules,694,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:887,deployability,version,version,887,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:667,energy efficiency,current,currently,667,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1140,energy efficiency,measur,measure,1140,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:887,integrability,version,version,887,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:434,modifiability,pac,package,434,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:694,modifiability,modul,modules,694,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:887,modifiability,version,version,887,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:211,reliability,fail,failed,211,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:79,safety,test,tests,79,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:149,safety,test,tests,149,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:417,safety,test,tests,417,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:505,safety,test,testing,505,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:567,safety,test,tests,567,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:689,safety,test,test,689,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:694,safety,modul,modules,694,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:790,safety,test,tests,790,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1180,safety,test,tests,1180,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1224,safety,test,test,1224,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1243,safety,test,tests,1243,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:79,testability,test,tests,79,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:149,testability,test,tests,149,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:417,testability,test,tests,417,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:505,testability,test,testing,505,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:567,testability,test,tests,567,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:689,testability,test,test,689,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:790,testability,test,tests,790,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1180,testability,test,tests,1180,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1224,testability,test,test,1224,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:1243,testability,test,tests,1243,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:513,usability,tool,tool,513,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:635,usability,clear,clear,635,"I've thought about it a bit more, and now think I agree with having the static tests in a separate job. I would like if this could also add `flake8` tests, and was setup so they would all run, regardless if any failed (`continueOnError: 'true'`). --------------------------------------. I don't think I agree with the rest, but am only going to give a partial response for now. . I'm not convinced we should move the tests out of the package. Broadly, I don't think `pytest` is a particularly opinionated testing tool, so I'm not sure one can use it wrong unless the tests aren't actually running. I do think their docs are not always clear/ correct. For example, we currently import from test modules https://github.com/theislab/scanpy/blob/8d9eec4c4763edb4a522dbec3fa5ea48832ff0f8/scanpy/tests/test_embedding_plots.py#L12. But:. ```sh. isaac@Mimir:~/github/scanpy ‹master›. $ pytest --version. pytest 6.1.2. isaac@Mimir:~/github/scanpy ‹master›. $ pytest -n 6 --import-mode=importlib. ... ================================ 587 passed, 17 skipped, 1 xfailed, 172 warnings in 84.39s (0:01:24) ================================. ```. For good measure I also chucked a `import scanpy.tests.test_embedding_plots` into one of the test files and the tests still ran with `--import-mode=importlib`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:94,availability,down,download,94,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:598,availability,sli,slight,598,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:612,availability,sli,slight,612,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:126,deployability,instal,installing,126,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:326,deployability,modul,modules,326,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:299,energy efficiency,current,currently,299,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:713,interoperability,conflict,conflicts,713,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:203,modifiability,pac,packages,203,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:326,modifiability,modul,modules,326,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:598,reliability,sli,slight,598,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:612,reliability,sli,slight,612,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:111,safety,test,test,111,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:175,safety,test,test,175,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:245,safety,test,test,245,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:282,safety,test,test,282,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:321,safety,test,test,321,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:326,safety,modul,modules,326,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:111,testability,test,test,111,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:175,testability,test,test,175,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:245,testability,test,test,245,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:282,testability,test,test,282,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:321,testability,test,test,321,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:180,usability,tool,tools,180,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:250,usability,tool,tools,250,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:269,usability,document,document,269,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:287,usability,tool,tools,287,"We should also move them out because of file size, I don’t think everyone should be forced to download all our test data when installing scanpy. We should separate importable test tools (that e.g. other packages can import too) and our internal test tools. We can then document the test tools. > we currently import from test modules . yes, my PR fixes that. ----. But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. Since there’s no obvious reason to not do it, why struggle to find any? We can just take the obvious advantages (however slight or non-slight they may be) and do it. So is it OK if I go ahead and merge this before more PRs come in with conflicts? It’s getting a bit tiring to resolve those.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:548,deployability,releas,release,548,"> So is it OK if I go ahead and merge this before more PRs come in with conflicts? . No. There are already open PRs which I'm working on merging, and this will cause conflicts in those. > But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. I've only partially responded because I'm low on time. At first glance, there are a number of things I'm against here. But I'll be able to consider them more thoroughly, and tell you my arguments, once I've got more time – sometime after the 1.7.0 release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:72,interoperability,conflict,conflicts,72,"> So is it OK if I go ahead and merge this before more PRs come in with conflicts? . No. There are already open PRs which I'm working on merging, and this will cause conflicts in those. > But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. I've only partially responded because I'm low on time. At first glance, there are a number of things I'm against here. But I'll be able to consider them more thoroughly, and tell you my arguments, once I've got more time – sometime after the 1.7.0 release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:166,interoperability,conflict,conflicts,166,"> So is it OK if I go ahead and merge this before more PRs come in with conflicts? . No. There are already open PRs which I'm working on merging, and this will cause conflicts in those. > But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. I've only partially responded because I'm low on time. At first glance, there are a number of things I'm against here. But I'll be able to consider them more thoroughly, and tell you my arguments, once I've got more time – sometime after the 1.7.0 release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:349,performance,time,time,349,"> So is it OK if I go ahead and merge this before more PRs come in with conflicts? . No. There are already open PRs which I'm working on merging, and this will cause conflicts in those. > But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. I've only partially responded because I'm low on time. At first glance, there are a number of things I'm against here. But I'll be able to consider them more thoroughly, and tell you my arguments, once I've got more time – sometime after the 1.7.0 release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:516,performance,time,time,516,"> So is it OK if I go ahead and merge this before more PRs come in with conflicts? . No. There are already open PRs which I'm working on merging, and this will cause conflicts in those. > But even if you don’t fully agree with all of my arguments, there’s still arguments, and zero for not doing it. I've only partially responded because I'm low on time. At first glance, there are a number of things I'm against here. But I'll be able to consider them more thoroughly, and tell you my arguments, once I've got more time – sometime after the 1.7.0 release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:56,modifiability,pac,packages,56,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:103,modifiability,pac,package,103,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:151,modifiability,pac,packages,151,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:186,modifiability,pac,package,186,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:79,safety,test,test,79,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:79,testability,test,test,79,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:130,usability,learn,learn,130,"@ivirshup I'd actually be interest in hearing those. My packages also have the test folder outside the package, but I am happy to learn why many major packages have theirs in the actual package and why that might be a good idea.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:50,testability,plan,plan,50,"Me too, but we can sidestep the issue now with my plan in https://github.com/scverse/scanpy/issues/2225",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1529:164,deployability,log,logFC,164,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:164,safety,log,logFC,164,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:110,security,sign,significant,110,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:164,security,log,logFC,164,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:164,testability,log,logFC,164,"Are the bottom ranked really not expressed, or just not differentially expressed? The former could still have significant p-values. I guess I wonder if you rank by logFC or by adjusted p-value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:188,deployability,log,log,188,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:355,deployability,log,log,355,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:297,modifiability,paramet,parameter,297,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:188,safety,log,log,188,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:355,safety,log,log,355,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:437,safety,test,tests,437,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:188,security,log,log,188,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:231,security,sign,significant,231,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:355,security,log,log,355,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:29,testability,simpl,simply,29,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:188,testability,log,log,188,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:355,testability,log,log,355,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:437,testability,test,tests,437,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:29,usability,simpl,simply,29,"@LuckyMD genes at the bottom simply have the lowest rank but they could be expressed. By default the ranking is taking directly from `sc.get.rank_genes_groups_df` which ranks the genes by log fold change. Bottom genes tend to have significant p-value. . To make this more transparent we can add a parameter to select how to rank for example by p-value or log fold change. . But, first I need to figure out what is this mess with the new tests....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:80,deployability,log,logFC,80,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:65,integrability,filter,filter,65,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:132,integrability,filter,filtering,132,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:52,reliability,doe,doesn,52,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:80,safety,log,logFC,80,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:80,security,log,logFC,80,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:80,testability,log,logFC,80,"Yeah, I recently found out that `rank_genes_groups` doesn't just filter for +ve logFC, but ranks by it. I used to think that it's a filtering and you needed to do A vs B and B vs A to get all results ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:463,availability,state,state,463,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:630,availability,cluster,cluster,630,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:657,availability,cluster,cluster,657,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:734,availability,cluster,cluster,734,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:630,deployability,cluster,cluster,630,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:657,deployability,cluster,cluster,657,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:734,deployability,cluster,cluster,734,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1430,deployability,log,logfoldchange,1430,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1510,deployability,log,logfoldchange,1510,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:455,energy efficiency,current,current,455,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:463,integrability,state,state,463,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:524,integrability,filter,filter,524,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:896,integrability,filter,filtering,896,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1065,integrability,filter,filtering,1065,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1231,integrability,filter,filtering,1231,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1300,integrability,filter,filter,1300,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1365,integrability,filter,filtering,1365,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1419,integrability,filter,filtering,1419,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:272,interoperability,specif,specific,272,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:720,interoperability,specif,specific,720,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:982,safety,compl,complicated,982,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1430,safety,log,logfoldchange,1430,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1510,safety,log,logfoldchange,1510,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:688,security,ident,identification,688,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:982,security,compl,complicated,982,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1430,security,log,logfoldchange,1430,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1510,security,log,logfoldchange,1510,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1430,testability,log,logfoldchange,1430,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:1510,testability,log,logfoldchange,1510,"@LuckyMD Your impression is right, but after changes to `sc.tl.rank_genes_groups` were introduced, now by default the full list of genes is returned and is not necessary to do A vs. B and then B vs A. In my impression this change opened new opportunities, like looking at specific genes or looking at the bottom ranked. However, I think it is worth to make the ranking and selection more transparent and I am open here for suggestions. For background the current state is:. * `sc.tl.filter_rank_genes_groups` can be used to filter the results in different ways like fold change or fraction of cells expressing the gene in a given cluster or outside a given cluster. The goal was to allow identification of markers quite specific to a cluster. Although, I made this function I think we should not use it as it is not up to date and creates confusion because it replaces genes by NaNs to allow the filtering. This was pre `sc.get.rank_genes_groups_df` and some other changes. Also is complicated to use because is run, a new rank_genes_groups key is created with the filtering and this key has to be added to the plotting functions to see the results. . * The `sc.pl.rank_genes_groups_*` plots have the option `min_logfoldchage` for filtering. I find this useful but limited because is not possible to filter by p-value for example. As a solution, plots could have a filtering option that uses pandas query syntax like: `filtering='logfoldchange>1 & p-value<0.0001'` and for the sorting something like `sortby=('logfoldchange', 'ascend')`. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:172,integrability,filter,filtering,172,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:307,integrability,filter,filtered,307,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:376,integrability,filter,filtering,376,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:430,integrability,filter,filtering,430,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:264,performance,perform,perform,264,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:220,safety,test,testing,220,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:281,safety,test,testing,281,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:207,security,sign,significance,207,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:220,testability,test,testing,220,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:281,testability,test,testing,281,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:264,usability,perform,perform,264,I like your suggestions. Especially the `filter_rank_genes_groups` use makes a lot of sense to me. The one thing I would suggest to take into account is that some of these filtering steps can be done before significance testing and therefore you would not have to perform multiple testing correction on the filtered out genes. This may be quite useful to some. That precludes filtering on p-value though. It also makes a case for filtering already in `rank_genes_groups` rather than in `sc.get`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:23,integrability,filter,filtering,23,My suggestion is to do filtering on the fly. . What I am not so sure is how to nicely achieve this without creating too many parameters and/or too much typing that is difficult to remember.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:125,modifiability,paramet,parameters,125,My suggestion is to do filtering on the fly. . What I am not so sure is how to nicely achieve this without creating too many parameters and/or too much typing that is difficult to remember.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:180,safety,reme,remember,180,My suggestion is to do filtering on the fly. . What I am not so sure is how to nicely achieve this without creating too many parameters and/or too much typing that is difficult to remember.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:113,availability,avail,available,113,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:103,integrability,filter,filtering,103,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:11,reliability,Doe,Does,11,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:113,reliability,availab,available,113,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:80,safety,compl,complex,80,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:113,safety,avail,available,113,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:80,security,compl,complex,80,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:113,security,availab,available,113,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:269,usability,user,users,269,"Re: #1649. Does this still need a max fold change argument? More generally, how complex do we want the filtering available through these functions (and `sc.get.rank_genes_groups_df`) to be? Is it most straight forward to recommend passing the gene names, and recommend users generate these by manipulating the dataframe returned by `rank_genes_groups_df`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:16,deployability,updat,updated,16,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:175,deployability,releas,release,175,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:16,safety,updat,updated,16,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:36,safety,test,tests,36,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:16,security,updat,updated,16,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:36,testability,test,tests,36,"@fidelram, I've updated this so the tests pass, and think I've caught a few more bugs. Hopefully I didn't misinterpret your intent here, but I'm merging as we'd like to get a release out. Please let me know if I've messed anything up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/issues/1530:149,deployability,log,logreg,149,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,deployability,log,logreg,261,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:348,deployability,log,logreg,348,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:470,deployability,stack,stack,470,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:662,deployability,log,logistic,662,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:715,deployability,log,logfoldchange,715,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:5,energy efficiency,current,currently,5,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:623,energy efficiency,adapt,adapted,623,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:623,integrability,adapt,adapted,623,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:623,interoperability,adapt,adapted,623,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:623,modifiability,adapt,adapted,623,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:149,safety,log,logreg,149,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,safety,log,logreg,261,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:316,safety,test,test,316,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:348,safety,log,logreg,348,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:388,safety,test,test,388,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:405,safety,test,test,405,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:458,safety,test,test,458,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:465,safety,test,test,465,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:500,safety,test,test,500,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:516,safety,test,test,516,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:545,safety,test,test,545,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:586,safety,test,test,586,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:645,safety,except,exception,645,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:662,safety,log,logistic,662,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:715,safety,log,logfoldchange,715,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:149,security,log,logreg,149,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,security,log,logreg,261,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:348,security,log,logreg,348,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:662,security,log,logistic,662,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:715,security,log,logfoldchange,715,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:149,testability,log,logreg,149,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,testability,log,logreg,261,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:316,testability,test,test,316,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:348,testability,log,logreg,348,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:388,testability,test,test,388,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:405,testability,test,test,405,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:458,testability,test,test,458,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:465,testability,test,test,465,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:500,testability,test,test,500,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:516,testability,test,test,516,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:545,testability,test,test,545,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:586,testability,test,test,586,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:662,testability,log,logistic,662,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:671,testability,regress,regression,671,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:715,testability,log,logfoldchange,715,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:51,usability,user,user-only,51,"I am currently having the same issue as well. As a user-only mostly, I tried to dig into the code and found a workaround to get a dataframe with the logreg scores (so, please forgive any inaccuracy and my naivety). After `sc.tl.rank_genes_groups` with `method='logreg'`:. ```python. colnames = ['names', `'scores']. test = [pd.DataFrame(adata.uns[""logreg""][c])[group] for c in colnames]. test = pd.concat(test, axis=1, names=[None, 'group'], keys=colnames). test = test.stack(level=1).reset_index(). test[""group""] = test[""group""].astype(""int""). test.sort_values('group', inplace=True). test. ```. I guess the code could be adapted to expect the exception of the logistic regression being different, i.e. not having logfoldchange and p-values, and allow the retrieval of a Dataframe with scores nonetheless.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:49,deployability,version,versions,49,"Should be solved now (scanpy 1.9.5, some earlier versions already), see comment here #2363.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:49,integrability,version,versions,49,"Should be solved now (scanpy 1.9.5, some earlier versions already), see comment here #2363.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:49,modifiability,version,versions,49,"Should be solved now (scanpy 1.9.5, some earlier versions already), see comment here #2363.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:127,deployability,version,versions,127,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,deployability,version,version,261,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:127,integrability,version,versions,127,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,integrability,version,version,261,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:127,modifiability,version,versions,127,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:261,modifiability,version,version,261,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:146,usability,close,close,146,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:214,usability,experien,experiencing,214,"Thanks everyone for posting here following up this issue! As the initial reproducible example now works with the latest scanpy versions, we might close the issue soon. Kindly let us know in a new issue if you keep experiencing this issue, along with the scanpy version you are using!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1531:136,modifiability,paramet,parameters,136,"Thanks for the nice investigation. However, is very difficult to say what the differences could be. Have you checked the `sc.tl.leiden` parameters. I think that by default `weights=True`. Also `sc.pp.neighbors` has as default `n_neighbors=15` ( I think). This may account for some differences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:262,availability,cluster,clusterings,262,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:401,availability,cluster,clustering,401,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:262,deployability,cluster,clusterings,262,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:401,deployability,cluster,clustering,401,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:46,energy efficiency,model,model,46,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:381,interoperability,distribut,distribution,381,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:453,interoperability,share,shared,453,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:46,security,model,model,46,"Hey @mxposed! Nice work on the scArches covid model! Love these types of comparisons :). There are a lot of potential differences. Just a few that come to mind:. 1. Louvain and leiden are stochastic... random seeds will differ. This can generate quite different clusterings. I would check against different choices of random seed in Scanpy and/or Seurat to see what the background distribution is for clustering quality. 2. Seurat uses what it calls a ""shared nearest neighbour graph"". That is weighted by Jaccard Index by default. I'm not sure that's the case in scanpy. 3. Numerical library differences means you will never get the same result :/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:123,availability,sli,slightly,123,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:318,deployability,modul,modularity,318,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:318,integrability,modular,modularity,318,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:66,modifiability,paramet,parameters,66,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:318,modifiability,modul,modularity,318,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:255,performance,content,content,255,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:123,reliability,sli,slightly,123,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:318,safety,modul,modularity,318,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:318,testability,modula,modularity,318,"My two cents. In additions to everything mentioned in this issue (parameters, rng, libraries) and the fact sNN and kNN are slightly different, neither Leiden nor Louvain method will save you from missing small populations (see [here](https://www.pnas.org/content/104/1/36)), it is a well-known issue when working with modularity.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:81,deployability,scale,scale,81,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:180,deployability,modul,modules,180,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:81,energy efficiency,scale,scale,81,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:126,interoperability,distribut,distribution,126,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:81,modifiability,scal,scale,81,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:180,modifiability,modul,modules,180,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:81,performance,scale,scale,81,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:180,safety,modul,modules,180,"True, the resolution limit could play a role. But I would assume not yet at this scale, as we would expect a more even degree distribution in a kNN graph, and we're not looking at modules that make up a very small proportion of the total nodes. It would be interesting to check when this starts being important for larger atlases. Have you found this to be a problem in some of your datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:57,deployability,scale,scale,57,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:178,deployability,depend,depend,178,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:57,energy efficiency,scale,scale,57,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:178,integrability,depend,depend,178,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:57,modifiability,scal,scale,57,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:178,modifiability,depend,depend,178,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:57,performance,scale,scale,57,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:178,safety,depend,depend,178,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:178,testability,depend,depend,178,"@LuckyMD Mine was a general answer, I agree that at this scale it may not be an issue but it may indeed be for larger atlases. @mxposed about your first question: cell distances depend on the HVG in absolute terms, but the overall structure of your data is more ""relative"". If the kNN graph topology is overall conserved you'll end up with similar populations.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:728,availability,cluster,clustering,728,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1474,availability,slo,slow,1474,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:323,deployability,updat,updated,323,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:728,deployability,cluster,clustering,728,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1551,deployability,log,log-norm,1551,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:746,energy efficiency,estimat,estimate,746,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:712,interoperability,distribut,distribution,712,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:72,modifiability,paramet,parameter,72,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:212,modifiability,paramet,parameter,212,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:833,reliability,doe,does,833,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:846,reliability,doe,doesn,846,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1474,reliability,slo,slow,1474,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1570,reliability,doe,does,1570,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:323,safety,updat,updated,323,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:994,safety,reme,remember,994,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1551,safety,log,log-norm,1551,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:323,security,updat,updated,323,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:701,security,assess,assess,701,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1551,security,log,log-norm,1551,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1551,testability,log,log-norm,1551,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1655,usability,behavi,behaviour,1655,"@fidelram Thank you for pointing this out. I did miss the `n_neighbors` parameter for `sc.pp.neighbors` function. It has default 15, while Seurat's have default 20 (and yes, they then prune the kNN). Adding this parameter did solve the discrepancy in the first dataset, but not the second, in the investigation (I have not updated the notebook). @LuckyMD Thank you! I really liked applying scArches, and it's also a very natural approach: having a reference, mapping to it. I hope we're moving towards that direction generally. Thank you for pointing out that Leiden is stochastic, I didn't realize that, and the fixed default random seed obscures it a little. I'll try to look at different seeds and assess the distribution of clustering. Can't estimate to which degree different runs would disagree. Indeed, it appears that scanpy does kNN and doesn't do any pruning (judging from my brief glance at the code). I honestly expected that some kind of pruning of the kNN graph would be there. I remember two talks, one from Dana Pe'er and one from Dominic Grün, that mentioned kNN pruning as a strategy to improve analysis. @dawe Thank you for linking to the resolution limit. However, I don't think it's the case here, because 2 of the 3 strategies that I tried did resolve those populations. . If we focus on dataset 2 (SC167) in the investigation, obviously, there's some small kNN topology difference between the strategies tried, that leads to SCT+scanpy strategy being slow to separate DC1 cells from B cells. I am mostly surprised that vanilla (log-norm) strategy does separate those cells. . I wonder how to go about investigating what drives that behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:265,deployability,version,versions,265,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:450,deployability,instal,install,450,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:507,deployability,instal,install,507,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:905,deployability,log,log,905,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:265,integrability,version,versions,265,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:909,integrability,transform,transform,909,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1160,integrability,sub,subset,1160,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1185,integrability,sub,subset,1185,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:909,interoperability,transform,transform,909,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:228,modifiability,Variab,Variable,228,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:265,modifiability,version,versions,265,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:706,modifiability,variab,variable,706,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1082,modifiability,variab,variable,1082,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1374,modifiability,Variab,VariableFeatures,1374,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1516,performance,perform,perform,1516,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:905,safety,log,log,905,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:905,security,log,log,905,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:905,testability,log,log,905,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:517,usability,user,user,517,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1516,usability,perform,perform,1516,"@mxposed It may be worth noting that scanpy's sc.pp.highly_variable_genes takes an argument `flavor` which defaults to the original [2015 Seurat paper](https://www.nature.com/articles/nbt.3192). To Obtain the same set of Highly Variable Genes as produced by modern versions of Seurat [2019 Stuart et al. paper](https://www.sciencedirect.com/science/article/pii/S0092867419305598), it is necessary to pass 'seurat_v3' for this value. You will need to install scikit-misc for this method to work:. ```sh. pip install --user scikit-misc. ```. But there is another wrinkle... the seurat3 algorithm needs count data. therefore it is necessary to rearrange the normalization in scanpy:. ```py. # find the highly variable genes... # Since we are using seurat_v3 as the flavor,. # we have to do this before normalization. sc.pp.highly_variable_genes(sc96, flavor='seurat_v3', . n_top_genes=2000). # Normalize and log transform (over all genes). sc.pp.normalize_total(sc96, target_sum=1e4). sc.pp.log1p(sc96). # it is necessary to do the Normalization before selecting. # to just the highly variable genes else our normalization . # for reads will only be counting the subset. # now select the subset. sc96 = sc96[:,sc96.var.highly_variable]. ```. With these steps scanpy selects the exact same set of HGV and the Normalized log1p data in scanpy `sc96.X` is equal to `sc96$RNA@data)[VariableFeatures(object=sc96),]` in Seurat to about 6 decimal places in my dataset. And thanks for sharing your notebook link, I am trying to perform a similar comparison.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/pull/1533:61,energy efficiency,GPU,GPU,61,"I am tacking the liberty of bumping this PR, as I have added GPU support for `sc.pp.pca` on the latest commit! (had to force push it to fix a big typo on the commit title)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:61,performance,GPU,GPU,61,"I am tacking the liberty of bumping this PR, as I have added GPU support for `sc.pp.pca` on the latest commit! (had to force push it to fix a big typo on the commit title)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:65,usability,support,support,65,"I am tacking the liberty of bumping this PR, as I have added GPU support for `sc.pp.pca` on the latest commit! (had to force push it to fix a big typo on the commit title)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:146,availability,avail,available,146,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:137,energy efficiency,GPU,GPUs,137,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,energy efficiency,GPU,GPU,170,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:269,energy efficiency,GPU,GPU,269,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:525,energy efficiency,CPU,CPU,525,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:533,energy efficiency,GPU,GPU,533,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:621,energy efficiency,GPU,GPU,621,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:66,integrability,coupl,couple,66,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:66,modifiability,coupl,couple,66,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:343,modifiability,paramet,parameter,343,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:137,performance,GPU,GPUs,137,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,performance,GPU,GPU,170,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:269,performance,GPU,GPU,269,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:525,performance,CPU,CPU,525,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:533,performance,GPU,GPU,533,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:621,performance,GPU,GPU,621,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:146,reliability,availab,available,146,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:146,safety,avail,available,146,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:146,security,availab,available,146,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:66,testability,coupl,couple,66,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:273,usability,support,support,273,"Dear @LouisFaure,. thank you very much for the high quality PR. A couple of questions:. 1. Do you think that we should check for whether GPUs are available if any of the GPU accelerated methods were chosen? This would allow us to exit more nicely if we were requesting GPU support but none were found. 2. I think that we should homogenize the parameter names for the method selection. Sometimes they are called 'method', sometimes 'flavor' and then you're also using 'device'. I myself am a fan of 'device' to switch between CPU and GPU implementations. However, then it would be unclear which method to use when several GPU accelerated algorithms for a task are implemented. Do you have better ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:214,availability,slo,slow,214,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:272,deployability,manag,manage,272,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:378,deployability,contain,containers,378,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:402,deployability,pipelin,pipelines,402,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:425,deployability,contain,containers,425,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:496,deployability,contain,containers,496,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:272,energy efficiency,manag,manage,272,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:392,integrability,Configur,Configure,392,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:402,integrability,pipelin,pipelines,402,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:464,interoperability,standard,standard,464,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:140,modifiability,pac,package,140,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:392,modifiability,Configur,Configure,392,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:214,reliability,slo,slow,214,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:65,safety,review,review,65,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:163,safety,test,test,163,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:272,safety,manag,manage,272,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:116,security,sign,significant,116,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:392,security,Configur,Configure,392,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:65,testability,review,review,65,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:163,testability,test,test,163,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:77,usability,person,personally,77,"Hey, just wanted to comment here on why it's taken so long for a review. I'm personally not comfortable with having significant code in the package that we cannot test on CI. We're looking into this, but it's been slow going since it looks like we have to set this up and manage it on our own. As far as I can tell this process is:. * Put money into the azure account. * Set up containers. * Configure pipelines to use these containers (not sure if we can use the standard Tasks on ""self hosted"" containers) . @Zethson, since you're actually at the institute with the money you may have better luck moving the first step forward than I've had. Do you think you'd be able to look into this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,deployability,resourc,resources,170,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:127,energy efficiency,core,core,127,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:136,energy efficiency,core,core,136,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,energy efficiency,resourc,resources,170,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,performance,resourc,resources,170,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,safety,resourc,resources,170,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:170,testability,resourc,resources,170,"@ivirshup fully agree. The CI must cover as much as possible. . We actually have the same issue over at https://github.com/mlf-core/mlf-core . I can certainly get us the resources, but might not be able to implement it soonish. However, I would be interested in taking up this task. I'll create an issue and assign myself. But again, don't expect it soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:169,availability,avail,available,169,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:238,deployability,instal,installed,238,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:249,deployability,depend,depending,249,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:363,deployability,instal,installation,363,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:828,deployability,api,api,828,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:75,energy efficiency,GPU,GPU,75,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:162,energy efficiency,gpu,gpu,162,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:356,energy efficiency,GPU,GPU,356,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:634,energy efficiency,cpu,cpu,634,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:640,energy efficiency,gpu,gpu,640,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:900,energy efficiency,gpu,gpu,900,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:971,energy efficiency,gpu,gpu,971,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:1028,energy efficiency,cpu,cpu,1028,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:249,integrability,depend,depending,249,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:828,integrability,api,api,828,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:828,interoperability,api,api,828,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:249,modifiability,depend,depending,249,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:666,modifiability,paramet,parameters,666,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:1070,modifiability,maintain,maintainers,1070,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:75,performance,GPU,GPU,75,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:162,performance,gpu,gpu,162,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:356,performance,GPU,GPU,356,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:634,performance,cpu,cpu,634,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:640,performance,gpu,gpu,640,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:900,performance,gpu,gpu,900,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:971,performance,gpu,gpu,971,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:1028,performance,cpu,cpu,1028,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:1208,performance,time,time,1208,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:169,reliability,availab,available,169,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:169,safety,avail,available,169,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:249,safety,depend,depending,249,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:1070,safety,maintain,maintainers,1070,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:169,security,availab,available,169,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:28,testability,understand,understand,28,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:249,testability,depend,depending,249,"Thanks for your comments, I understand the struggle of implementing CI for GPU code! @Zethson here are my answers to your questions:. 1. Instead of checking if a gpu is available, I would suggest to rather check if the related library is installed (depending on the method, it could be cugraph, cupy or cuml) since each of these libraries always require a GPU at installation and usage, I think using these as check would suffice. 2. I agree with moving to the usage of 'device' as much as possible. It should be easily possible to rename ""method""/""flavor"" to ""device"" for `tl.draw_graph`, `tl.leiden` and `tl.louvain`, and use only ""cpu""/""gpu"" as choices as theses parameters would have only two choices anyway. In most case this would indeed remove the name of the python backend used, but one could instead mention it in the api/doc. . `pp.neighbors` is a bit more tricky to handle, running it in gpu mode lead to a combination of distances/neighbors calculation with gpu/cuml backend and then connectivities calculations on cpu/umap backend, this could be solved if maintainers of cuml decide to allow the latter to be computed with cuml: https://github.com/rapidsai/cuml/issues/3123. Since it will take time before CI can be implemented, I can just add the easy small changes proposed on 2. and let the PR open so you decide what to do later!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:196,availability,down,down,196,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:292,availability,ping,ping,292,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:217,energy efficiency,GPU,GPU,217,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:399,energy efficiency,GPU,GPU,399,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:186,interoperability,conflict,conflicts,186,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:115,performance,time,time,115,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:217,performance,GPU,GPU,217,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:399,performance,GPU,GPU,399,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:337,reliability,Doe,Does,337,@LouisFaure Great! While I agree with your comments and suggestions I think that for now you can save yourself the time to implement them since they are likely to run into further merge conflicts down the road. . The GPU CI is certainly off weeks if not months. As soon as it's ready I would ping you again and we can get this PR ready. Does this sound fine to you? Thanks again! Looking forward to GPU accelerated Scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:216,deployability,manag,management,216,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:118,energy efficiency,GPU,GPUs,118,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:205,energy efficiency,GPU,GPU,205,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:216,energy efficiency,manag,management,216,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:252,modifiability,pac,packages,252,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:118,performance,GPU,GPUs,118,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:205,performance,GPU,GPU,205,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:209,performance,memor,memory,209,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:216,safety,manag,management,216,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:209,usability,memor,memory,209,diffusion maps and TSNE also work with cupy and rapids. Diffusion Maps don't see a massive speedup maybe 2X on modern GPUs. TSNE sees a massive speedup. For larger anndata objects it's important to set up GPU memory management for both cupy and rapids packages. This becomes very import on hardware with low VRAM,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,availability,avail,available,100,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:332,deployability,contain,containing,332,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:546,deployability,scale,scale,546,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:34,energy efficiency,GPU,GPU,34,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:546,energy efficiency,scale,scale,546,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:615,integrability,wrap,wrapper,615,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:615,interoperability,wrapper,wrapper,615,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:546,modifiability,scal,scale,546,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:34,performance,GPU,GPU,34,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:546,performance,scale,scale,546,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,reliability,availab,available,100,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,safety,avail,available,100,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:310,safety,test,tested,310,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,security,availab,available,100,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:310,testability,test,tested,310,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:433,usability,user,user-images,433,"For those interested in using the GPU accelerated functions leiden, draw_graph_fa, I have made them available on the following gist:. https://gist.github.com/LouisFaure/9302aa140d7989a25ed2a44b1ce741e8. I have also included in that code `load_mtx`, which reads and convert mtx files into anndata using cudf. I tested on a 654Mo mtx containing 56621 cells x 20222 genes, I can obtain a 13X speedup (using RTX8000)! . ![image](https://user-images.githubusercontent.com/27488782/164707560-30c0c9fe-6bfe-4fcb-ac2c-0d8a503081b6.png). I expect this to scale even better with higher number of cells. I could also add this wrapper into scanpy once CI is ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:76,energy efficiency,GPU,GPUs,76,To me having the meta data (obs and var) in VRAM only makes sense for large GPUs like your RTX8000 or A100. I wrote a small anndata like object (https://github.com/Intron7/rapids_singlecell) for Prepossessing and the benefit of having everything in VRAM is rather small. Its better to just move the indexes around.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:76,performance,GPU,GPUs,76,To me having the meta data (obs and var) in VRAM only makes sense for large GPUs like your RTX8000 or A100. I wrote a small anndata like object (https://github.com/Intron7/rapids_singlecell) for Prepossessing and the benefit of having everything in VRAM is rather small. Its better to just move the indexes around.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:675,deployability,scale,scale,675,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:286,energy efficiency,load,loading,286,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:321,energy efficiency,GPU,GPU,321,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:575,energy efficiency,GPU,GPU,575,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:675,energy efficiency,scale,scale,675,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:675,modifiability,scal,scale,675,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:161,performance,memor,memory,161,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:286,performance,load,loading,286,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:321,performance,GPU,GPU,321,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:575,performance,GPU,GPU,575,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:675,performance,scale,scale,675,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:161,usability,memor,memory,161,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:433,usability,command,command,433,"@Intron7 I think the aim here is indeed to not keep anything in VRAM anyway. In the code/functions I propose here, the data is only transiently stored in device memory for calculation and the resulting output is always transfered back to host once finished. Moreover, I also think that loading a huge mtx file with a 4Go GPU is not impossible. From what I understood rmm should allow oversubscription on host RAM using the following command:. ```python. rmm.reinitialize(managed_memory=True). cp.cuda.set_allocator(rmm.rmm_cupy_allocator). ```. I had a look at your code and GPU accelerated preprocessing functions would be also welcome in scanpy in my opinion! I feel that `scale` and `regress_out` could benefit from such speedup for example.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:166,availability,error,error,166,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:160,energy efficiency,alloc,alloc,160,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:38,modifiability,exten,extend,38,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:153,performance,memor,memory,153,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:166,performance,error,error,166,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:166,safety,error,error,166,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:58,testability,understand,understand,58,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:153,usability,memor,memory,153,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:166,usability,error,error,166,Using RMM works but only to a certain extend. As far as I understand it you can oversubscribe VRAM to a maximum of 2X. If you go above that you’ll get a memory alloc error.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:14,deployability,updat,updates,14,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,deployability,version,version,100,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:469,deployability,pipelin,pipeline,469,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:483,energy efficiency,load,loading,483,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:636,energy efficiency,GPU,GPU,636,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:689,energy efficiency,CPU,CPU,689,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:723,energy efficiency,CPU,CPU,723,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:727,energy efficiency,core,cores,727,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,integrability,version,version,100,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:469,integrability,pipelin,pipeline,469,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:100,modifiability,version,version,100,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:370,performance,memor,memory,370,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:392,performance,perform,performed,392,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:483,performance,load,loading,483,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:636,performance,GPU,GPU,636,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:689,performance,CPU,CPU,689,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:723,performance,CPU,CPU,723,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:14,safety,updat,updates,14,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:710,safety,test,tested,710,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:14,security,updat,updates,14,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:77,security,expos,exposed,77,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:462,testability,simpl,simple,462,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:710,testability,test,tested,710,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:370,usability,memor,memory,370,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:392,usability,perform,performed,392,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:462,usability,simpl,simple,462,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:536,usability,user,user-images,536,"Here are some updates:. - `_fuzzy_simplicial_set` from umap has been freshly exposed in the nightly version of cuml 22.06 (stable should be there in the coming weeks), so I did a quick implementation and now have a fully accelerated sc.pp.neighbors! - I also used this opportunity to introduce `read_mtx_gpu` function, which includes a dask_cudf backend for out of vram memory mtx reading. I performed a speed comparison on a 100.000 cells dataset, running full simple pipeline from loading the mtx until UMAP/leiden:. ![image](https://user-images.githubusercontent.com/27488782/170506738-39eb95ac-9340-4790-ad0d-36ac07575b5f.png). The GPU accelerated code shows a 13X speedup compared to CPU based functions (tested on 12 CPU cores system)!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:92,deployability,log,logreg,92,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:362,deployability,log,logreg,362,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:37,energy efficiency,GPU,GPU,37,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:285,energy efficiency,GPU,GPU,285,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:430,energy efficiency,current,currently,430,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:171,modifiability,layer,layers,171,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:37,performance,GPU,GPU,37,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:285,performance,GPU,GPU,285,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:92,safety,log,logreg,92,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:362,safety,log,logreg,362,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:92,security,log,logreg,92,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:362,security,log,logreg,362,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:92,testability,log,logreg,92,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:362,testability,log,logreg,362,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:41,usability,support,support,41,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:179,usability,support,support,179,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:206,usability,help,helps,206,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:241,usability,workflow,workflow,241,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:474,usability,user,user-images,474,"I created a PR to this branch to add GPU support for :. *`tl.rank_gene_groups` with method='logreg'. *`tl.embedding_density`. *`correlation_matrix`. *`diffmap`. I added `.layers` support for `pp.pca`. This helps with the ""Pearson Residuals"" workflow. The default pca solver for device GPU is now ""auto"". I also fixed a bug in `tl.rank_gene_groups` with `method='logreg'` with selecting groups (eg. groups = [""2"",""1"",""5""]) that is currently still in scanpy. ![image](https://user-images.githubusercontent.com/37635888/179788802-6783f87d-19eb-497c-922e-59c18d6015d5.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:353,deployability,updat,updated,353,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:113,energy efficiency,GPU,GPU,113,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:335,energy efficiency,current,currently,335,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:89,performance,time,time,89,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:113,performance,GPU,GPU,113,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:192,safety,test,tested,192,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:353,safety,updat,updated,353,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:29,security,Hack,Hackathlon,29,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:353,security,updat,updated,353,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:192,testability,test,tested,192,"Hey @LouisFaure,. During the Hackathlon last week we talked again about this PR. For the time being we will keep GPU computing functionality out of scanpy and in rapids-singlecell. RSC is now tested with a CI solution. If you want to contribute to rapids-singlecell I would be very happy. Missing functions like Umap and Neighbors are currently getting updated and also ported to RSC. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:34,modifiability,pac,package,34,"Great I am looking at it now, RSC package looks very nice!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/issues/1534:24,interoperability,coordinat,coordinate,24,"EDIT: the issue is that coordinate system in this case has origin bottom left, whereas coordinate system in visium is top left.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:87,interoperability,coordinat,coordinate,87,"EDIT: the issue is that coordinate system in this case has origin bottom left, whereas coordinate system in visium is top left.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1537:283,availability,operat,operate,283,"@djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). @fidelram, how should we handle this? The documentation suggests that these functions will return `Axes`, though many of them don't operate on single `Axes` and instead have `GridSpecs`/ `Figures`. Could we do a pass over all plotting functions and normalize the behaviour for these arguments?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:62,energy efficiency,current,current,62,"@djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). @fidelram, how should we handle this? The documentation suggests that these functions will return `Axes`, though many of them don't operate on single `Axes` and instead have `GridSpecs`/ `Figures`. Could we do a pass over all plotting functions and normalize the behaviour for these arguments?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:99,energy efficiency,current,current,99,"@djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). @fidelram, how should we handle this? The documentation suggests that these functions will return `Axes`, though many of them don't operate on single `Axes` and instead have `GridSpecs`/ `Figures`. Could we do a pass over all plotting functions and normalize the behaviour for these arguments?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:134,energy efficiency,current,current,134,"@djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). @fidelram, how should we handle this? The documentation suggests that these functions will return `Axes`, though many of them don't operate on single `Axes` and instead have `GridSpecs`/ `Figures`. Could we do a pass over all plotting functions and normalize the behaviour for these arguments?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:193,usability,document,documentation,193,"@djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). @fidelram, how should we handle this? The documentation suggests that these functions will return `Axes`, though many of them don't operate on single `Axes` and instead have `GridSpecs`/ `Figures`. Could we do a pass over all plotting functions and normalize the behaviour for these arguments?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:414,usability,behavi,behaviour,414,"@djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). @fidelram, how should we handle this? The documentation suggests that these functions will return `Axes`, though many of them don't operate on single `Axes` and instead have `GridSpecs`/ `Figures`. Could we do a pass over all plotting functions and normalize the behaviour for these arguments?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:64,energy efficiency,current,current,64,"> @djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). Thanks, thats works",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:101,energy efficiency,current,current,101,"> @djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). Thanks, thats works",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/issues/1537:136,energy efficiency,current,current,136,"> @djbios you should be able to work around this by getting the current figures via `plt.gca()` (get current axis) and `plt.gcf()` (get current figure). Thanks, thats works",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1537
https://github.com/scverse/scanpy/pull/1538:216,availability,cluster,clusters,216,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:251,availability,cluster,clusters,251,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:667,availability,consist,consistent,667,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:216,deployability,cluster,clusters,216,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:251,deployability,cluster,clusters,251,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:522,deployability,version,versions,522,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:522,integrability,version,versions,522,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:706,integrability,compon,component,706,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:866,integrability,compon,components,866,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1107,integrability,compon,components,1107,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1197,integrability,compon,components,1197,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1318,integrability,compon,components,1318,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:706,interoperability,compon,component,706,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:866,interoperability,compon,components,866,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1107,interoperability,compon,components,1107,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1197,interoperability,compon,components,1197,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1318,interoperability,compon,components,1318,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:140,modifiability,paramet,parameter,140,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:165,modifiability,paramet,parameter,165,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:307,modifiability,concern,concerns,307,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:522,modifiability,version,versions,522,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:706,modifiability,compon,component,706,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:866,modifiability,compon,components,866,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1107,modifiability,compon,components,1107,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1197,modifiability,compon,components,1197,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1266,modifiability,paramet,parameter,1266,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1318,modifiability,compon,components,1318,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:471,safety,avoid,avoid,471,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:115,testability,simpl,simple,115,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:307,testability,concern,concerns,307,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1218,testability,context,context,1218,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:115,usability,simpl,simple,115,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:667,usability,consist,consistent,667,"It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of `sc.pl.umap(adata, color='clusters')` -> `sc.pl.umap(adata, 'clusters')`. About the changes that you suggest: I have concerns with breaking previous functionality and I wonder what is your position with respect to this. The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage from the very firsts versions of scanpy but maybe you have some good ideas for transitioning this from a string to a tuple. . The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. . For the plots being the product of `color` and `components`: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. . For your question about replacing `components` by `dimensions`. We need to be careful here because in many places the use of components is in the context of PCA as in `sc.pp.neighbors` with the parameter `n_pcs`. I think that the replacement of `components` by `dimensions` should only be done for the embedding functions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:217,availability,cluster,clusters,217,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:250,availability,cluster,clusters,250,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:497,availability,consist,consistent,497,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:687,availability,consist,consistent,687,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:217,deployability,cluster,clusters,217,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:250,deployability,cluster,clusters,250,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1378,energy efficiency,Cool,Cool,1378,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:382,integrability,compon,components,382,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:536,integrability,compon,component,536,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1175,integrability,compon,components,1175,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:382,interoperability,compon,components,382,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:536,interoperability,compon,component,536,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1175,interoperability,compon,components,1175,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:142,modifiability,paramet,parameter,142,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:167,modifiability,paramet,parameter,167,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:382,modifiability,compon,components,382,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:536,modifiability,compon,component,536,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1175,modifiability,compon,components,1175,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:329,safety,avoid,avoid,329,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1109,safety,reme,remember,1109,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:117,testability,simpl,simple,117,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:117,usability,simpl,simple,117,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:497,usability,consist,consistent,497,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:687,usability,consist,consistent,687,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:733,usability,clear,clear,733,"> It is great that you are looking into this. Can you check if it is possible to remove the need to type 'color' and simple accept the second parameter as the 'color' parameter (eg instead of sc.pl.umap(adata, color='clusters') -> sc.pl.umap(adata, 'clusters'). 👍 . > The reason why the dimensions is a string like ""1,2"", was to avoid breaking previous usage. The idea is to parse `components`, but allow you to directly pass the indices with dimensions. > The starting number is not 0 because is consistent with usage as in 'principal component 1' or 'UMAP-1'. I don't think this should be changed even though it requires a bit of extra coding. To me, I think it makes more sense to be consistent with python. I feel like it's very clear what is happening if the default argument is `sc.pl.pca(adata, dimensions=(0, 1))`. It makes it easier to work with programmatically if the values are equivalent to what you could use to index the array directly. For example, say you find the dimension which is maximally correlated with some gene. You can just pass the result of that into dimensions without having to remember to add 1. > For the plots being the product of color and components: this was to solve the unlikely case in which you want to plot n colors using m dimensions. I don't have an opinion on this as I think is a corner case and have never used this functionality. Cool. I feel like this can be useful, but it would be useful if I could choose which arguments it worked with. I think this is a different function call though. For example, I might was to look at a gene under multiple embeddings, so pairwise combinations of `basis` and `colors`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:21,integrability,compon,components,21,Regarding the use of components using zero based index I would like to know what @falexwolf opinion is.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:21,interoperability,compon,components,21,Regarding the use of components using zero based index I would like to know what @falexwolf opinion is.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:21,modifiability,compon,components,21,Regarding the use of components using zero based index I would like to know what @falexwolf opinion is.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:288,availability,consist,consistently,288,"I'm fine with changing the convention to zero-pre-fix-based. The original design was also due to diffusion maps having a ""zero-component"" that is not meant for visualization. But diffusion maps is a highly artificial case given the more modern embedding these days, and so I'd suggest to consistently implement the 0-based pythonic convention. In diffusion maps, we can default to `(1, 2)` whereas in all other methods we can default to `(0, 1)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:127,integrability,compon,component,127,"I'm fine with changing the convention to zero-pre-fix-based. The original design was also due to diffusion maps having a ""zero-component"" that is not meant for visualization. But diffusion maps is a highly artificial case given the more modern embedding these days, and so I'd suggest to consistently implement the 0-based pythonic convention. In diffusion maps, we can default to `(1, 2)` whereas in all other methods we can default to `(0, 1)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:127,interoperability,compon,component,127,"I'm fine with changing the convention to zero-pre-fix-based. The original design was also due to diffusion maps having a ""zero-component"" that is not meant for visualization. But diffusion maps is a highly artificial case given the more modern embedding these days, and so I'd suggest to consistently implement the 0-based pythonic convention. In diffusion maps, we can default to `(1, 2)` whereas in all other methods we can default to `(0, 1)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:127,modifiability,compon,component,127,"I'm fine with changing the convention to zero-pre-fix-based. The original design was also due to diffusion maps having a ""zero-component"" that is not meant for visualization. But diffusion maps is a highly artificial case given the more modern embedding these days, and so I'd suggest to consistently implement the 0-based pythonic convention. In diffusion maps, we can default to `(1, 2)` whereas in all other methods we can default to `(0, 1)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:160,usability,visual,visualization,160,"I'm fine with changing the convention to zero-pre-fix-based. The original design was also due to diffusion maps having a ""zero-component"" that is not meant for visualization. But diffusion maps is a highly artificial case given the more modern embedding these days, and so I'd suggest to consistently implement the 0-based pythonic convention. In diffusion maps, we can default to `(1, 2)` whereas in all other methods we can default to `(0, 1)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:288,usability,consist,consistently,288,"I'm fine with changing the convention to zero-pre-fix-based. The original design was also due to diffusion maps having a ""zero-component"" that is not meant for visualization. But diffusion maps is a highly artificial case given the more modern embedding these days, and so I'd suggest to consistently implement the 0-based pythonic convention. In diffusion maps, we can default to `(1, 2)` whereas in all other methods we can default to `(0, 1)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:26,integrability,compon,components,26,"I've put off deprecating `components`, since that's a bunch more work and would need changes throughout the codebase. Will create an issue for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:26,interoperability,compon,components,26,"I've put off deprecating `components`, since that's a bunch more work and would need changes throughout the codebase. Will create an issue for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:26,modifiability,compon,components,26,"I've put off deprecating `components`, since that's a bunch more work and would need changes throughout the codebase. Will create an issue for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/issues/1539:55,integrability,transform,transform,55,"Hi, yes there is such functionalities in episcanpy. To transform a peak matrix into a gene activity matrix you can use epi.tl.geneactivity",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:55,interoperability,transform,transform,55,"Hi, yes there is such functionalities in episcanpy. To transform a peak matrix into a gene activity matrix you can use epi.tl.geneactivity",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/pull/1540:54,deployability,releas,release,54,Could this get a notice in the docs/ something in the release notes?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:15,deployability,updat,update,15,Thanks for the update! Merged via #1595,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:15,safety,updat,update,15,Thanks for the update! Merged via #1595,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:15,security,updat,update,15,Thanks for the update! Merged via #1595,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1544:298,deployability,Updat,Updated,298,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:236,modifiability,extens,extensions,236,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:298,safety,Updat,Updated,298,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:298,security,Updat,Updated,298,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:615,testability,understand,understand,615,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:119,usability,guid,guidelines,119,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:150,usability,minim,minimal,150,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:175,usability,Document,Documentation,175,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:502,usability,guid,guide,502,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:555,usability,person,person,555,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:579,usability,document,documentation,579,"I think this is getting to a good place for an initial addition. Parts that definitely need expanding include:. * Code guidelines. * These are pretty minimal at the moment. * Documentation. * Information on restructured text . * sphinx extensions we use. * More on the structure of a doc-string. * Updated examples (I took these from the existing `CONTRIBUTING.md`). I think these can be expanded at a later date. The main goal here was to make sure there was some base organization for a contributing guide and dev-docs. . I'm probably also not the best person to expand on the documentation, since I still barely understand sphinx :wink:.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/issues/1545:94,deployability,log,logarithmic,94,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:152,deployability,log,logspace,152,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:128,integrability,transform,transformed,128,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:128,interoperability,transform,transformed,128,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:202,reliability,Doe,Doesn,202,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:94,safety,log,logarithmic,94,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:152,safety,log,logspace,152,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:94,security,log,logarithmic,94,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:152,security,log,logspace,152,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:94,testability,log,logarithmic,94,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:152,testability,log,logspace,152,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:22,usability,document,documentation,22,I'm confused too. The documentation says that flavor ='seurat' or flavor ='cell_ranger' needs logarithmic data. Why the data is transformed back out of logspace using X=np.expm1(X) if flavor='seurat' ? Doesn't this do nothing if expm1(log1p(X))?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:248,deployability,log,log,248,"Hi, same confusion here. According to: https://github.com/scverse/scanpy/issues/969#issuecomment-629667682. If I set `flavor ='cell_ranger'`, dose it mean I should not use `sc.pp.log1p(adata)` to ensure use the ""library size normalized counts""(not log)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:248,safety,log,log,248,"Hi, same confusion here. According to: https://github.com/scverse/scanpy/issues/969#issuecomment-629667682. If I set `flavor ='cell_ranger'`, dose it mean I should not use `sc.pp.log1p(adata)` to ensure use the ""library size normalized counts""(not log)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:248,security,log,log,248,"Hi, same confusion here. According to: https://github.com/scverse/scanpy/issues/969#issuecomment-629667682. If I set `flavor ='cell_ranger'`, dose it mean I should not use `sc.pp.log1p(adata)` to ensure use the ""library size normalized counts""(not log)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:248,testability,log,log,248,"Hi, same confusion here. According to: https://github.com/scverse/scanpy/issues/969#issuecomment-629667682. If I set `flavor ='cell_ranger'`, dose it mean I should not use `sc.pp.log1p(adata)` to ensure use the ""library size normalized counts""(not log)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1549:191,deployability,log,logg,191,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：. ```. if dendrogram_key not in adata.uns:. from ..tools._dendrogram import dendrogram. logg.warning(. f""dendrogram data not found (using key={dendrogram_key}). "". ""Running `sc.tl.dendrogram` with default parameters. For fine "". ""tuning it is recommended to run `sc.tl.dendrogram` independently."". ). dendrogram(adata, groupby, key_added=dendrogram_key). ```. `dendrogram` is not add `var_names`, and i fixed it in my source code. ------. anndata 0.7.8. scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:308,modifiability,paramet,parameters,308,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：. ```. if dendrogram_key not in adata.uns:. from ..tools._dendrogram import dendrogram. logg.warning(. f""dendrogram data not found (using key={dendrogram_key}). "". ""Running `sc.tl.dendrogram` with default parameters. For fine "". ""tuning it is recommended to run `sc.tl.dendrogram` independently."". ). dendrogram(adata, groupby, key_added=dendrogram_key). ```. `dendrogram` is not add `var_names`, and i fixed it in my source code. ------. anndata 0.7.8. scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:191,safety,log,logg,191,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：. ```. if dendrogram_key not in adata.uns:. from ..tools._dendrogram import dendrogram. logg.warning(. f""dendrogram data not found (using key={dendrogram_key}). "". ""Running `sc.tl.dendrogram` with default parameters. For fine "". ""tuning it is recommended to run `sc.tl.dendrogram` independently."". ). dendrogram(adata, groupby, key_added=dendrogram_key). ```. `dendrogram` is not add `var_names`, and i fixed it in my source code. ------. anndata 0.7.8. scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:191,security,log,logg,191,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：. ```. if dendrogram_key not in adata.uns:. from ..tools._dendrogram import dendrogram. logg.warning(. f""dendrogram data not found (using key={dendrogram_key}). "". ""Running `sc.tl.dendrogram` with default parameters. For fine "". ""tuning it is recommended to run `sc.tl.dendrogram` independently."". ). dendrogram(adata, groupby, key_added=dendrogram_key). ```. `dendrogram` is not add `var_names`, and i fixed it in my source code. ------. anndata 0.7.8. scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:191,testability,log,logg,191,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：. ```. if dendrogram_key not in adata.uns:. from ..tools._dendrogram import dendrogram. logg.warning(. f""dendrogram data not found (using key={dendrogram_key}). "". ""Running `sc.tl.dendrogram` with default parameters. For fine "". ""tuning it is recommended to run `sc.tl.dendrogram` independently."". ). dendrogram(adata, groupby, key_added=dendrogram_key). ```. `dendrogram` is not add `var_names`, and i fixed it in my source code. ------. anndata 0.7.8. scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:154,usability,tool,tools,154,"I found the same problem in `sc.pl.dotplot`, but i found in `\scanpy\plotting\_anndata.py` 2236th line：. ```. if dendrogram_key not in adata.uns:. from ..tools._dendrogram import dendrogram. logg.warning(. f""dendrogram data not found (using key={dendrogram_key}). "". ""Running `sc.tl.dendrogram` with default parameters. For fine "". ""tuning it is recommended to run `sc.tl.dendrogram` independently."". ). dendrogram(adata, groupby, key_added=dendrogram_key). ```. `dendrogram` is not add `var_names`, and i fixed it in my source code. ------. anndata 0.7.8. scanpy 1.9.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:58,modifiability,paramet,parameter,58,I found that scanpy always only uses all var_names if the parameter `var_names` is set to not None. . ![image](https://github.com/scverse/scanpy/assets/68582496/656fdd14-69f7-4fb1-92a0-59b4fb08b96e).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4,deployability,updat,update,4,Any update on this? I encountered the same issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4,safety,updat,update,4,Any update on this? I encountered the same issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4,security,updat,update,4,Any update on this? I encountered the same issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1550:128,availability,cluster,cluster,128,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:161,availability,cluster,clusters,161,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:128,deployability,cluster,cluster,128,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:161,deployability,cluster,clusters,161,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:258,deployability,continu,continuous,258,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:269,modifiability,variab,variables,269,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:216,safety,except,excepting,216,"Scanpy has enhanced sc.pl.umap function last year. For example, now sc.pl.umap(adata,color=[""louvain""],groups=""1"") can highligt cluster 1 while displaying other clusters in gray color. I think they are very similar, excepting that gene expressing values are continuous variables.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:1099,interoperability,specif,specific,1099,"What you mean by not showing the cells? Do you have an example of this? For sure some color maps (like `""Reds""`) can seem to make cells seem invisible since white is their lowest value, but I'm not aware of any cell hiding. As for displaying zero count cells as some color, you can do that by passing a `cmap`, e.g. a cubehelix one:. ```python. import seaborn as sns. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.umap(. pbmc,. color=""LGALS2"",. cmap=sns.cubehelix_palette(dark=0, light=.9, as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610132-c6b06380-4180-11eb-8da1-6edb2a9feed0.png). Or you could generate your own colormap where you can choose the color for a low value:. ```python. sc.pl.umap(. pbmc,. color=""LGALS2"",. # Felt appropriate for the data. cmap=sns.blend_palette([""lightgray"", sns.xkcd_rgb[""blood""]], as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610181-dcbe2400-4180-11eb-806b-713a844fdf07.png). You can also get a bit more involved and set low values to be shown as a specific color (thought this is both a bit inelegant, and has a dramatic cutoff):. ```python. import matplotlib as mpl. from copy import copy. reds = copy(mpl.cm.Reds). reds.set_under(""lightgray""). sc.pl.umap(pbmc, color=""LGALS2"", cmap=reds, vmin=0.00001). ```. ![image](https://user-images.githubusercontent.com/8238804/102610145-cca64480-4180-11eb-9517-aadb4b80cc94.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:565,usability,user,user-images,565,"What you mean by not showing the cells? Do you have an example of this? For sure some color maps (like `""Reds""`) can seem to make cells seem invisible since white is their lowest value, but I'm not aware of any cell hiding. As for displaying zero count cells as some color, you can do that by passing a `cmap`, e.g. a cubehelix one:. ```python. import seaborn as sns. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.umap(. pbmc,. color=""LGALS2"",. cmap=sns.cubehelix_palette(dark=0, light=.9, as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610132-c6b06380-4180-11eb-8da1-6edb2a9feed0.png). Or you could generate your own colormap where you can choose the color for a low value:. ```python. sc.pl.umap(. pbmc,. color=""LGALS2"",. # Felt appropriate for the data. cmap=sns.blend_palette([""lightgray"", sns.xkcd_rgb[""blood""]], as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610181-dcbe2400-4180-11eb-806b-713a844fdf07.png). You can also get a bit more involved and set low values to be shown as a specific color (thought this is both a bit inelegant, and has a dramatic cutoff):. ```python. import matplotlib as mpl. from copy import copy. reds = copy(mpl.cm.Reds). reds.set_under(""lightgray""). sc.pl.umap(pbmc, color=""LGALS2"", cmap=reds, vmin=0.00001). ```. ![image](https://user-images.githubusercontent.com/8238804/102610145-cca64480-4180-11eb-9517-aadb4b80cc94.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:931,usability,user,user-images,931,"What you mean by not showing the cells? Do you have an example of this? For sure some color maps (like `""Reds""`) can seem to make cells seem invisible since white is their lowest value, but I'm not aware of any cell hiding. As for displaying zero count cells as some color, you can do that by passing a `cmap`, e.g. a cubehelix one:. ```python. import seaborn as sns. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.umap(. pbmc,. color=""LGALS2"",. cmap=sns.cubehelix_palette(dark=0, light=.9, as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610132-c6b06380-4180-11eb-8da1-6edb2a9feed0.png). Or you could generate your own colormap where you can choose the color for a low value:. ```python. sc.pl.umap(. pbmc,. color=""LGALS2"",. # Felt appropriate for the data. cmap=sns.blend_palette([""lightgray"", sns.xkcd_rgb[""blood""]], as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610181-dcbe2400-4180-11eb-806b-713a844fdf07.png). You can also get a bit more involved and set low values to be shown as a specific color (thought this is both a bit inelegant, and has a dramatic cutoff):. ```python. import matplotlib as mpl. from copy import copy. reds = copy(mpl.cm.Reds). reds.set_under(""lightgray""). sc.pl.umap(pbmc, color=""LGALS2"", cmap=reds, vmin=0.00001). ```. ![image](https://user-images.githubusercontent.com/8238804/102610145-cca64480-4180-11eb-9517-aadb4b80cc94.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:1378,usability,user,user-images,1378,"What you mean by not showing the cells? Do you have an example of this? For sure some color maps (like `""Reds""`) can seem to make cells seem invisible since white is their lowest value, but I'm not aware of any cell hiding. As for displaying zero count cells as some color, you can do that by passing a `cmap`, e.g. a cubehelix one:. ```python. import seaborn as sns. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.umap(. pbmc,. color=""LGALS2"",. cmap=sns.cubehelix_palette(dark=0, light=.9, as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610132-c6b06380-4180-11eb-8da1-6edb2a9feed0.png). Or you could generate your own colormap where you can choose the color for a low value:. ```python. sc.pl.umap(. pbmc,. color=""LGALS2"",. # Felt appropriate for the data. cmap=sns.blend_palette([""lightgray"", sns.xkcd_rgb[""blood""]], as_cmap=True). ). ```. ![image](https://user-images.githubusercontent.com/8238804/102610181-dcbe2400-4180-11eb-806b-713a844fdf07.png). You can also get a bit more involved and set low values to be shown as a specific color (thought this is both a bit inelegant, and has a dramatic cutoff):. ```python. import matplotlib as mpl. from copy import copy. reds = copy(mpl.cm.Reds). reds.set_under(""lightgray""). sc.pl.umap(pbmc, color=""LGALS2"", cmap=reds, vmin=0.00001). ```. ![image](https://user-images.githubusercontent.com/8238804/102610145-cca64480-4180-11eb-9517-aadb4b80cc94.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:24,usability,guidanc,guidance,24,Thanks for you detailed guidance. All I want is to display zero count cells as some color (gray) and this is what cellranger and seurat do. I can do it now following the above code. This is just what I want !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:8,usability,help,help,8,Glad to help!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/pull/1551:293,availability,error,error,293,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`. * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example. * If `norm` is passed along at the same time, an error should be thrown. * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:284,performance,time,time,284,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`. * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example. * If `norm` is passed along at the same time, an error should be thrown. * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:293,performance,error,error,293,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`. * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example. * If `norm` is passed along at the same time, an error should be thrown. * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:293,safety,error,error,293,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`. * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example. * If `norm` is passed along at the same time, an error should be thrown. * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:167,usability,user,users,167,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`. * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example. * If `norm` is passed along at the same time, an error should be thrown. * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:293,usability,error,error,293,"I like this idea. * While we should be conservative about adding new keywords, this fits well with `vmin` and `vmax`. * The docs for this argument should mention that users should pass a diverging palette with it, and probably have an example. * If `norm` is passed along at the same time, an error should be thrown. * It looks like there is a bunch of repeated code handling generating the `norm`, could this get put into a common utility function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:47,availability,error,error,47,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:284,availability,error,error,284,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:723,availability,error,error,723,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:453,deployability,Log,LogNorm,453,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:739,deployability,releas,releases,739,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:228,energy efficiency,current,currently,228,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:633,modifiability,paramet,parameters,633,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:38,performance,time,time,38,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:47,performance,error,error,47,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:284,performance,error,error,284,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:723,performance,error,error,723,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:47,safety,error,error,47,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:284,safety,error,error,284,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:453,safety,Log,LogNorm,453,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:723,safety,error,error,723,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:453,security,Log,LogNorm,453,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:453,testability,Log,LogNorm,453,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:665,testability,simul,simultaneously,665,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:47,usability,error,error,47,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:284,usability,error,error,284,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:723,usability,error,error,723,"> If norm is passed along at the same time, an error should be thrown. Following up on this a bit, I realized I didn't actually know what matplotlib would do if you passed `norm` and a bound, so I checked it out. Turns out they currently allow it, but it's deprecated, so throwing an error is the right thing to do. ```python. import vega_datasets. import matplotlib as mpl, matplotlib.pyplot as plt. iris = vega_datasets.data.iris(). norm = mpl.colors.LogNorm(). plt.scatter(. iris[""sepalLength""],. iris[""sepalWidth""],. c=iris[""petalLength""],. norm=norm,. vmin=3,. ). plt.colorbar(). ```. ```. MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . simultaneously is deprecated since 3.3 and will become an error two minor releases . later. Please pass vmin/vmax directly to the norm when creating it. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:139,availability,error,error,139,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:155,deployability,releas,releases,155,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:318,deployability,upgrad,upgrading,318,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:47,modifiability,paramet,parameters,47,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:318,modifiability,upgrad,upgrading,318,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:139,performance,error,error,139,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:139,safety,error,error,139,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:81,testability,simul,simultaneously,81,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:139,usability,error,error,139,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:292,usability,support,support,292,"> ```. > MatplotlibDeprecationWarning: Passing parameters norm and vmin/vmax . > simultaneously is deprecated since 3.3 and will become an error two minor releases . > later. Please pass vmin/vmax directly to the norm when creating it. > ```. Yeah, that actually re-ignited my idea of adding support for vcenter after upgrading mpl :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:127,deployability,fail,fail,127,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:692,deployability,fail,fail,692,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:957,deployability,fail,fail,957,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:992,deployability,updat,updated,992,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1461,performance,time,times,1461,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:127,reliability,fail,fail,127,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:150,reliability,doe,does,150,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:692,reliability,fail,fail,692,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:957,reliability,fail,fail,957,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:38,safety,test,tests,38,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:104,safety,test,test,104,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:221,safety,test,tests,221,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:357,safety,test,tests,357,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:674,safety,test,tests,674,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:992,safety,updat,updated,992,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1066,safety,test,tests,1066,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1189,safety,test,tests,1189,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1267,safety,test,test,1267,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1316,safety,test,tests,1316,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1354,safety,test,tests,1354,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1523,safety,compl,complaint,1523,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:992,security,updat,updated,992,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1523,security,compl,complaint,1523,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1594,security,team,team,1594,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:38,testability,test,tests,38,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:104,testability,test,test,104,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:221,testability,test,tests,221,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:357,testability,test,tests,357,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:674,testability,test,tests,674,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1066,testability,test,tests,1066,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1189,testability,test,tests,1189,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1267,testability,test,test,1267,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1316,testability,test,tests,1316,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1354,testability,test,tests,1354,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:15,usability,help,help,15,"@fidelram Some help with the plotting tests is very much appreciated :) I don't get why only Python 3.6 test passes and others fail. For example; why does [this plot](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) which is produced by [this code](https://github.com/theislab/scanpy/blob/master/scanpy/tests/test_plotting.py#L357) where the color legend is defined [here](https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_matrixplot.py#L74) as `Mean expression in group` have the old title which is `Expression level in group`? If the ""ground truth plots"" in the ""_images"" folder are outdated, aren't the tests supposed to fail since the [this commit](https://github.com/theislab/scanpy/commit/d4d373ea58b9add4451091c5650d4da245d025dc#diff-421b3afbcd51c81c45f23dd7e8483697b68668de9172f124ec6bf2f0523840d9L95) i.e. `Expression level in group` -> `Mean expression in group`, but they don't fail, why? Another example: I have updated [this file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot_with_totals.png) but not [that file](https://github.com/theislab/scanpy/blob/master/scanpy/tests/_images/master_matrixplot.png) which seem both outdated. But Python 3.6 test still seems to pass. How come? Are plotting tests disabled in Python3.6? Plotting tests are extremely tricky and make it pretty difficult to contribute I must say :/ I think twice or three times when I want to change anything about plotting... (not a complaint addressed to @fidelram but something we should consider as a team)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:619,availability,mask,masking,619,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:125,deployability,fail,failed,125,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:471,deployability,fail,failing,471,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:550,deployability,version,versions,550,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:568,deployability,instal,installed,568,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:786,deployability,updat,updated,786,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:550,integrability,version,versions,550,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:550,modifiability,version,versions,550,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:887,modifiability,paramet,parameter,887,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:125,reliability,fail,failed,125,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:471,reliability,fail,failing,471,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:29,safety,test,tests,29,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:120,safety,test,test,120,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:246,safety,test,tests,246,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:334,safety,test,test,334,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:454,safety,avoid,avoid,454,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:460,safety,test,tests,460,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:786,safety,updat,updated,786,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1009,safety,test,tests,1009,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1089,safety,review,review,1089,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:786,security,updat,updated,786,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:29,testability,test,tests,29,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:120,testability,test,test,120,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:246,testability,test,tests,246,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:334,testability,test,test,334,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:460,testability,test,tests,460,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1009,testability,test,tests,1009,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:1089,testability,review,review,1089,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:766,usability,clear,clearly,766,"@gokceneraslan Regarding the tests: yes, they are annoying particularly because is not possible to actually check why a test failed on the server while passes locally. I agree that this limits contribution because the mountain of work to get the tests working puts one off. For the particular question about the title difference: the test may be passing because of the 'threshold' used to call the images as different. Why we use a threshold? This is to avoid tests from failing due to small differences between matplotlib or other graphic libraries versions or fonts installed. However, sometimes the threshold may be masking some small problems, although in general I am quite happy because important differences not missed. . BTW: The image that you point out is clearly wrong but I updated it recently for other reason (PR #1584). Regarding the issue about adding `norm` as explicit parameter. I would suggest to add it if this just mean changing very few lines but I know this is lot of work (do we want tests for this?) for something that is already working. . Besides the very good review by Isaac I don't have much to add and will be happy to merge once some of the changes are taken care. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/issues/1552:29,deployability,updat,update,29,Also looking forward to this update,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:29,safety,updat,update,29,Also looking forward to this update,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:29,security,updat,update,29,Also looking forward to this update,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:24,deployability,updat,update,24,Looking forward to this update or is there any other way to achieve this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:24,safety,updat,update,24,Looking forward to this update or is there any other way to achieve this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:24,security,updat,update,24,Looking forward to this update or is there any other way to achieve this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:84,modifiability,paramet,parameter,84,"It seems that the question has not be addressed yet, and still can't find the ncols parameter alike.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:381,integrability,sub,subplots,381,"Pull requests welcome! You can achieve this e.g. like this:. ```py. import itertools. import math. import matplotlib.figure. import scanpy as sc. # parameters. ad = sc.datasets.pbmc68k_reduced(). vars = [""n_genes"", ""percent_mito"", ""n_counts"", ""S_score"", ""G2M_score""]. n_cols = 3. # plotting code. n_rows = math.ceil(len(vars) / n_cols). fig = matplotlib.figure.Figure(). axs = fig.subplots(n_rows, 1). for ax, v in zip(axs.flat, itertools.batched(vars, n_cols)):. sc.pl.violin(ad, v, ax=ax). fig. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:439,integrability,batch,batched,439,"Pull requests welcome! You can achieve this e.g. like this:. ```py. import itertools. import math. import matplotlib.figure. import scanpy as sc. # parameters. ad = sc.datasets.pbmc68k_reduced(). vars = [""n_genes"", ""percent_mito"", ""n_counts"", ""S_score"", ""G2M_score""]. n_cols = 3. # plotting code. n_rows = math.ceil(len(vars) / n_cols). fig = matplotlib.figure.Figure(). axs = fig.subplots(n_rows, 1). for ax, v in zip(axs.flat, itertools.batched(vars, n_cols)):. sc.pl.violin(ad, v, ax=ax). fig. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:148,modifiability,paramet,parameters,148,"Pull requests welcome! You can achieve this e.g. like this:. ```py. import itertools. import math. import matplotlib.figure. import scanpy as sc. # parameters. ad = sc.datasets.pbmc68k_reduced(). vars = [""n_genes"", ""percent_mito"", ""n_counts"", ""S_score"", ""G2M_score""]. n_cols = 3. # plotting code. n_rows = math.ceil(len(vars) / n_cols). fig = matplotlib.figure.Figure(). axs = fig.subplots(n_rows, 1). for ax, v in zip(axs.flat, itertools.batched(vars, n_cols)):. sc.pl.violin(ad, v, ax=ax). fig. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:439,performance,batch,batched,439,"Pull requests welcome! You can achieve this e.g. like this:. ```py. import itertools. import math. import matplotlib.figure. import scanpy as sc. # parameters. ad = sc.datasets.pbmc68k_reduced(). vars = [""n_genes"", ""percent_mito"", ""n_counts"", ""S_score"", ""G2M_score""]. n_cols = 3. # plotting code. n_rows = math.ceil(len(vars) / n_cols). fig = matplotlib.figure.Figure(). axs = fig.subplots(n_rows, 1). for ax, v in zip(axs.flat, itertools.batched(vars, n_cols)):. sc.pl.violin(ad, v, ax=ax). fig. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/pull/1554:11,safety,review,reviewing,11,Thanks for reviewing! Just pushed requested changes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1554
https://github.com/scverse/scanpy/pull/1554:11,testability,review,reviewing,11,Thanks for reviewing! Just pushed requested changes.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1554
https://github.com/scverse/scanpy/issues/1556:74,deployability,stack,stackoverflow,74,> what was the solution to this issue? here I wrote my solution:. https://stackoverflow.com/questions/65430814/dendrogram-valueerror-the-truth-value-of-a-series-is-ambiguous-use-a-empty-a,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1559:201,deployability,contain,contain,201,"Hi,. I guess this issue might be more appropriate in the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). I assume that the AnnData object you are working with does not contain sparse data. In that case you can leave out the `.A1` from your commands. Also, you're currently working with an `ArrayView` rather than an AnnData object, which you can change with a `adata = adata.copy()` line.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559
https://github.com/scverse/scanpy/issues/1559:296,energy efficiency,current,currently,296,"Hi,. I guess this issue might be more appropriate in the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). I assume that the AnnData object you are working with does not contain sparse data. In that case you can leave out the `.A1` from your commands. Also, you're currently working with an `ArrayView` rather than an AnnData object, which you can change with a `adata = adata.copy()` line.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559
https://github.com/scverse/scanpy/issues/1559:192,reliability,doe,does,192,"Hi,. I guess this issue might be more appropriate in the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). I assume that the AnnData object you are working with does not contain sparse data. In that case you can leave out the `.A1` from your commands. Also, you're currently working with an `ArrayView` rather than an AnnData object, which you can change with a `adata = adata.copy()` line.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559
https://github.com/scverse/scanpy/issues/1559:273,usability,command,commands,273,"Hi,. I guess this issue might be more appropriate in the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). I assume that the AnnData object you are working with does not contain sparse data. In that case you can leave out the `.A1` from your commands. Also, you're currently working with an `ArrayView` rather than an AnnData object, which you can change with a `adata = adata.copy()` line.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559
https://github.com/scverse/scanpy/issues/1559:28,usability,help,help,28,Thank you very much for the help and link to tutorial. It works for me,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559
https://github.com/scverse/scanpy/issues/1560:344,deployability,depend,depending,344,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:195,integrability,filter,filtered,195,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:288,integrability,filter,filter,288,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:344,integrability,depend,depending,344,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:344,modifiability,depend,depending,344,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:344,safety,depend,depending,344,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:344,testability,depend,depending,344,"Hi,. It looks like this code comes from the [single-cell-tutorial github](https://github.com/theislab/single-cell-tutorial). It might be best to report the issue there. It looks like you haven't filtered out genes that are not expressed in your dataset via `sc.pp.filter_genes()`. If you filter the dataset (maybe with `min_cells` set to 5-50, depending on the size of your dataset), then this shouldn't happen. Here, you have too many genes with the same mean, which is very low.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:11,usability,help,help,11,Thanks for help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/pull/1561:812,integrability,interfac,interface,812,"Hi Pavlin, Happy New Year! Great to see this going forward! > We'd probably have to do something similar to the gauss option and just overwrite the UMAP weights after the fact. Does this sound reasonable? Yes, I also thought we'd need to do it similar to the `gauss` option. Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? One question here though: how would `tsne` function know if it should use the uniform kernel or the weights constructed by the `neighbors` function? Can some flag be switched if `neighbors` is run with `mode='tsne'` so that the `tsne()` function later on uses those weights? Not sure what's the best interface here. Alternatively the `tsne()` function could check if the weights conform to what t-SNE expects (sum to 1). Maybe that's better actually. Apart from that, I noticed that you implemented . ```. class UniformAffinities(openTSNE.affinity.Affinities):. ``` . in here, but isn't it part of `openTSNE` already?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:812,interoperability,interfac,interface,812,"Hi Pavlin, Happy New Year! Great to see this going forward! > We'd probably have to do something similar to the gauss option and just overwrite the UMAP weights after the fact. Does this sound reasonable? Yes, I also thought we'd need to do it similar to the `gauss` option. Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? One question here though: how would `tsne` function know if it should use the uniform kernel or the weights constructed by the `neighbors` function? Can some flag be switched if `neighbors` is run with `mode='tsne'` so that the `tsne()` function later on uses those weights? Not sure what's the best interface here. Alternatively the `tsne()` function could check if the weights conform to what t-SNE expects (sum to 1). Maybe that's better actually. Apart from that, I noticed that you implemented . ```. class UniformAffinities(openTSNE.affinity.Affinities):. ``` . in here, but isn't it part of `openTSNE` already?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:812,modifiability,interfac,interface,812,"Hi Pavlin, Happy New Year! Great to see this going forward! > We'd probably have to do something similar to the gauss option and just overwrite the UMAP weights after the fact. Does this sound reasonable? Yes, I also thought we'd need to do it similar to the `gauss` option. Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? One question here though: how would `tsne` function know if it should use the uniform kernel or the weights constructed by the `neighbors` function? Can some flag be switched if `neighbors` is run with `mode='tsne'` so that the `tsne()` function later on uses those weights? Not sure what's the best interface here. Alternatively the `tsne()` function could check if the weights conform to what t-SNE expects (sum to 1). Maybe that's better actually. Apart from that, I noticed that you implemented . ```. class UniformAffinities(openTSNE.affinity.Affinities):. ``` . in here, but isn't it part of `openTSNE` already?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:177,reliability,Doe,Does,177,"Hi Pavlin, Happy New Year! Great to see this going forward! > We'd probably have to do something similar to the gauss option and just overwrite the UMAP weights after the fact. Does this sound reasonable? Yes, I also thought we'd need to do it similar to the `gauss` option. Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? One question here though: how would `tsne` function know if it should use the uniform kernel or the weights constructed by the `neighbors` function? Can some flag be switched if `neighbors` is run with `mode='tsne'` so that the `tsne()` function later on uses those weights? Not sure what's the best interface here. Alternatively the `tsne()` function could check if the weights conform to what t-SNE expects (sum to 1). Maybe that's better actually. Apart from that, I noticed that you implemented . ```. class UniformAffinities(openTSNE.affinity.Affinities):. ``` . in here, but isn't it part of `openTSNE` already?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:612,deployability,API,API,612,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1469,deployability,releas,release,1469,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:612,integrability,API,API,612,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:720,integrability,wrap,wrapper,720,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:612,interoperability,API,API,612,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:720,interoperability,wrapper,wrapper,720,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1078,interoperability,architectur,architecture,1078,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:916,modifiability,paramet,parameters,916,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1199,modifiability,paramet,parameter,1199,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:632,safety,compl,complicated,632,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:632,security,compl,complicated,632,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1150,testability,simpl,simple,1150,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1150,usability,simpl,simple,1150,"Hey Dmitry, happy New Year's to you too! > Can one use openTSNE code for computing perplexity-based weights or would one need to copy the binary search in here? [...] I noticed that you implemented `UniformAffinities ` in here, but isn't it part of openTSNE already? No, I think we should be able to call the existing machinery. But we'd need to do something like I do with the Uniform affinities here. The reason I had to write separate classes is that the ones in openTSNE calculate the KNNG internally, and don't really offer a way to pass an existing KNNG. In openTSNE that makes sense, since otherwise, the API would be pretty complicated. But here, we have to deal with that. As you can see, it's a pretty trivial wrapper anyway. > How would tsne function know if it should use the uniform kernel or the weights constructed by the neighbors function? I noticed that `sc.tl.umap` and now `sc.tl.tsne` add their parameters to `adata.uns`. I would imagine `sc.pp.neighbors` probably do the same, and if not, that seems like an easy addition, which is in line with the scanpy architecture. Determining which affinity kernel to use would then be as simple as looking into `adata.uns` to find which parameter value `sc.pp.neighbors` was called with. > I would definitely suggest to add `exaggeration=1` argument to `tsne()`. I added `exaggeration=None`, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:392,deployability,releas,release,392,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:40,integrability,wrap,wrapper,40,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:40,interoperability,wrapper,wrapper,40,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:181,modifiability,paramet,parameter,181,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:467,modifiability,paramet,parameter,467,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:134,testability,simpl,simple,134,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:134,usability,simpl,simple,134,"> As you can see, it's a pretty trivial wrapper anyway. Yes, makes sense. > Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. Yes, I like this. > I added exaggeration=None, as is the default in openTSNE. But setting it to 1 instead of None is better, and I should change that in the next release. Ah, right, I somehow overlooked that you did add the exaggeration parameter. That's fine then!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:49,availability,ping,pinging,49,I hope everybody had a good New Year break! Just pinging @ivirshup again because I think it'd be great to move forward with this. Also wanted to ping @falexwolf as I know he did a lot of work on dim reduction etc. Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:145,availability,ping,ping,145,I hope everybody had a good New Year break! Just pinging @ivirshup again because I think it'd be great to move forward with this. Also wanted to ping @falexwolf as I know he did a lot of work on dim reduction etc. Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:199,energy efficiency,reduc,reduction,199,I hope everybody had a good New Year break! Just pinging @ivirshup again because I think it'd be great to move forward with this. Also wanted to ping @falexwolf as I know he did a lot of work on dim reduction etc. Cheers.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1054,availability,avail,available,1054,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,deployability,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,integrability,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,interoperability,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:522,interoperability,specif,specify,522,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,modifiability,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1141,modifiability,paramet,parameters,1141,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1275,modifiability,paramet,parameter,1275,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,reliability,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1011,reliability,doe,does,1011,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1054,reliability,availab,available,1054,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1422,reliability,doe,does,1422,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1054,safety,avail,available,1054,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:55,security,polic,policar,55,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,security,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1054,security,availab,available,1054,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:195,testability,integr,integration,195,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1228,testability,simpl,simple,1228,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:324,usability,workflow,workflow,324,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:511,usability,user,user,511,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:707,usability,prefer,prefer,707,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:821,usability,workflow,workflow,821,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1228,usability,simpl,simple,1228,"Happy new year! And thanks for opening this PR @pavlin-policar. -----------------. First a general question. What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ `ingest` functionality happening separately, or would you like to do it all at once? -----------------. In terms of workflow, I think I'd like it to look similar to UMAP. * One function for calculating the graph/ manifold. * One function for computing the embedding. If possible, I would like it if the user could specify an arbitrary manifold (e.g. the umap weighted one) to pass to the embedding step, but this is icing. > It would also make sense to add a tsne option to sc.pp.neighbors. I would prefer for this to be a separate function, maybe `neighbors_tsne`? This could use the entire neighbor calculating workflow from `openTSNE`. How different are the arguments to the various `affinity` methods? At first glance they look pretty similar. I'd like to have the option of choosing which one, but does it make sense to have all the methods available through one function? > noticed that sc.tl.umap and now sc.tl.tsne add their parameters to adata.uns. ... Determining which affinity kernel to use would then be as simple as looking into adata.uns to find which parameter value sc.pp.neighbors was called with. +1. Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:410,availability,sli,slightly,410,">> It would also make sense to add a tsne option to sc.pp.neighbors. >. > I would prefer for this to be a separate function, maybe neighbors_tsne? This could use the entire neighbor calculating workflow from openTSNE. Not sure I understood this bit. Why? `sc.pp.neighbors` already has `method='gauss'` implemented which is using Gaussian weights instead of UMAP weights. t-SNE also uses Gaussian weights, only slightly differently. Why would you prefer a separate function over having `method='tsne'` in the same function? My first impression is that it'd more confusing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:410,reliability,sli,slightly,410,">> It would also make sense to add a tsne option to sc.pp.neighbors. >. > I would prefer for this to be a separate function, maybe neighbors_tsne? This could use the entire neighbor calculating workflow from openTSNE. Not sure I understood this bit. Why? `sc.pp.neighbors` already has `method='gauss'` implemented which is using Gaussian weights instead of UMAP weights. t-SNE also uses Gaussian weights, only slightly differently. Why would you prefer a separate function over having `method='tsne'` in the same function? My first impression is that it'd more confusing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:82,usability,prefer,prefer,82,">> It would also make sense to add a tsne option to sc.pp.neighbors. >. > I would prefer for this to be a separate function, maybe neighbors_tsne? This could use the entire neighbor calculating workflow from openTSNE. Not sure I understood this bit. Why? `sc.pp.neighbors` already has `method='gauss'` implemented which is using Gaussian weights instead of UMAP weights. t-SNE also uses Gaussian weights, only slightly differently. Why would you prefer a separate function over having `method='tsne'` in the same function? My first impression is that it'd more confusing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:194,usability,workflow,workflow,194,">> It would also make sense to add a tsne option to sc.pp.neighbors. >. > I would prefer for this to be a separate function, maybe neighbors_tsne? This could use the entire neighbor calculating workflow from openTSNE. Not sure I understood this bit. Why? `sc.pp.neighbors` already has `method='gauss'` implemented which is using Gaussian weights instead of UMAP weights. t-SNE also uses Gaussian weights, only slightly differently. Why would you prefer a separate function over having `method='tsne'` in the same function? My first impression is that it'd more confusing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:446,usability,prefer,prefer,446,">> It would also make sense to add a tsne option to sc.pp.neighbors. >. > I would prefer for this to be a separate function, maybe neighbors_tsne? This could use the entire neighbor calculating workflow from openTSNE. Not sure I understood this bit. Why? `sc.pp.neighbors` already has `method='gauss'` implemented which is using Gaussian weights instead of UMAP weights. t-SNE also uses Gaussian weights, only slightly differently. Why would you prefer a separate function over having `method='tsne'` in the same function? My first impression is that it'd more confusing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:267,availability,mainten,maintenance,267,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:829,deployability,API,API,829,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:829,integrability,API,API,829,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:829,interoperability,API,API,829,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:267,reliability,mainten,maintenance,267,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:436,safety,compl,complicated,436,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:600,safety,valid,valid,600,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:707,safety,compl,complicated,707,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:436,security,compl,complicated,436,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:707,security,compl,complicated,707,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:569,testability,understand,understand,569,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:813,testability,simpl,simple,813,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:283,usability,document,documentation,283,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:563,usability,user,users,563,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:813,usability,simpl,simple,813,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:880,usability,workflow,workflow,880,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1097,usability,minim,minimum,1097,"> I think it may be possible to use openTSNE's function to compute the affinities and then get the weights out of there? I would definitely like this to be the case. I'm not sure I see . > Why? `sc.pp.neighbors` already has `method='gauss'`. To me, it’s largely of a maintenance and documentation issue. Most bugs I fix (here, and in upstream libraries) come from argument handling. The more features you lump into a function, the more complicated argument handling gets. There are questions of default values and fallbacks for different backends, and being sure users understand which arguments are valid for each backend. The use of the `Neighbors` class ends up making the `neighbors` function much more complicated than it needs to be. I think skipping out on that here can make this implementation much more simple. From an API stand point, I would like the ""blessed"" `tsne` workflow to be dead obvious. I'm thinking:. ```python. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. How many arguments is it going to take to make this work if this functionality is in `sc.pp.neighbors`? At a minimum, `k=30, method=tsne_affinity, nn_method=""annoy""`, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1289,availability,down,downstream,1289,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1322,availability,cluster,clustering,1322,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:263,deployability,API,API,263,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1322,deployability,cluster,clustering,1322,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:191,integrability,event,eventually,191,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:263,integrability,API,API,263,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:263,interoperability,API,API,263,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:694,reliability,doe,does,694,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:92,safety,compl,complicated,92,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:122,safety,compl,complicate,122,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:92,security,compl,complicated,92,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:122,security,compl,complicate,122,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:14,testability,understand,understanding,14,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:312,usability,workflow,workflow,312,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:521,usability,minim,minimum,521,"Thanks! So my understanding is that you are saying that `neighbors` function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that `gauss` out of it, I guess?). > From an API stand point, I would like the ""blessed"" tsne workflow to be dead obvious. I'm thinking:. > `sc.pp.neighbors_tsne(adata)`. > `sc.tl.tsne(adata)`. > How many arguments is it going to take to make this work if this functionality is in sc.pp.neighbors? At a minimum, k=30, method=tsne_affinity, nn_method=""annoy"", right? I'd say `perplexity=30, method='tsne'`. I don't see why t-SNE should use annoy if UMAP uses pynndescent. This does not matter for the algorithm. So `nn_method` could either be included in all `neighbors` functions or into none, IMHO. In any case,. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. would also be fine with me. I think it's important that the following works:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). But if somebody wants to do the ""actual"" t-SNE, then they can run `sc.pp.neighbors_tsne(adata)` first. I think this makes sense. . One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs `neighbors_tsne` (or both `neighbors` and `neighbors_tsne`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1404,availability,down,downstream,1404,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1437,availability,cluster,clustering,1437,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:317,deployability,API,APIs,317,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:355,deployability,API,APIs,355,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:925,deployability,API,API,925,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1051,deployability,build,build,1051,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1437,deployability,cluster,clustering,1437,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:191,integrability,event,eventually,191,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:317,integrability,API,APIs,317,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:355,integrability,API,APIs,355,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:405,integrability,event,eventually,405,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:520,integrability,interfac,interface,520,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:751,integrability,Coupl,Couple,751,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:925,integrability,API,API,925,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:317,interoperability,API,APIs,317,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:355,interoperability,API,APIs,355,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:520,interoperability,interfac,interface,520,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:925,interoperability,API,API,925,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:520,modifiability,interfac,interface,520,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:751,modifiability,Coupl,Couple,751,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:92,safety,compl,complicated,92,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:122,safety,compl,complicate,122,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:832,safety,input,input,832,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:945,safety,compl,completely,945,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:92,security,compl,complicated,92,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:122,security,compl,complicate,122,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:508,security,expos,exposing,508,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:945,security,compl,completely,945,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:16,testability,understand,understanding,16,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:287,testability,simpl,simpler,287,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:751,testability,Coupl,Couple,751,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:266,usability,prefer,prefer,266,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:287,usability,simpl,simpler,287,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:501,usability,prefer,prefer,501,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:801,usability,prefer,prefer,801,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:832,usability,input,input,832,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1002,usability,clear,clear,1002,"> Thanks! So my understanding is that you are saying that neighbors function is ALREADY too complicated, so we should not complicate it any further (and rather the existing function could be eventually split by taking that gauss out of it, I guess?). Pretty much. I prefer more smaller, simpler functions with common APIs than fewer functions with larger APIs. > and rather the existing function could be eventually split by taking that gauss out of it, I guess? I think I'd be pro that. I'd probably prefer exposing an interface for computing weights from KNN distances where methods like `gauss` could sit. > I think it's important that the following works and is actually the recommended way to run t-SNE within scanpy. (Using uniform affinities). Couple questions, first scientific: Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. Second API: I'm not sure I completely agree with this. I think it would be the most clear for `sc.pp.neighbors` to essentially mean ""build umap's connectivity graph"", and functions like `sc.tl.tsne` or `sc.tl.umap` to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via `connectivities_key`) are the weights that get used. Are there cases you think this disallows? > One question here is maybe what should other downstream functions like Leiden clustering use, if somebody runs neighbors_tsne (or both neighbors and neighbors_tsne). The graph that's used is provided from arguments like `neighbors_key` or `obsp` from `leiden`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:162,deployability,API,API,162,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:566,deployability,API,API,566,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:690,deployability,build,build,690,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:162,integrability,API,API,162,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:566,integrability,API,API,566,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:162,interoperability,API,API,162,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:566,interoperability,API,API,566,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:47,safety,input,input,47,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:586,safety,compl,completely,586,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:586,security,compl,completely,586,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:950,testability,understand,understand,950,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1286,testability,simpl,simply,1286,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:16,usability,prefer,prefer,16,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:47,usability,input,input,47,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:643,usability,clear,clear,643,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1093,usability,user,users,1093,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1257,usability,workflow,workflow,1257,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1286,usability,simpl,simply,1286,"> Why would you prefer uniform edge weights as input to your t-sne? I would think the information about relative distance is useful. My argument was mostly about API. But one big benefit of using kNN with k=15 is that it's *much faster* then using k=90 (with perplexity=30) which is what t-SNE is using by default (for historical reasons). It's not about uniform vs non-uniform, it's about k=15 vs k=90. Uniform on k=15 just happens to give almost the same results as perplexity=30 on k=90. So it's a lucky coincidence that I thought we could benefit from. > Second API: I'm not sure I completely agree with this. I think it would be the most clear for sc.pp.neighbors to essentially mean ""build umap's connectivity graph"", and functions like sc.tl.tsne or sc.tl.umap to be ""find a 2d embedding using the passed connectivity graph"". This means whatever affinities you're passing through (e.g. via connectivities_key) are the weights that get used. I understand what you saying, but the situation won't be symmetric because `neighbors` already exists, is *not* called `neighbors_umap`, and all users of Scanpy are very familiar with this function. I'd like to make it very easy to use t-SNE in scanpy and that it naturally fits into the scanpy's established workflow. That's why I think simply running `tsne()` after running `neighbors()` should be possible. Please note that t-SNE requires normalized weights (they should sum to 1). The weights constructed by UMAP in `neighbors` are not normalized. So if you run `neighbors()` and then `tsne()` then t-SNE should do *something* in order to be able to use this graph. My suggestion is that it discards the weights and uses normalized affinity matrix. I am not sure what exactly is your suggestion? Take UMAP weights and normalize them? This has never been explored in the literature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1341,availability,cluster,clustering,1341,"hould be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1817,availability,cluster,clustering,1817,"ings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they sp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1999,availability,cluster,clustering,1999,"est neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` us",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2094,availability,cluster,clustering,2094,"essing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philos",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3748,availability,cluster,clustering,3748," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:4030,availability,slo,slow,4030," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,deployability,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1140,deployability,API,API,1140,"ntegration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1192,deployability,API,API,1192,"y, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1275,deployability,API,API,1275,"nce they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitabl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1341,deployability,cluster,clustering,1341,"hould be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1817,deployability,cluster,clustering,1817,"ings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they sp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1999,deployability,cluster,clustering,1999,"est neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` us",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2094,deployability,cluster,clustering,2094,"essing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philos",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2786,deployability,releas,release,2786," when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3748,deployability,cluster,clustering,3748," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3947,deployability,API,API,3947," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:912,energy efficiency,model,model,912,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,integrability,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:968,integrability,transform,transform,968,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1140,integrability,API,API,1140,"ntegration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1192,integrability,API,API,1192,"y, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1275,integrability,API,API,1275,"nce they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitabl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1438,integrability,rout,route,1438,"ffinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2082,integrability,graph-bas,graph-based,2082," but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the de",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3062,integrability,sub,suboptimal,3062,"g the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3947,integrability,API,API,3947," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,interoperability,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:575,interoperability,specif,specify,575,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:968,interoperability,transform,transform,968,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1140,interoperability,API,API,1140,"ntegration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1192,interoperability,API,API,1192,"y, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1275,interoperability,API,API,1275,"nce they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitabl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2044,interoperability,standard,standard,2044,"d how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. B",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3947,interoperability,API,API,3947," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,modifiability,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:518,modifiability,paramet,parameters,518,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:724,modifiability,paramet,parameter,724,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2885,modifiability,refact,refactoring,2885,"ghbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2885,performance,refactor,refactoring,2885,"ghbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,reliability,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:831,reliability,doe,does,831,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1078,reliability,doe,does,1078," PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG fo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2605,reliability,doe,does,2605,"onfusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one conn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2902,reliability,doe,doesn,2902,"I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design ch",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3030,reliability,doe,does,3030,"n tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a sl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:4030,reliability,slo,slow,4030," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:365,safety,review,review,365,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:4083,safety,compl,completely,4083," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,security,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:912,security,model,model,912,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:4083,security,compl,completely,4083," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,testability,integr,integration,141,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:365,testability,review,review,365,"I'm a little late to the party, but here's my 0.02$. > What is the scope of this PR? Will this just be single dataset TSNE calculation, with integration/ ingest functionality happening separately, or would you like to do it all at once? I think we can split it into two PRs, since they're going to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1287,testability,simpl,simple,1287,"oing to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1399,testability,simpl,simple,1399,"rent are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1940,testability,understand,understand,1940,"t, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1287,usability,simpl,simple,1287,"oing to touch different parts of the code base, and it should be easier to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to cal",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1353,usability,visual,visualization,1353,"r to review them individually. > How different are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1399,usability,simpl,simple,1399,"rent are the arguments to the various affinity methods? So, if we use the KNNG provided by `sc.pp.neighbors`, these parameters become unnecessary. Both `perplexity` and `k` specify the number of k-nearest neighbors when constructing the KNNG. Here, we assume that the KNNG exists from before, so there is no need for this parameter. > Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1729,usability,visual,visualizations,1729," Do you need to know what the affinity method was if you're just calculating an embeddings? Or does that only become important when you want to add new data? Yes, the affinity model will have to be somehow kept, since when we call `transform`, we need to find the nearest neighbors in the index. I haven't checked how your UMAP functionality does this, but I'm guessing it's similar. Regarding the whole API, I have a few comments. I very much dislike the API `sc.pp.neighbors_tsne(adata)`. scanpy is nice because it's easy to use and the API is dead simple. I can just call `sc.pp.neighbors` followed by clustering, visualization, and whatever else I want using simple function calls. If we went this route, this would mean changing `sc.pp.neighbors` to `sc.pp.umap_neighbors`, and then splitting of yet another `sc.pp.gauss_neighbors`. This would not only make things confusing, it would mean re-calculating the KNNG at each call, which we would inevitably have to do if we wanted different visualizations. It then also becomes quite unclear what to do when I want to do Louvain clustering. Should there be a `sc.pp.louvain_neighbors` as well? Which neighbors should I use there? (As an aside, I don't understand why using UMAP connectivites is the default for clustering at all. From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems lik",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:3581,usability,prefer,preference,3581," From an implementation standpoint, the `sc.pp.tsne_negihbors` will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. `sc.pp.neighbors` calls the UMAP implementation directly, and since the goal is to use the same KNNG construction procedure, t-SNE will have to call the same UMAP function, and override the weights afterward. Much like `gauss` does now. It would probably make more sense to split out the KNNG construction from the UMAP weight calculation, but that seems like a lot of work. Or maybe not. In the latest UMAP release from a few days ago, they split out the graph construction into `pynndescent`. Either way, refactoring this doesn't belong in this PR. Alternatively, we could construct our own KNNG in `sc.pp.tsne_neighbors` using Annoy, which openTSNE does by default. But that seems suboptimal, because the design philosophy seems to be re-use the same graph for everything. . What I think would make more sense is to remove the connectivity calculation from the `sc.pp.neighbors` altogether, and have that calculate an unweighted KNNG. Since different methods need their own connectivities anyways, that should be done in each method separately. So UMAP connectivities would be calculated in `sc.tl.umap`, and the Louvain Jaccard connectivities in `sc.tl.louvain`. Then, you wouldn't be assigning any preference to any one connectivity method. From what I can tell, there's no evidence the UMAP connectivities are better than the others in any way, especially not for clustering. If you have any information on this, I'd be really curious to know. Ultimately, the decision is up to you guys, since this is more of a design choice of where you want to take the scanpy API. The existing solution is worse than anything we've discussed because we use a slow variant of t-SNE, which calculates its own KNNG completely separately from the `sc.pp.neighbors`. So really, any step we take would be a step in the right direction.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:506,availability,avail,available,506,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2146,availability,cluster,clustering,2146,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2480,availability,cluster,cluster,2480,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2720,availability,cluster,clusters,2720,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:10,deployability,API,API,10,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:165,deployability,depend,depend,165,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,deployability,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,deployability,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2146,deployability,cluster,clustering,2146,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2480,deployability,cluster,cluster,2480,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2720,deployability,cluster,clusters,2720,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:10,integrability,API,API,10,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:165,integrability,depend,depend,165,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,integrability,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,integrability,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1125,integrability,Wrap,WrappedAffinities,1125,"ultiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1968,integrability,event,eventually,1968,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2134,integrability,graph-bas,graph-based,2134,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2304,integrability,standardiz,standardized,2304,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:10,interoperability,API,API,10,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,interoperability,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,interoperability,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1563,interoperability,specif,specifically,1563,"an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2096,interoperability,standard,standard,2096,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2304,interoperability,standard,standardized,2304,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:165,modifiability,depend,depend,165,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:190,modifiability,pac,package,190,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:259,modifiability,paramet,parameters,259,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:516,modifiability,paramet,parameters,516,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,modifiability,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,modifiability,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2438,modifiability,paramet,parameter,2438,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:506,reliability,availab,available,506,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,reliability,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,reliability,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2262,reliability,doe,does,2262,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:165,safety,depend,depend,165,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:506,safety,avail,available,506,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:506,security,availab,available,506,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,security,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,security,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:165,testability,depend,depend,165,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:713,testability,integr,integrate,713,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:763,testability,integr,integrated,763,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:531,usability,clear,clear,531,"About the API, I still think it makes sense for TSNE weighted neighbor calculation to be separate, especially if it is going to have multiple weighting options that depend on the `openTSNE` package. If it turns out these methods don't have much in the way of parameters, then it might be reasonable for this to be a part of `sc.pp.neighbors`. How about this, the implementation here should be well factored out into:. 1. Getting nearest neighbors. 2. Weighting the graph. 3. Computing the layout. Once the available parameters are clear I think it'll be easier to make an informed decision about whether neighbor weighting for tsne should occur through `sc.pp.neighbors`. Additionally, I think it'll be easier to integrate cleanly separated code than to separate integrated code. > The weights constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2047,usability,help,help,2047,"ts constructed by UMAP in neighbors are not normalized. So if you run neighbors() and then tsne() then t-SNE should do something in order to be able to use this graph. For passing the umap connectivity matrix to tsne layout, I think I would expect the weights to be used. Something like this should accomplish that:. ```python. class WrappedAffinities(openTSNE.affinity.Affinities):. def __init__(self, neighbors, symmetrize=True, verbose=False):. self.verbose = verbose. P = neighbors. if symmetrize:. P = (P + P.T) / 2. total = P.sum(). if not np.isclose(total, 1.):. P = P / total. self.P = P. ```. That said, I'm not too familiar with the assumptions of tsne, or if this would be appropriate. I think binarizing the edge weights is a bit of a strong assumption unless specifically requested though. With `umap`, we throw a warning if it looks like the passed graph didn't come from `umap`. You could do the same here? > From an implementation standpoint, the sc.pp.tsne_negihbors will inevitably have to call the UMAP KNNG construction, since I can see that it's not split out in the code-base. I would like nearest neighbor calculation and graph weighting to be split out eventually. Since it's already done this way in `openTSNE`, I think this could help with that goal. > From what I can tell, the standard way of weighing the KNNG for graph-based clustering in single-cell is to use the Jaccard index of the mutual nearest neighbors to weigh the edges). `Seurat` does this, but I'm not sure this has been standardized much otherwise. Off the top of my head, I'd guess that the Jaccard method is going to be much more sensitive to `k` as a parameter, particularly how it relates to cluster size. I'm not really aware of any consensus made on this or benchmarks comparing approaches. When I've looked into it, using the weights (as opposed to just binarized edges) seems to give more stable results, particularly for small clusters. We've had some previous discussions on this here: #586, #240.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1139,deployability,API,API,1139,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:205,integrability,pub,publications,205,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:602,integrability,pub,publications,602,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1139,integrability,API,API,1139,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1139,interoperability,API,API,1139,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1311,modifiability,refact,refactoring,1311,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1311,performance,refactor,refactoring,1311,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:29,testability,simpl,simple,29,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:783,testability,simpl,simply,783,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:29,usability,simpl,simple,29,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:72,usability,command,commands,72,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:783,usability,simpl,simply,783,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:859,usability,user,user,859,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1173,usability,person,personally,1173,"My primary wish here is very simple. I'd like the following sequence of commands:. ```. sc.pp.neighbors(adata). sc.tl.tsne(adata). ```. to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. What you suggest @ivirshup (t-SNE on normalized UMAP affinities) could maybe achieve that, but we would need to check. As I said, I don't think anybody ever has tried that. I could imagine that it would roughly correspond to t-SNE with perplexity less than 30, perhaps 20 or so, but this is just a wild guess. . I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications, because it's really t-SNE on normalized UMAP affinities which is an odd-sounding hybrid. But if the result is similar enough to t-SNE, then maybe it's okay to call it simply ""t-SNE (as implemented in Scanpy)""... A *separate* question is how a user would be able to achieve t-SNE *proper*, and here I could live with either. ```. sc.pp.neighbors(adata, method='tsne') # this would use perplexity=30 by default. sc.tl.tsne(adata). ```. or. ```. sc.pp.neighbors_tsne(adata). sc.tl.tsne(adata). ```. This is just a question of API, and is less important for me personally. I agree that it could be better to have `neighbors()` compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1477,availability,down,down,1477,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,deployability,API,API,568,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:888,deployability,API,API,888,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:119,integrability,pub,publications,119,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:208,integrability,pub,publications,208,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,integrability,API,API,568,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:888,integrability,API,API,888,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:224,interoperability,share,share,224,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,interoperability,API,API,568,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:888,interoperability,API,API,888,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1121,interoperability,compatib,compatibility,1121,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1058,modifiability,refact,refactoring,1058,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1058,performance,refactor,refactoring,1058,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:596,security,control,control,596,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:672,security,control,control,672,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:596,testability,control,control,596,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:672,testability,control,control,672,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:37,usability,command,commands,37,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:365,usability,user,users,365,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:765,usability,close,closer,765,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:922,usability,person,personally,922,"> I'd like the following sequence of commands ... to produce a reasonable t-SNE result that could be called ""t-SNE"" in publications. . > I am worried that it may be a bit weird to refer to this as ""t-SNE"" in publications. I share the same worry, but am not qualified to answer when something becomes ""t-SNE"". I think it would be sufficient for `sc.tl.tsne` to warn users if the graph it was passed looks unexpected (or if it could tell it was generated by a different method). > What you suggest (t-SNE on normalized UMAP affinities) could maybe achieve that. From an API point of view, we don't control weights at the `sc.tl.umap` call, so I think it would be strange to control weights at the `sc.tl.tsne` call. I'm also not sure if binarizing the graph would be closer to ""t-SNE"". ----------------------. About `sc.pp.neighbors` vs `sc.pp.neighbors_tsne`. > This is just a question of API, and is less important for me personally. I agree that it could be better to have neighbors() compute kNN adjacency matrix without computing any weights, but this is refactoring beyond the scope of this PR. I think for backwards compatibility I would like to keep neighbors pretty much as is. I think new functions like `distance_neighbors`, `umap_neighbors`, `tsne_neighbors` could be reasonable to add. It's also possible we could add a `""tsne""` method to `neighbors`, but I think the implementation can look very similar to having a `tsne_neighbors` function, so this can be kicked down the road a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:464,availability,slo,slower,464,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:531,deployability,API,API,531,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1258,deployability,manag,managed,1258,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1258,energy efficiency,manag,managed,1258,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1586,energy efficiency,current,current,1586,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:179,integrability,messag,message,179,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:239,integrability,messag,message,239,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:350,integrability,messag,message,350,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:531,integrability,API,API,531,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:179,interoperability,messag,message,179,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:239,interoperability,messag,message,239,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:350,interoperability,messag,message,350,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:531,interoperability,API,API,531,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:464,reliability,slo,slower,464,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:949,reliability,doe,does,949,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1070,reliability,pra,practically,1070,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1258,safety,manag,managed,1258,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:559,security,control,control,559,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:633,security,control,control,633,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:695,security,control,control,695,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:747,security,control,controls,747,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:559,testability,control,control,559,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:633,testability,control,control,633,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:695,testability,control,control,695,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:747,testability,control,controls,747,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:56,usability,user,users,56,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:303,usability,close,close,303,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:418,usability,command,command,418,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:851,usability,close,closer,851,"> I think it would be sufficient for sc.tl.tsne to warn users if the graph it was passed looks unexpected. Yes, warning is a good idea. But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. If you really want to get exactly t-SNE, run the following command instead: ..., but note that it can be slower and the result will likely look around the same"". > From an API point of view, we don't control weights at the sc.tl.umap call, so I think it would be strange to control weights at the sc.tl.tsne call. But we will *have* to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. > I'm also not sure if binarizing the graph would be closer to ""t-SNE"". Maybe not, but. (1) it will be further away from UMAP, so that e.g. UMAP paper does not need to be cited when using such t-SNE. . (2) There is citeable literature showing that binary affinities yield practically the same result as t-SNE proper. We can cite this in Scanpy docs. I am not aware of any such literature for normalized UMAP affinities in t-SNE. Stepping back, I am not sure I managed to convey my main point here. Which is: Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, *UMAP-independent*, and nearly equivalent replacement for k=90, perplexity=30 affinities. . I agree with Pavlin though that pretty much any decision would be better than the current situation :-)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,availability,error,error,568,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1182,availability,error,erroring,1182,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:55,deployability,releas,release,55,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:895,deployability,compos,composable,895,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:608,energy efficiency,optim,optimization,608,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,integrability,messag,message,141,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:201,integrability,messag,message,201,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:312,integrability,messag,message,312,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:141,interoperability,messag,message,141,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:201,interoperability,messag,message,201,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:312,interoperability,messag,message,312,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1814,interoperability,standard,standard,1814,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2060,interoperability,standard,standard,2060,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:895,modifiability,compos,composable,895,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1396,modifiability,maintain,maintained,1396,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,performance,error,error,568,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:608,performance,optimiz,optimization,608,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1182,performance,error,erroring,1182,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1211,reliability,doe,doesn,1211,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,safety,error,error,568,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1061,safety,except,exception,1061,". Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1182,safety,error,erroring,1182,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1396,safety,maintain,maintained,1396,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:368,security,control,control,368,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:420,security,control,controls,420,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:368,testability,control,control,368,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:420,testability,control,controls,420,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:265,usability,close,close,265,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:568,usability,error,error,568,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:828,usability,user,users,828,"Sorry about the wait, had to focus on getting the last release out. Now we can do new features! > But the warning IMHO should not convey the message ""Do not do this!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warni",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1182,usability,error,erroring,1182,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1323,usability,efficien,efficient,1323,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2017,usability,user,user,2017,"is!"". In my mind, it should convey the message ""What you are computing is not exactly t-SNE, but it is close enough to t-SNE that you can ignore this message. That sounds appropriate. > But we will have to control them anyway... Your suggested solution also controls them: namely, symmetrizes and normalizes. I think normalization is a ""lighter touch"" than binarization. To me, the alternative would be to error for non-normalized data since the optimization won't converge properly. Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Exactly how the option to do this is provided to users could take some consideration. I think it would be clean and composable to have graph weighting options separate from embedding layout options, but considering `tsne` has restrictions on graph weights there may have to be some exception here. Perhaps there needs to be a `weights` option on `tsne` which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. -------------------. From my perspective, what we have to gain here is:. * More efficient TSNE by default. * Consolidate implementation to a single well maintained library. * More flexibility in how tsne is computed. > Scanpy is in a unique position to offer people t-SNE with k=15 binary affinities as a convenient, faster, UMAP-independent, and nearly equivalent replacement for k=90, perplexity=30 affinities. I'm happy to have this be an option. I'm less comfortable with something like this being the ""recommended path"", since not using perplexity weights seems non-standard. -------------------. In general, are we agreed on these points? * `tsne` should allow weights to be passed through (whether perplexity based, or not). * There should be a warning to notify the user if the weights were computed in a non-standard way. * There should be a function for computing a perplexity weighted nearest neighbor graph.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:441,availability,error,erroring,441,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:525,availability,error,erroring,525,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1628,deployability,API,API,1628,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1628,integrability,API,API,1628,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:218,interoperability,standard,standard,218,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1628,interoperability,API,API,1628,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:441,performance,error,erroring,441,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:525,performance,error,erroring,525,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:470,reliability,doe,doesn,470,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1748,reliability,Doe,Does,1748,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:441,safety,error,erroring,441,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:525,safety,error,erroring,525,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1468,safety,compl,complicated,1468,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1519,safety,compl,complicated,1519,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1468,security,compl,complicated,1468,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1519,security,compl,complicated,1519,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:175,usability,user,user,175,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:441,usability,error,erroring,441,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:525,usability,error,erroring,525,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1118,usability,close,closer,1118,"> In general, are we agreed on these points? . > tsne should allow weights to be passed through (whether perplexity based, or not) . > There should be a warning to notify the user if the weights were computed in a non-standard way . > There should be a function for computing a perplexity weighted nearest neighbor graph. . Yes. I agree. > Perhaps there needs to be a weights option on tsne which allows normalization, binarization, or just erroring if the passed graph doesn't have correct weighting. This sounds good. IMHO erroring is not necessary. There will be a warning anyway. > Not knowing too much about the internals of tsne, is a symmetric graph necessary? If it's not, then I'd be fine with not doing that. Actually UMAP weights *are* symmetric. So it would be enough to normalize the entire weight matrix to sum to 1. -----------------. I think there are two different choices that we have been disagreeing about:. * Choice 1: whether `preprocess_weights='normalize'` or `preprocess_weights='binarize'` is default for `tl.tsne()` if the passed weights do not sum to 1. * Argument for `normalize` (Isaac): closer to originally calculated weights;. * Argument for `binarize` (Dmitry and Pavlin): will make it UMAP-independent if `tl.tsne()` is run after default `tt.neighbors()`. * Choice 2: whether perplexity weights are given by `pp.neighbors_tsne()` or by `pp.neighbors(method='tsne')`. * Argument for `neighbors_tsne` (Isaac): the existing function is complicated enough, so let's not make it even more complicated;. * Argument for `neighbors(method='tsne')` (Dmitry and Pavlin): the other option would make the API for UMAP weights and for tSNE weights assymetric and even confusing, as `neighbors` is not called `neighbors_umap`. Does this summarize the arguments from both sides?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:266,reliability,Doe,Does,266,"Ahh, I had written a response to this, but appear not to have hit send! Apologies! For the decisions, I think that these are both relatively easy to change, and it'll be easier to get another opinion from the team once the basic functionality is present in this PR. Does that sound right to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:209,security,team,team,209,"Ahh, I had written a response to this, but appear not to have hit send! Apologies! For the decisions, I think that these are both relatively easy to change, and it'll be easier to get another opinion from the team once the basic functionality is present in this PR. Does that sound right to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:50,interoperability,convers,conversation,50,@pavlin-policar Have you had a chance to read our conversation above (I tried to summarize it in my last comment above)? What are your thoughts?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:8,security,polic,policar,8,@pavlin-policar Have you had a chance to read our conversation above (I tried to summarize it in my last comment above)? What are your thoughts?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1732,availability,down,downstream,1732," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1743,availability,cluster,clustering,1743," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:103,deployability,API,API,103,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:155,deployability,releas,release,155,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:203,deployability,releas,release,203,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:792,deployability,automat,automatically,792,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1743,deployability,cluster,clustering,1743," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2022,deployability,API,API,2022," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2179,deployability,patch,patching,2179," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2201,deployability,API,API,2201," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2252,deployability,API,API,2252," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2280,deployability,log,logical,2280," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2419,deployability,API,API,2419," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:103,integrability,API,API,103,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2022,integrability,API,API,2022," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2201,integrability,API,API,2201," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2252,integrability,API,API,2252," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2419,integrability,API,API,2419," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:103,interoperability,API,API,103,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:257,interoperability,compatib,compatibility,257,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2022,interoperability,API,API,2022," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2201,interoperability,API,API,2201," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2252,interoperability,API,API,2252," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2419,interoperability,API,API,2419," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:502,modifiability,paramet,parameter,502,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1238,modifiability,scenario,scenarios,1238,"bout backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of paramet",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1282,modifiability,paramet,parameters,1282,"he following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1442,modifiability,paramet,parameters,1442," whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2236,modifiability,paramet,parameters,2236," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:610,safety,input,input,610,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1024,safety,avoid,avoid,1024,"ad, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2162,safety,compl,complicated,2162," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2179,safety,patch,patching,2179," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2280,safety,log,logical,2280," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2162,security,compl,complicated,2162," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2179,security,patch,patching,2179," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2280,security,log,logical,2280," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:792,testability,automat,automatically,792,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2280,testability,log,logical,2280," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:61,usability,clear,clear,61,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:610,usability,input,input,610,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:962,usability,close,close,962,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:987,usability,user,users,987,"So, having re-read the thread, the steps forward seem pretty clear, and we're really just debating the API, which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are consid",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1105,usability,close,close,1105,"which wouldn't be that hard to change before a release anyways. It becomes much harder after a release because they you have to worry about backward compatibility. So, I suggest the following. First, calling `sc.pp.neighbors` followed by `sc.tl.tsne` should not recompute the nearest neighbors, and use the existing KNNG. To get around the whole ""should we binarize or not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionali",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1606,usability,clear,clear,1606," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1612,usability,prefer,preferential,1612," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:2447,usability,prototyp,prototype,2447," not"", I suggest adding a parameter to `sc.tl.tsne(binarize: bool = ""auto"")`. If `binarize=True`, we binarize the KNNG, regardless of input. If `binarize=False`, we just re-normalize the weights if needed. This way, we can potentially use UMAP connectivities. As for the default option `binarize=""auto""`, this would automatically binarize weights if they don't come from `sc.pp.neighbors_tsne`. This way, the default would either use t-SNE proper, or the uniform kernel t-SNE, which is close enough. Since most users use default values, this would avoid people running a strange combination of UMAP and t-SNE, and have something close to t-SNE proper, and would only have to cite the t-SNE paper (as implemented in scanpy). This way, we can run any of the three scenarios. Second, I agree that adding more parameters to `sc.pp.neighbors` is not a good idea, so, at least for now, the least bad solution seems to add `sc.pp.neighbors_tsne`. This way, we can see what parameters are needed and not need to work around the existing implementation. That said, this is not a good solution, just not as bad as the other one. This gives clear preferential treatment to UMAP weights. I am still confused why the UMAP weights are the used for everything, including downstream clustering (e.g. `sc.pp.neighbors(...); sc.tl.leiden(...)`). I haven't been following single-cell literature as much lately, but from what I can tell, there's no evidence that shows this is better than anything else. From #1739, it seems that you are considering a change in the API, and I would definitely be in favour of that. As you add more and more functionality to scanpy, things are inevitably going to get more complicated, and patching the existing API will just lead to thousands of parameters. The API in #1739 seems like the logical next step. I'll try to work on this in the coming days/weeks, so we can see what's really necessary, and we can work out the exact API after we have a working prototype. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:291,deployability,pipelin,pipeline,291,Sounds great to me! Looking forward. Would be interesting to compare these three t-SNEs: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on a couple of datasets after the standard scanpy preprocessing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:232,integrability,coupl,couple,232,Sounds great to me! Looking forward. Would be interesting to compare these three t-SNEs: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on a couple of datasets after the standard scanpy preprocessing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:291,integrability,pipelin,pipeline,291,Sounds great to me! Looking forward. Would be interesting to compare these three t-SNEs: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on a couple of datasets after the standard scanpy preprocessing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:261,interoperability,standard,standard,261,Sounds great to me! Looking forward. Would be interesting to compare these three t-SNEs: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on a couple of datasets after the standard scanpy preprocessing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:232,modifiability,coupl,couple,232,Sounds great to me! Looking forward. Would be interesting to compare these three t-SNEs: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on a couple of datasets after the standard scanpy preprocessing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:232,testability,coupl,couple,232,Sounds great to me! Looking forward. Would be interesting to compare these three t-SNEs: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on a couple of datasets after the standard scanpy preprocessing pipeline.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:209,deployability,fail,fail,209,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:222,deployability,releas,release,222,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:236,deployability,version,version,236,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:431,deployability,updat,updated,431,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:112,integrability,coupl,couple,112,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:236,integrability,version,version,236,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:112,modifiability,coupl,couple,112,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:236,modifiability,version,version,236,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:625,modifiability,paramet,parameter,625,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:735,modifiability,refact,refactoring,735,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:735,performance,refactor,refactoring,735,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:209,reliability,fail,fail,209,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:183,safety,test,tests,183,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:431,safety,updat,updated,431,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:431,security,updat,updated,431,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:535,security,ident,identical,535,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:112,testability,coupl,couple,112,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:183,testability,test,tests,183,"@ivirshup @dkobak I've fixed up this PR, so now it implements what I mentioned in my comment above. I've left a couple of comments on the code, commenting on anything noteworthy. The tests and everything will fail until I release a new version of openTSNE, which I'll do in the coming days. But please look through the changes and let me know if there's anything you'd like me to change, so we can get this merged. Also, I haven't updated the docstrings at all. The most glaring thing is `neighbors_tsne`. Over 90% of the code here is identical to `neighbors`. Really, the only difference is that I changed the `n_neighbors` parameter to `perplexity`. But there was no elegant way to incorporate that into `neighbors`. I've also tried refactoring the duplicated code that saves the settings into `adata.uns`, but doingt that would also make the code pretty messy. Obviously, it's not a good idea to have duplicated code like this. What do you think would be the best way to handle this? Functionally, this now works as agreed. Let me know how you want to proceed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:0,energy efficiency,Cool,Cool,0,"Cool! Did you have a chance to compare these embeddings: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on one of the standard scanpy datasets, like e.g. scanpy.datasets.pbmc3k_processed (used in scanpy tutorials such as https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:209,interoperability,standard,standard,209,"Cool! Did you have a chance to compare these embeddings: . ```. sc.pp.neighbors(). sc.tl.tsne(binarize=True). sc.tl.tsne(binarize=False). sc.pp.neighbors_tsne(). sc.tl.tsne(binarize=False). ```. on one of the standard scanpy datasets, like e.g. scanpy.datasets.pbmc3k_processed (used in scanpy tutorials such as https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:840,availability,cluster,cluster,840,"Indeed I did:. <details>. <summary>Plots</summary>. **UMAP weights, binarize=True**. ![image](https://user-images.githubusercontent.com/5758119/115158699-cfae3480-a08f-11eb-9b86-2803f6e91890.png). **UMAP weights, binarize=False**. ![image](https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png). **t-SNE weights**. ![image](https://user-images.githubusercontent.com/5758119/115158734-f5d3d480-a08f-11eb-9483-dfcca23ccafc.png). </details>. The differences between UMAP weights with and without binarization make sense: using the weights look like t-SNE using a smaller perplexity, compared to the uniform kernel, which tends to make things more compact. The only noticeable structural difference between the UMAP and t-SNE weights are that maybe the Megakaryocytes are a bit closer to the left cluster. But that's probably due to the larger number of neighbors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:840,deployability,cluster,cluster,840,"Indeed I did:. <details>. <summary>Plots</summary>. **UMAP weights, binarize=True**. ![image](https://user-images.githubusercontent.com/5758119/115158699-cfae3480-a08f-11eb-9b86-2803f6e91890.png). **UMAP weights, binarize=False**. ![image](https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png). **t-SNE weights**. ![image](https://user-images.githubusercontent.com/5758119/115158734-f5d3d480-a08f-11eb-9483-dfcca23ccafc.png). </details>. The differences between UMAP weights with and without binarization make sense: using the weights look like t-SNE using a smaller perplexity, compared to the uniform kernel, which tends to make things more compact. The only noticeable structural difference between the UMAP and t-SNE weights are that maybe the Megakaryocytes are a bit closer to the left cluster. But that's probably due to the larger number of neighbors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:102,usability,user,user-images,102,"Indeed I did:. <details>. <summary>Plots</summary>. **UMAP weights, binarize=True**. ![image](https://user-images.githubusercontent.com/5758119/115158699-cfae3480-a08f-11eb-9b86-2803f6e91890.png). **UMAP weights, binarize=False**. ![image](https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png). **t-SNE weights**. ![image](https://user-images.githubusercontent.com/5758119/115158734-f5d3d480-a08f-11eb-9483-dfcca23ccafc.png). </details>. The differences between UMAP weights with and without binarization make sense: using the weights look like t-SNE using a smaller perplexity, compared to the uniform kernel, which tends to make things more compact. The only noticeable structural difference between the UMAP and t-SNE weights are that maybe the Megakaryocytes are a bit closer to the left cluster. But that's probably due to the larger number of neighbors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:248,usability,user,user-images,248,"Indeed I did:. <details>. <summary>Plots</summary>. **UMAP weights, binarize=True**. ![image](https://user-images.githubusercontent.com/5758119/115158699-cfae3480-a08f-11eb-9b86-2803f6e91890.png). **UMAP weights, binarize=False**. ![image](https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png). **t-SNE weights**. ![image](https://user-images.githubusercontent.com/5758119/115158734-f5d3d480-a08f-11eb-9483-dfcca23ccafc.png). </details>. The differences between UMAP weights with and without binarization make sense: using the weights look like t-SNE using a smaller perplexity, compared to the uniform kernel, which tends to make things more compact. The only noticeable structural difference between the UMAP and t-SNE weights are that maybe the Megakaryocytes are a bit closer to the left cluster. But that's probably due to the larger number of neighbors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:379,usability,user,user-images,379,"Indeed I did:. <details>. <summary>Plots</summary>. **UMAP weights, binarize=True**. ![image](https://user-images.githubusercontent.com/5758119/115158699-cfae3480-a08f-11eb-9b86-2803f6e91890.png). **UMAP weights, binarize=False**. ![image](https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png). **t-SNE weights**. ![image](https://user-images.githubusercontent.com/5758119/115158734-f5d3d480-a08f-11eb-9483-dfcca23ccafc.png). </details>. The differences between UMAP weights with and without binarization make sense: using the weights look like t-SNE using a smaller perplexity, compared to the uniform kernel, which tends to make things more compact. The only noticeable structural difference between the UMAP and t-SNE weights are that maybe the Megakaryocytes are a bit closer to the left cluster. But that's probably due to the larger number of neighbors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:821,usability,close,closer,821,"Indeed I did:. <details>. <summary>Plots</summary>. **UMAP weights, binarize=True**. ![image](https://user-images.githubusercontent.com/5758119/115158699-cfae3480-a08f-11eb-9b86-2803f6e91890.png). **UMAP weights, binarize=False**. ![image](https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png). **t-SNE weights**. ![image](https://user-images.githubusercontent.com/5758119/115158734-f5d3d480-a08f-11eb-9483-dfcca23ccafc.png). </details>. The differences between UMAP weights with and without binarization make sense: using the weights look like t-SNE using a smaller perplexity, compared to the uniform kernel, which tends to make things more compact. The only noticeable structural difference between the UMAP and t-SNE weights are that maybe the Megakaryocytes are a bit closer to the left cluster. But that's probably due to the larger number of neighbors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:76,availability,error,error,76,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:82,integrability,messag,message,82,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:82,interoperability,messag,message,82,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:76,performance,error,error,76,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:76,safety,error,error,76,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:76,usability,error,error,76,"For some reason I don't see the figures here on the Github page (and get an error message when I click on the link), but they showed fine in the email notification I received. Looks good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:242,availability,error,error,242,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:311,availability,error,errors,311,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:302,deployability,contain,contains,302,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:248,integrability,messag,message,248,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:248,interoperability,messag,message,248,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:242,performance,error,error,242,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:311,performance,error,errors,311,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:242,safety,error,error,242,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:311,safety,error,errors,311,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:140,usability,user,user-images,140,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:242,usability,error,error,242,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:311,usability,error,errors,311,"The problem is not the collapsible thing. I still don't see the images here but only links instead, and when I click on a link e.g. https://user-images.githubusercontent.com/5758119/115158730-f0768a00-a08f-11eb-939a-1b9c35373fae.png I get an error message that the image cannot be displayed because it contains errors. Odd. Maybe it's something weird on my side.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:11,deployability,updat,updating,11,"Thanks for updating this! Just a heads up that it might be a little bit until I can give a full review. As a wider design question, would you want to allow using the other `Affinities` weightings from `openTSNE`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:11,safety,updat,updating,11,"Thanks for updating this! Just a heads up that it might be a little bit until I can give a full review. As a wider design question, would you want to allow using the other `Affinities` weightings from `openTSNE`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:96,safety,review,review,96,"Thanks for updating this! Just a heads up that it might be a little bit until I can give a full review. As a wider design question, would you want to allow using the other `Affinities` weightings from `openTSNE`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:11,security,updat,updating,11,"Thanks for updating this! Just a heads up that it might be a little bit until I can give a full review. As a wider design question, would you want to allow using the other `Affinities` weightings from `openTSNE`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:96,testability,review,review,96,"Thanks for updating this! Just a heads up that it might be a little bit until I can give a full review. As a wider design question, would you want to allow using the other `Affinities` weightings from `openTSNE`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:58,availability,ping,ping,58,Just got reminded of this PR... @ivirshup Should we maybe ping somebody else from the Scanpy team to join the discussion / review here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:123,safety,review,review,123,Just got reminded of this PR... @ivirshup Should we maybe ping somebody else from the Scanpy team to join the discussion / review here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:93,security,team,team,93,Just got reminded of this PR... @ivirshup Should we maybe ping somebody else from the Scanpy team to join the discussion / review here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:123,testability,review,review,123,Just got reminded of this PR... @ivirshup Should we maybe ping somebody else from the Scanpy team to join the discussion / review here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:53,modifiability,extens,extensively,53,"I've just seen a new really big/important study that extensively uses t-SNE visualization of ~500k cells (this is unusual as most papers in the field seem to be using UMAP nowadays), and they use Scanpy t-SNE with default parameters :-/ I think this highlights the importance of this PR. https://www.biorxiv.org/content/10.1101/2021.07.04.451050v1. I am going to CC @LuckyMD @giovp (apologies guys if it's not up your street).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:222,modifiability,paramet,parameters,222,"I've just seen a new really big/important study that extensively uses t-SNE visualization of ~500k cells (this is unusual as most papers in the field seem to be using UMAP nowadays), and they use Scanpy t-SNE with default parameters :-/ I think this highlights the importance of this PR. https://www.biorxiv.org/content/10.1101/2021.07.04.451050v1. I am going to CC @LuckyMD @giovp (apologies guys if it's not up your street).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:312,performance,content,content,312,"I've just seen a new really big/important study that extensively uses t-SNE visualization of ~500k cells (this is unusual as most papers in the field seem to be using UMAP nowadays), and they use Scanpy t-SNE with default parameters :-/ I think this highlights the importance of this PR. https://www.biorxiv.org/content/10.1101/2021.07.04.451050v1. I am going to CC @LuckyMD @giovp (apologies guys if it's not up your street).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:76,usability,visual,visualization,76,"I've just seen a new really big/important study that extensively uses t-SNE visualization of ~500k cells (this is unusual as most papers in the field seem to be using UMAP nowadays), and they use Scanpy t-SNE with default parameters :-/ I think this highlights the importance of this PR. https://www.biorxiv.org/content/10.1101/2021.07.04.451050v1. I am going to CC @LuckyMD @giovp (apologies guys if it's not up your street).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:294,deployability,API,API,294,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,deployability,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,deployability,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:294,integrability,API,API,294,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,integrability,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,integrability,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:294,interoperability,API,API,294,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,interoperability,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,interoperability,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,modifiability,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,modifiability,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:54,performance,time,time,54,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,reliability,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,reliability,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,security,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,security,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:391,testability,integr,integration,391,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:477,testability,integr,integration,477,"@ivirshup @giovp I'm wondering whether you've had the time to look over this. If this PR is maybe too big a change, then perhaps it would make more sense to migrate to openTSNE in a more iterative approach. For instance, we could just replace the t-SNE implementation to openTSNE, ignoring the API discussion and ignoring the precomputed graphs. I think switching to openTSNE, regardless of integration, would make the t-SNE implementation faster. We could then go for tighter integration step by step. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:0,deployability,Updat,Update,0,"Update here: I met @ivirshup at the SCG conference in Utrecht and we briefly chatted about this issue on the way to a pub. Isaac seemed supportive of the whole setup in this PR, which would allow to do this:. ``` Python. sc.pp.neighbors(). sc.tl.tsne() # default binarize='auto' resolves to binarize=True here. UMAP kNN graph but binary weights. sc.tl.tsne(binarize=False) # this would use UMAP weights but normalize to sum to 1. sc.pp.neighbors_tsne(). sc.tl.tsne() # default binarize='auto' resolves to binarize=False here. ```. As @pavlin-policar showed above, these three t-SNE calls yield very similar embeddings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:118,integrability,pub,pub,118,"Update here: I met @ivirshup at the SCG conference in Utrecht and we briefly chatted about this issue on the way to a pub. Isaac seemed supportive of the whole setup in this PR, which would allow to do this:. ``` Python. sc.pp.neighbors(). sc.tl.tsne() # default binarize='auto' resolves to binarize=True here. UMAP kNN graph but binary weights. sc.tl.tsne(binarize=False) # this would use UMAP weights but normalize to sum to 1. sc.pp.neighbors_tsne(). sc.tl.tsne() # default binarize='auto' resolves to binarize=False here. ```. As @pavlin-policar showed above, these three t-SNE calls yield very similar embeddings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:0,safety,Updat,Update,0,"Update here: I met @ivirshup at the SCG conference in Utrecht and we briefly chatted about this issue on the way to a pub. Isaac seemed supportive of the whole setup in this PR, which would allow to do this:. ``` Python. sc.pp.neighbors(). sc.tl.tsne() # default binarize='auto' resolves to binarize=True here. UMAP kNN graph but binary weights. sc.tl.tsne(binarize=False) # this would use UMAP weights but normalize to sum to 1. sc.pp.neighbors_tsne(). sc.tl.tsne() # default binarize='auto' resolves to binarize=False here. ```. As @pavlin-policar showed above, these three t-SNE calls yield very similar embeddings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:0,security,Updat,Update,0,"Update here: I met @ivirshup at the SCG conference in Utrecht and we briefly chatted about this issue on the way to a pub. Isaac seemed supportive of the whole setup in this PR, which would allow to do this:. ``` Python. sc.pp.neighbors(). sc.tl.tsne() # default binarize='auto' resolves to binarize=True here. UMAP kNN graph but binary weights. sc.tl.tsne(binarize=False) # this would use UMAP weights but normalize to sum to 1. sc.pp.neighbors_tsne(). sc.tl.tsne() # default binarize='auto' resolves to binarize=False here. ```. As @pavlin-policar showed above, these three t-SNE calls yield very similar embeddings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:542,security,polic,policar,542,"Update here: I met @ivirshup at the SCG conference in Utrecht and we briefly chatted about this issue on the way to a pub. Isaac seemed supportive of the whole setup in this PR, which would allow to do this:. ``` Python. sc.pp.neighbors(). sc.tl.tsne() # default binarize='auto' resolves to binarize=True here. UMAP kNN graph but binary weights. sc.tl.tsne(binarize=False) # this would use UMAP weights but normalize to sum to 1. sc.pp.neighbors_tsne(). sc.tl.tsne() # default binarize='auto' resolves to binarize=False here. ```. As @pavlin-policar showed above, these three t-SNE calls yield very similar embeddings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:136,usability,support,supportive,136,"Update here: I met @ivirshup at the SCG conference in Utrecht and we briefly chatted about this issue on the way to a pub. Isaac seemed supportive of the whole setup in this PR, which would allow to do this:. ``` Python. sc.pp.neighbors(). sc.tl.tsne() # default binarize='auto' resolves to binarize=True here. UMAP kNN graph but binary weights. sc.tl.tsne(binarize=False) # this would use UMAP weights but normalize to sum to 1. sc.pp.neighbors_tsne(). sc.tl.tsne() # default binarize='auto' resolves to binarize=False here. ```. As @pavlin-policar showed above, these three t-SNE calls yield very similar embeddings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/issues/1562:128,deployability,version,version,128,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:455,deployability,updat,update,455,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:128,integrability,version,version,128,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:128,modifiability,version,version,128,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:239,safety,valid,valid,239,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:455,safety,updat,update,455,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:455,security,updat,update,455,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:5,testability,understand,understand,5,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:263,usability,user,user-images,263,"If I understand correctly, pandas > 1.2.0 `plot.add_totals(sort='descending')` returns a different sorting compared to previous version. However, most of the categories have the same number of cells and thus a different sorting is equally valid. ![image](https://user-images.githubusercontent.com/4964309/104478840-0a9d5980-55c3-11eb-94b0-b0e2092c55c3.png). My suggestion is to use other dataset in which the number of cells per category is different and update the image.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1563:49,deployability,automat,automated,49,I like this idea a lot. I recently learned about automated linting and blacking of code per commit and have started using it for the single cell open problems project upon the suggestion of @scottgigante.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:49,testability,automat,automated,49,I like this idea a lot. I recently learned about automated linting and blacking of code per commit and have started using it for the single cell open problems project upon the suggestion of @scottgigante.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:35,usability,learn,learned,35,I like this idea a lot. I recently learned about automated linting and blacking of code per commit and have started using it for the single cell open problems project upon the suggestion of @scottgigante.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:224,deployability,automat,automatically,224,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:978,deployability,modul,module,978,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1292,energy efficiency,profil,profile,1292,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:192,interoperability,standard,standard,192,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:300,interoperability,format,format-yaml,300,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:127,modifiability,variab,variables,127,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:978,modifiability,modul,module,978,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1292,performance,profil,profile,1292,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:412,safety,prevent,prevented,412,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:653,safety,except,except,653,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:673,safety,except,exceptions,673,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:978,safety,modul,module,978,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:412,security,preven,prevented,412,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1251,security,iso,isort,1251,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:224,testability,automat,automatically,224,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:832,testability,hook,hooks,832,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1323,testability,plan,planed,1323,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:707,usability,help,helps,707,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1246,usability,tool,tool,1246,"@ivirshup . I'd recommend these:. - `mypy` for type checking (I've caught a few bugs using it). - `autoflake` to remove unused variables/imports (by default removes only imports from Python's standard library). - `yesqa` to automatically remove unused `# noqa` for flake8. - `check-yaml` and `pretty-format-yaml` I also found useful. - `requirements-txt-fixer` to sort the reqs. - `check-added-large-files` have prevented my from commiting some `.h5ad` files that shouldn't be there. - `rstcheck` to check the syntax of .rst files. - some flake8: `pytest-style` (enforces some pytest conventions, like non-returning fixtures beginning with `_`), `blind-except` (no blanket exceptions) and `comprehensions` (helps you rewrite comprehensions). Here's also an exhaustive list from which I picked the ones I use: https://pre-commit.com/hooks.html. As for any problems, some of them came from `rstcheck` as. `docs/source/classes.rst:9: (INFO/1) No directive entry for ""autoclass"" in module ""docutils.parsers.rst.languages.en"".`, that's why `.rstcheck.cfg` might be necessary. Also fixing types for `mypy` takes a while, I'd do it as last. Also `flake8-comprehensions` forces you to abandon `dict(foo=..., bar=...)` calls, unless you disable it. And `[tool.isort]` in `pyproject.toml` should have `profile = ""black""`. I had also planed to use `pylint` to enforce naming conventions, etc., but it has large overlap with `flake8` + the config file can be rather large, see https://gist.github.com/dkatz23238/08d79a76911ddaaa6171dff9cddd5772",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:142,interoperability,format,formatting,142,"I really don't want it to be mandatory. It is not a rational objection, i just prefer my code to be committed as i wrote it and then run some formatting scripts separately if needed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:79,usability,prefer,prefer,79,"I really don't want it to be mandatory. It is not a rational objection, i just prefer my code to be committed as i wrote it and then run some formatting scripts separately if needed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1944,availability,operat,operators,1944,"es `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good to document the escape hatches for this (`# fmt: off` for `black`). That said, we already do require that merged code goes through black before it gets merged, and a benefit of using this would be to not have commit messages like ""formatting"", ""remove unused import"", etc. The pre-commit checks would be a part of CI as well, so it would be *eventually* mandatory – just not on your machine. Does this address your concerns?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:228,deployability,configurat,configurations,228,"@michalk8 thanks for the extensive recommendations! I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:720,deployability,depend,dependencies,720,"@michalk8 thanks for the extensive recommendations! I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:950,deployability,releas,release,950,"@michalk8 thanks for the extensive recommendations! I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1704,deployability,instal,install,1704,"es `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good to document the escape hatches for this (`# fmt: off` for `black`). That said, we already do require that merged code goes through black before it gets merged, and a benefit of using this would be to not have commit messages like ""formatting"", ""remove unused import"", etc. The pre-commit checks would be a part of CI as well, so it would be *eventually* mandatory – just not on your machine. Does this address your concerns?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:1813,deployability,automat,automated,1813,"es `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good to document the escape hatches for this (`# fmt: off` for `black`). That said, we already do require that merged code goes through black before it gets merged, and a benefit of using this would be to not have commit messages like ""formatting"", ""remove unused import"", etc. The pre-commit checks would be a part of CI as well, so it would be *eventually* mandatory – just not on your machine. Does this address your concerns?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:292,energy efficiency,reduc,reducing,292,"@michalk8 thanks for the extensive recommendations! I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:311,energy efficiency,load,load,311,"@michalk8 thanks for the extensive recommendations! I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:695,energy efficiency,current,currently,695,"@michalk8 thanks for the extensive recommendations! I think I'd like to keep the number of tools used small. It's the worst when you want to fix a bug, but instead have to learn about configuring a linter. More tools means more configurations people need to be familiar with, and the goal is reducing cognitive load. > Also fixing types for `mypy` takes a while, I'd do it as last. Yeah, I figured this would be the case. Does `mypy` allow partial typing these days? Also, I haven't found the numpy or pandas type stubs to always be great. Have you run into problems around this? I think this would also need to wait at least until we can drop python 3.6 for `anndata`, since adding types there currently means circular dependencies. > `rstcheck` to check the syntax of .rst files. I would particularly like a linter for `rst`. I noticed you also had `doc8`, but you'd recommend `rstcheck` check over this? I'm a little worried, considering its last release was over a year ago. Spell check for prose in doc-strings could also be great, but I could see this being overzealous (is there a good way to notify about misspelled words, while not being annoying about technical terms?). I'm a little worried about some custom sphinx extensions we have, and conflicting with this, any experience here? --------------------------------------------. @Koncopd, I think I agree with your concern, as I said above: it's the worst when you want to fix a bug, but instead have to learn about configuring a linter. I also think it's very easy to add new checks, so someone complaining about new ones is valuable. Per commit, this should always be an option with `git commit --no-verify`, though you could also just not install `pre-commit`. I would like to keep the required checks limited, ideally formatting tasks that can be automated as opposed ""this is poor style"" warnings. I also know these tools can be wrong (e.g. `black` when expression's have many operators, sometimes with chaining) so it would be good ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
