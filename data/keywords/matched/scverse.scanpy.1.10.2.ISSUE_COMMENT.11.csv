id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/749:1925,performance,CPU,CPUDispatcher,1925,"his, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] During: typing of call at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3207,performance,error,errors,3207,"size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3377,performance,parallel,parallel,3377,"mpiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3432,performance,parallel,parallel,3432,"ree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is fallin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3497,performance,parallel,parallel,3497,"/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3569,performance,parallel,parallel,3569,"def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3682,performance,parallel,parallel,3682,"n3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/uma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3973,performance,parallel,parallel,3973,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4028,performance,parallel,parallel,4028,"using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4093,performance,parallel,parallel,4093,", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @num",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4165,performance,parallel,parallel,4165,"ate, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4281,performance,parallel,parallel,4281,"hon3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compila",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5661,performance,error,errors,5661,"n3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:1210,reliability,fail,failed,1210,"e is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] During: typing of call at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_siz",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3506,reliability,diagno,diagnostics,3506,"3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simpl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3583,reliability,diagno,diagnostics,3583,"an_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4102,reliability,diagno,diagnostics,4102,". @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4179,reliability,diagno,diagnostics,4179,"0):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4523,reliability,fail,failed,4523,"p://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8910,reliability,doe,does,8910,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:16,safety,except,exception,16,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply! Unfortunately , no visible exception... My code is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] Duri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:84,safety,error,error,84,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply! Unfortunately , no visible exception... My code is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] Duri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:194,safety,except,exception,194,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply! Unfortunately , no visible exception... My code is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] Duri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:665,safety,error,error,665,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply! Unfortunately , no visible exception... My code is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] Duri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:2845,safety,detect,detected,2845,"rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] During: typing of call at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3207,safety,error,errors,3207,"size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5340,safety,detect,detected,5340,"iz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5661,safety,error,errors,5661,"n3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6510,safety,detect,detected,6510,"haviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6679,safety,modul,module,6679,"onWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6988,safety,detect,detect,6988,"rse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8213,safety,log,logg,8213,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8228,safety,detect,detected,8228,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:2845,security,detect,detected,2845,"rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] During: typing of call at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rn",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5340,security,detect,detected,5340,"iz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6510,security,detect,detected,6510,"haviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6988,security,detect,detect,6988,"rse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8213,security,log,logg,8213,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8228,security,detect,detected,8228,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3506,testability,diagno,diagnostics,3506,"3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simpl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3583,testability,diagno,diagnostics,3583,"an_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbo",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4102,testability,diagno,diagnostics,4102,". @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). d",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4179,testability,diagno,diagnostics,4179,"0):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6580,testability,Trace,Traceback,6580,"_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6621,testability,Trace,Traceback,6621,"_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8213,testability,log,logg,8213,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:84,usability,error,error,84,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply! Unfortunately , no visible exception... My code is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] Duri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:665,usability,error,error,665,"> Do you get an exception message or something else? If you can also copy paste the error message here, we can debug it more easily. Many thanks for your quick reply! Unfortunately , no visible exception... My code is as follows:. ```py. import velocyto as vcy. import numpy as np. import scanpy as sc. import anndata. vlm = vcy.VelocytoLoom(""path of DentateGyrus.loom""). S = vlm.S. S=S.transpose(). adata = anndata.AnnData(S). print(adata.X). print(adata.obs). print(adata.var). sc.pp.neighbors(adata, n_neighbors=100). adata.uns['iroot'] = 0. print(adata.uns). sc.tl.dpt(adata, n_branchings=2). sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ```. error message (a number of warnings as well, taking up lots of lines and I have no idea of how to include all of them here...) :. <details><summary>numba warnings</summary>. ```pytb. WARNING: You’re trying to run this on 27998 dimensions of `.X`, if you really want this, set `use_rep='X'`. Falling back to preprocessing with `sc.pp.pca` and default params. /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py:450: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""make_euclidean_tree"" failed type inference due to: Cannot unify RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none) and RandomProjectionTreeNode(none, bool, array(float32, 1d, C), float64, RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none), RandomProjectionTreeNode(array(int64, 1d, C), bool, none, none, none, none)) for '$14.16', defined at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. [1] During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] Duri",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:2874,usability,behavi,behaviour,2874,"During: resolving callee type: recursive(type(CPUDispatcher(<function make_euclidean_tree at 0x7f822dd05d08>))). [2] During: typing of call at /home/liz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3017,usability,behavi,behaviour-when-using-jit,3017,"iz3/env/lib/python3.6/site-packages/umap/rp_tree.py (457). File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 457:. def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3207,usability,error,errors,3207,"size=30):. <source elided>. left_node = make_euclidean_tree(data, left_indices, rng_state, leaf_size). ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""make_euclidean_tree"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3564,usability,user,user,3564,"jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped globa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:3599,usability,help,help,3599,", indices, rng_state, leaf_size=30):. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/rp_tree.py"", line 451:. @numba.jit(). def make_euclidean_tree(data, indices, rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4160,usability,user,user,4160," rng_state, leaf_size=30):. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:4195,usability,help,help,4195,"ings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/nndescent.py:92: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/utils.py"", line 409:. @numba.njit(parallel=True). def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):. ^. current_graph, n_vertices, n_neighbors, max_candidates, rng_state. /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:588: NumbaPerformanceWarning: . The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible. To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help. File ""env/lib/python3.6/site-packages/umap/nndescent.py"", line 47:. @numba.njit(parallel=True). def nn_descent(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packag",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5369,usability,behavi,behaviour,5369,"kages/umap/umap_.py:349: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""fuzzy_simplicial_set"" failed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WAR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5512,usability,behavi,behaviour-when-using-jit,5512,"ailed type inference due to: Untyped global name 'nearest_neighbors': cannot determine Numba type of <class 'function'>. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:5661,usability,error,errors,5661,"n3.6/site-packages/umap/umap_.py"", line 467:. def fuzzy_simplicial_set(. <source elided>. if knn_indices is None or knn_dists is None:. knn_indices, knn_dists, _ = nearest_neighbors(. ^. @numba.jit(). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:725: NumbaWarning: Function ""fuzzy_simplicial_set"" was compiled in object mode without forceobj=True. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. self.func_ir.loc)). /home/liz3/env/lib/python3.6/site-packages/numba/compiler.py:734: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""env/lib/python3.6/site-packages/umap/umap_.py"", line 350:. @numba.jit(). def fuzzy_simplicial_set(. ^. warnings.warn(errors.NumbaDeprecationWarning(msg, self.func_ir.loc)). OrderedDict([('neighbors', {'params': {'n_neighbors': 100, 'method': 'umap', 'metric': 'euclidean'}, 'distances': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffus",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:6885,usability,tool,tools,6885,"'>'. 	with 1803087 stored elements in Compressed Sparse Row format>, 'connectivities': <18213x18213 sparse matrix of type '<class 'numpy.float64'>'. 	with 2667882 stored elements in Compressed Sparse Row format>}), ('iroot', 0)]). WARNING: Trying to run `tl.dpt` without prior call of `tl.diffmap`. Falling back to `tl.diffmap` with default parameters. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segme",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:7233,usability,tool,tools,7233,"ers. WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: shifting branching point away from maximal kendall-tau correlation (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:7443,usability,tool,tools,7443," (suppress this with `allow_kendall_tau_shift=False`). WARNING: detected group with only [] cells. ```. </details>. <details><summary>Traceback</summary>. ```pytb. ValueError Traceback (most recent call last). ~/diffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.sha",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:7657,usability,tool,tools,7657,"ffusion_map.py in <module>. 57 adata.uns['iroot'] = 0. 58 print(adata.uns). ---> 59 sc.tl.dpt(adata, n_branchings=2). 60 sc.pl.diffmap(adata, color='dpt_pseudotime', projection='2d'). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in dpt(adata, n_dcs, n_branchings, min_group_size, allow_kendall_tau_shift, copy). 128 # detect branchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8098,usability,tool,tools,8098,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8145,usability,tip,tips,8145,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8329,usability,tip,tips,8329,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:8378,usability,tip,tips,8378,"ranchings and partition the data into segments. 129 if n_branchings > 0:. --> 130 dpt.branchings_segments(). 131 adata.obs['dpt_groups'] = pd.Categorical(. 132 values=dpt.segs_names.astype('U'),. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in branchings_segments(self). 187 for each segment. 188 """""". --> 189 self.detect_branchings(). 190 self.postprocess_segments(). 191 self.set_segs_names(). ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branchings(self). 262 segs_connects,. 263 segs_undecided,. --> 264 segs_adjacency, iseg, tips3). 265 # store as class members. 266 self.segs = segs. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in detect_branching(self, segs, segs_tips, segs_connects, segs_undecided, segs_adjacency, iseg, tips3). 476 # branching on the segment, return the list ssegs of segments that. 477 # are defined by splitting this segment. --> 478 result = self._detect_branching(Dseg, tips3, seg). 479 ssegs, ssegs_tips, ssegs_adjacency, ssegs_connects, trunk = result. 480 # map back to global indices. ~/env/lib/python3.6/site-packages/scanpy/tools/_dpt.py in _detect_branching(self, Dseg, tips, seg_reference). 646 if len(np.flatnonzero(newseg)) <= 1:. 647 logg.warning(f'detected group with only {np.flatnonzero(newseg)} cells'). --> 648 secondtip = newseg[np.argmax(Dseg[tips[inewseg]][newseg])]. 649 ssegs_tips.append([tips[inewseg], secondtip]). 650 undecided_cells = np.arange(Dseg.shape[0], dtype=int)[nonunique]. ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in argmax(a, axis, out). 1101 . 1102 """""". -> 1103 return _wrapfunc(a, 'argmax', axis=axis, out=out). 1104 . 1105 . ~/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 54 def _wrapfunc(obj, method, *args, **kwds):. 55 try:. ---> 56 return getattr(obj, method)(*args, **kwds). 57 . 58 # An AttributeError occurs if the object does not have. ValueError: attempt to get argmax of an empty sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:19,availability,error,error,19,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:10,performance,parallel,parallel,10,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:19,performance,error,error,19,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:19,safety,error,error,19,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:19,usability,error,error,19,The Numba parallel error also occurred to me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:99,integrability,sub,subsample,99,"This issue is still persistent. I've created a colab notebook that shows the issue on a dataset we subsample to 6000 cells:. https://colab.research.google.com/drive/1QrnDFZ7nDNOLx9gr92eknhKShd2aTIdN. @gokceneraslan can you please throw a ""bug"" tag on this issue so it gets put in the queue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:284,integrability,queue,queue,284,"This issue is still persistent. I've created a colab notebook that shows the issue on a dataset we subsample to 6000 cells:. https://colab.research.google.com/drive/1QrnDFZ7nDNOLx9gr92eknhKShd2aTIdN. @gokceneraslan can you please throw a ""bug"" tag on this issue so it gets put in the queue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:284,performance,queue,queue,284,"This issue is still persistent. I've created a colab notebook that shows the issue on a dataset we subsample to 6000 cells:. https://colab.research.google.com/drive/1QrnDFZ7nDNOLx9gr92eknhKShd2aTIdN. @gokceneraslan can you please throw a ""bug"" tag on this issue so it gets put in the queue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:111,availability,error,error,111,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:38,energy efficiency,cloud,cloudstor,38,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:111,performance,error,error,111,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:216,reliability,diagno,diagnosis,216,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:111,safety,error,error,111,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:216,testability,diagno,diagnosis,216,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:111,usability,error,error,111,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:206,usability,help,help,206,"[Here's the `AnnData` object](https://cloudstor.aarnet.edu.au/plus/s/oYjEB26gWJdaA4R) which will reproduce the error if you call: `sc.tl.dpt(adata, n_branchings=N)` where N > 3. @falexwolf, maybe you could help with diagnosis here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/749:61,testability,trace,traceback,61,"Hi everyone, I am having the same issue, with the exact same traceback. Was this ever solved or addressed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/749
https://github.com/scverse/scanpy/issues/750:161,energy efficiency,heat,heatmap,161,"Default parameter was set for use_raw in each cases. They were the same. 1e7 is a so large value that it is not proportional to 0, 1, 2, 3 4. I doubt that sc.pl.heatmap treats some genes with a certain name and expression value as special characters or exception values. In the above images, if I remove “Sct"" from the marker gene list, then another gene which works well before the remove would has the similar issue ! Now look carefully at the above heatmap, you can see that at the bottom of the heatmap, Sct show a very high expression value (it's very thin perhaps you cannot see it).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:452,energy efficiency,heat,heatmap,452,"Default parameter was set for use_raw in each cases. They were the same. 1e7 is a so large value that it is not proportional to 0, 1, 2, 3 4. I doubt that sc.pl.heatmap treats some genes with a certain name and expression value as special characters or exception values. In the above images, if I remove “Sct"" from the marker gene list, then another gene which works well before the remove would has the similar issue ! Now look carefully at the above heatmap, you can see that at the bottom of the heatmap, Sct show a very high expression value (it's very thin perhaps you cannot see it).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:499,energy efficiency,heat,heatmap,499,"Default parameter was set for use_raw in each cases. They were the same. 1e7 is a so large value that it is not proportional to 0, 1, 2, 3 4. I doubt that sc.pl.heatmap treats some genes with a certain name and expression value as special characters or exception values. In the above images, if I remove “Sct"" from the marker gene list, then another gene which works well before the remove would has the similar issue ! Now look carefully at the above heatmap, you can see that at the bottom of the heatmap, Sct show a very high expression value (it's very thin perhaps you cannot see it).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:8,modifiability,paramet,parameter,8,"Default parameter was set for use_raw in each cases. They were the same. 1e7 is a so large value that it is not proportional to 0, 1, 2, 3 4. I doubt that sc.pl.heatmap treats some genes with a certain name and expression value as special characters or exception values. In the above images, if I remove “Sct"" from the marker gene list, then another gene which works well before the remove would has the similar issue ! Now look carefully at the above heatmap, you can see that at the bottom of the heatmap, Sct show a very high expression value (it's very thin perhaps you cannot see it).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:253,safety,except,exception,253,"Default parameter was set for use_raw in each cases. They were the same. 1e7 is a so large value that it is not proportional to 0, 1, 2, 3 4. I doubt that sc.pl.heatmap treats some genes with a certain name and expression value as special characters or exception values. In the above images, if I remove “Sct"" from the marker gene list, then another gene which works well before the remove would has the similar issue ! Now look carefully at the above heatmap, you can see that at the bottom of the heatmap, Sct show a very high expression value (it's very thin perhaps you cannot see it).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:58,deployability,scale,scale,58,I did not see the 1e7. It seems that the heatmap colormap scale is just off then. Not sure how to change that though... @fidelram? I'm not sure what I'm meant to be looking for that is very thin otherwise...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:41,energy efficiency,heat,heatmap,41,I did not see the 1e7. It seems that the heatmap colormap scale is just off then. Not sure how to change that though... @fidelram? I'm not sure what I'm meant to be looking for that is very thin otherwise...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:58,energy efficiency,scale,scale,58,I did not see the 1e7. It seems that the heatmap colormap scale is just off then. Not sure how to change that though... @fidelram? I'm not sure what I'm meant to be looking for that is very thin otherwise...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:58,modifiability,scal,scale,58,I did not see the 1e7. It seems that the heatmap colormap scale is just off then. Not sure how to change that though... @fidelram? I'm not sure what I'm meant to be looking for that is very thin otherwise...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:58,performance,scale,scale,58,I did not see the 1e7. It seems that the heatmap colormap scale is just off then. Not sure how to change that though... @fidelram? I'm not sure what I'm meant to be looking for that is very thin otherwise...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:81,deployability,version,version,81,"This is strange and I had not seen it before. Maybe something related to a newer version of `matplotlib`? . You can fix the problem by doing sc.pl.heatmap(...., vmax=7). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:147,energy efficiency,heat,heatmap,147,"This is strange and I had not seen it before. Maybe something related to a newer version of `matplotlib`? . You can fix the problem by doing sc.pl.heatmap(...., vmax=7). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:81,integrability,version,version,81,"This is strange and I had not seen it before. Maybe something related to a newer version of `matplotlib`? . You can fix the problem by doing sc.pl.heatmap(...., vmax=7). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/750:81,modifiability,version,version,81,"This is strange and I had not seen it before. Maybe something related to a newer version of `matplotlib`? . You can fix the problem by doing sc.pl.heatmap(...., vmax=7). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/750
https://github.com/scverse/scanpy/issues/751:552,availability,error,error,552,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:391,energy efficiency,load,load,391,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:494,energy efficiency,load,load,494,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:918,integrability,filter,filter,918,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1031,integrability,filter,filter,1031,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1287,integrability,sub,subscribed,1287,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:932,interoperability,format,format,932,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1045,interoperability,format,format,1045,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:391,performance,load,load,391,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:494,performance,load,load,494,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:552,performance,error,error,552,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:552,safety,error,error,552,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:552,usability,error,error,552,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/751:1200,usability,help,help,1200,"sudo rm /media/ubuntu/d0b69706-4d42-40a3-b531-382041477d35/home/cns/biosoft/cellranger/cellranger-3.0.2/deng2_count_myself -fr. At 2019-07-27 18:48:50, ""Cristian"" <notifications@github.com> wrote:. Good day! I have been trying to run the single cell tutorial but have had some issues concatenating several datasets. I am able to read successfully the first data set. However, once I want to load the other datasets, there is a problem concatenating the files. This happens in the first loop to load all the datasets. If I run only one dataset the same error (unsupported operand type(s) for +: 'int' and 'str') showed up when I plot some data quality summary plots:. For instance:. p1 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac') p2 = sc.pl.scatter(adata[adata.obs['n_counts']<10000], 'n_counts', 'n_genes', color='mt_frac'). adata = adata[adata.obs['mt_frac'] < 0.2] print('Number of cells after MT filter: {:d}'.format(adata.n_obs)). sc.pp.filter_cells(adata, min_genes = 700) print('Number of cells after gene filter: {:d}'.format(adata.n_obs)). I am using data generated by 10x V3 and CellRanger v3.0.1. I really do not know where the problem is. I really appreciate any advice/help to solve this issue. Thanks in advance. —. You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/751
https://github.com/scverse/scanpy/issues/752:41,availability,avail,available,41,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:22,deployability,build,build,22,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:41,reliability,availab,available,41,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:41,safety,avail,available,41,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:41,security,availab,available,41,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/752:73,usability,close,closed,73,@ivirshup I fixed the build it should be available now. The issue can be closed.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/752
https://github.com/scverse/scanpy/issues/753:57,interoperability,specif,specify,57,This is a consequence of our rec-arrays where we have to specify the length of strings. I think it would be safe to calculate the maximum length of a gene name instead of using a hard coded value.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:108,safety,safe,safe,108,This is a consequence of our rec-arrays where we have to specify the length of strings. I think it would be safe to calculate the maximum length of a gene name instead of using a hard coded value.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:143,energy efficiency,reduc,reduce,143,"It'll take a little doing, but it's certainly do-able. Something like this should do it:. ```python. import numpy as np. from functools import reduce. def concat(arrays: ""list[np.recarray]""):. names = arrays[0].dtype.names. dtypes = [dict(a.dtype.descr) for a in arrays]. assert all(arrays[0].dtype.names == a.dtype.names for a in arrays[1:]), ""All arrays should have same names"". . offset = 0. out_dtypes = {}. for k in names:. out_dtype = reduce(np.result_type, (dtype[k] for dtype in dtypes)). out_dtypes[k] = (out_dtype, offset). offset += out_dtype.alignment. out_recarray = np.recarray(sum(map(len, arrays)), dtype=out_dtypes) . np.concatenate(arrays, out=out_recarray). . return out_recarray. ```. Maybe the solution should happen upstream though. . Do we concatenate recarrays often?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:441,energy efficiency,reduc,reduce,441,"It'll take a little doing, but it's certainly do-able. Something like this should do it:. ```python. import numpy as np. from functools import reduce. def concat(arrays: ""list[np.recarray]""):. names = arrays[0].dtype.names. dtypes = [dict(a.dtype.descr) for a in arrays]. assert all(arrays[0].dtype.names == a.dtype.names for a in arrays[1:]), ""All arrays should have same names"". . offset = 0. out_dtypes = {}. for k in names:. out_dtype = reduce(np.result_type, (dtype[k] for dtype in dtypes)). out_dtypes[k] = (out_dtype, offset). offset += out_dtype.alignment. out_recarray = np.recarray(sum(map(len, arrays)), dtype=out_dtypes) . np.concatenate(arrays, out=out_recarray). . return out_recarray. ```. Maybe the solution should happen upstream though. . Do we concatenate recarrays often?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/753:272,testability,assert,assert,272,"It'll take a little doing, but it's certainly do-able. Something like this should do it:. ```python. import numpy as np. from functools import reduce. def concat(arrays: ""list[np.recarray]""):. names = arrays[0].dtype.names. dtypes = [dict(a.dtype.descr) for a in arrays]. assert all(arrays[0].dtype.names == a.dtype.names for a in arrays[1:]), ""All arrays should have same names"". . offset = 0. out_dtypes = {}. for k in names:. out_dtype = reduce(np.result_type, (dtype[k] for dtype in dtypes)). out_dtypes[k] = (out_dtype, offset). offset += out_dtype.alignment. out_recarray = np.recarray(sum(map(len, arrays)), dtype=out_dtypes) . np.concatenate(arrays, out=out_recarray). . return out_recarray. ```. Maybe the solution should happen upstream though. . Do we concatenate recarrays often?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/753
https://github.com/scverse/scanpy/issues/754:1562,availability,operat,operations,1562,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:721,deployability,log,logfoldchanges,721,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1093,deployability,log,logfoldchanges,1093,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1458,deployability,log,log,1458,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:721,safety,log,logfoldchanges,721,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1093,safety,log,logfoldchanges,1093,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1458,safety,log,log,1458,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:721,security,log,logfoldchanges,721,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1093,security,log,logfoldchanges,1093,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1458,security,log,log,1458,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:721,testability,log,logfoldchanges,721,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1093,testability,log,logfoldchanges,1093,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1458,testability,log,log,1458,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/754:1486,usability,close,close,1486,"A quick reproducible example:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X. sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""Dendritic"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_d = ( . sc.get.rank_genes_groups_df(pbmc, group=""CD14+ Monocyte"") . .set_index(""names"", drop=False) . ) . . sc.tl.rank_genes_groups( . pbmc, . groupby=""bulk_labels"", . groups=[""CD14+ Monocyte"", ""Dendritic""], . reference=""CD14+ Monocyte"", . n_genes=pbmc.shape[1], . method='wilcoxon' . ) . md_m = ( . sc.get.rank_genes_groups_df(pbmc, group=""Dendritic"") . .set_index(""names"", drop=False) . ). md_d.head(). # scores names logfoldchanges pvals pvals_adj. # names . # FTL 13.163277 FTL 1.600541 1.427571e-39 1.092092e-36. # AIF1 12.768205 AIF1 1.882886 2.467807e-37 9.439361e-35. # FCGR3A 12.733917 FCGR3A 4.500901 3.831234e-37 9.769647e-35. # PSAP 12.576810 PSAP 1.998426 2.832393e-36 5.416951e-34. # FCER1G 12.152568 FCER1G 1.596950 5.559192e-34 8.505565e-32. md_m.tail()[::-1]. # scores names logfoldchanges pvals pvals_adj. # names . # FTL -12.616215 FTL -1.600541 1.718871e-36 1.314936e-33. # FCGR3A -12.204766 FCGR3A -4.500901 2.931495e-34 7.919483e-32. # AIF1 -12.176620 AIF1 -1.882886 4.140906e-34 7.919483e-32. # PSAP -12.115210 PSAP -1.998426 8.773953e-34 1.342415e-31. # FCER1G -11.519019 FCER1G -1.596950 1.058089e-30 8.094380e-29. ```. I think the log fold changes are pretty close, and those small changes could be occurring due to different order of operations and the use of single precision. I'm not to worried about these. . Could someone more familiar with the differential expression code comment about p-value correctness? @falexwolf @a-munoz-rojas? A few of the values look pretty different.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/754
https://github.com/scverse/scanpy/issues/755:21,availability,cluster,clustering,21,seems like 'louvain' clustering is not yet computed. You compute it by doing. ```PYTHON. sc.tl.louvain(adata). ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/755:21,deployability,cluster,clustering,21,seems like 'louvain' clustering is not yet computed. You compute it by doing. ```PYTHON. sc.tl.louvain(adata). ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/755
https://github.com/scverse/scanpy/issues/756:679,energy efficiency,load,loading,679,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:97,modifiability,deco,decorator,97,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:710,modifiability,deco,decorators,710,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:159,performance,cach,caches,159,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:566,performance,network,networkx,566,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:679,performance,load,loading,679,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:839,performance,network,networkx,839,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:566,security,network,networkx,566,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:839,security,network,networkx,839,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:482,usability,interact,interactive,482,"The biggest ones are in order:. 1. [ ] `numba`: Hard to defer. We’d have to create our own `jit` decorator returning a callable object that numba-compiles and caches the real function on its first invocation. 2. ~~`pandas`~~: Used all over the place, not feasible to defer. 3. [x] `sklearn.metrics`: Easy to defer I think, let’s start with this. 4. [ ] `matplotlib.pyplot`: Shouldn’t be used in a library at all. It exists to import the kitchen sink in order to be low-friction for interactive use. Hard to do since we rely on it a lot, but we should do it. 5. [x] `networkx`: Used in DPT, paga and plotting. Pretty easy. We use pandas all over the place, and it’s hard to defer loading numba as it works with decorators. /edit: shaved off another 2/5 in a7729bc61ac569a718075edb4466852b0b4a696a via `sklearn.metrics`, `scipy.stats`, and `networkx`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:204,deployability,Manag,Management,204,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:513,deployability,depend,depending,513,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:74,energy efficiency,core,core,74,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:204,energy efficiency,Manag,Management,204,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:513,integrability,depend,depending,513,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:230,modifiability,variab,variables,230,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:513,modifiability,depend,depending,513,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:374,performance,time,times,374,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:500,performance,time,times,500,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:157,reliability,doe,does,157,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:204,safety,Manag,Management,204,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:513,safety,depend,depending,513,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:513,testability,depend,depending,513,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:411,usability,interact,interactive,411,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:526,usability,interact,interactive,526,"I don't think we should bother with numba, since it'll likely be a pretty core requirement once we can start transitioning to `pydata/sparse`. For `pyplot`, does `matplotlib` also take a while to import? Management of environment variables is a good reason not to defer that import. If we're already using `h5py`, could we drop `tables` as a requirement? I think bad import times are only really noticeable for interactive use, since any script using scanpy will likely take longer to run. Do import times change depending on interactive environment? I wouldn't be surprised if different code ran when importing something like matplotlib in a notebook vs in a script.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:160,deployability,modul,module,160,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:263,energy efficiency,measur,measure,263,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:102,modifiability,variab,variables,102,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:160,modifiability,modul,module,160,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:34,performance,time,time,34,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:226,performance,time,times,226,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:160,safety,modul,module,160,"Matplotlib takes a while but less time. Can you please point me to what you mean with the environment variables? No idea about tables, @falexwolf wrote the sim module I think and it’s not commonly used …. I don’t think import times change noticably, but I didn’t measure.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:359,availability,state,state,359,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:278,deployability,depend,depending,278,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:278,integrability,depend,depending,278,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:359,integrability,state,state,359,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:249,modifiability,pac,packages,249,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:278,modifiability,depend,depending,278,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:12,safety,compl,complaints,12,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:278,safety,depend,depending,278,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:12,security,compl,complaints,12,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:278,testability,depend,depending,278,"I've gotten complaints from Matplotlib about calling `mpl.use`, to set the backend after importing `pyplot` ([relevant matplotlib docs](https://matplotlib.org/tutorials/introductory/usage.html#what-is-a-backend)). I think it would be unintuitive if packages behaved differently depending on what functions had been called. In general, matplotlib has a lot of state and messing with it has only brought me pain.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:64,availability,state,state,64,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:514,deployability,api,api,514,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:587,deployability,api,api,587,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:64,integrability,state,state,64,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:420,integrability,configur,configure,420,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:514,integrability,api,api,514,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:587,integrability,api,api,587,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:514,interoperability,api,api,514,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:587,interoperability,api,api,587,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:48,modifiability,pac,packages,48,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:420,modifiability,configur,configure,420,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:118,safety,test,testing,118,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:257,safety,test,tests,257,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:57,security,modif,modify,57,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:420,security,configur,configure,420,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:118,testability,test,testing,118,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:257,testability,test,tests,257,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:336,usability,user,user,336,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:600,usability,interact,interactive,600,"That’s exactly backwards: I find it annoying if packages modify state on import. We already jump through hoops in our testing framework to work around our misbehavior:. https://github.com/theislab/scanpy/blob/681ce93e7e58956cb78ef81bc165558b84d6ebb0/scanpy/tests/conftest.py#L4-L6. `import matplotlib.pyplot [as plt]` means “I’m an end user who just opened a notebook and I want the kitchen sink, give me everything and configure everything”. Libraries shouldn’t do it and scanpy is one. When we still had `scanpy.api` there would have been a case for importing pyplot there, as `scanpy.api` was for interactive use. Now we don’t have any excuses.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:41,availability,state,state,41,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:87,availability,state,state,87,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:495,deployability,depend,depend,495,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:41,integrability,state,state,41,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:87,integrability,state,state,87,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:495,integrability,depend,depend,495,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:495,modifiability,depend,depend,495,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:197,performance,time,time,197,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:495,safety,depend,depend,495,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:34,security,modif,modify,34,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:80,security,modif,modify,80,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:495,testability,depend,depend,495,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:22,usability,behavi,behavior,22,"I agree that it's bad behavior to modify state on import. I think it's worse to modify state after a function is called, save a few cases where it's obvious that will happen. I think it takes less time to figure out why my plot suddenly looks different if it's based on imports than which functions were called prior. I think if we could make all of our plots without importing `pyplot` that would be great. I'm not sure how feasible this is. Not only do we use `pyplot` a lot, but libraries we depend on for plots (like `seaborn`) import `pyplot`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/756:35,usability,user,user-images,35,"Newest numbers:. ![grafik](https://user-images.githubusercontent.com/291575/70558670-9ef9e900-1b85-11ea-8b09-f510f3598580.png). scipy.stats is still a big chunk, but we can’t ignore it easily due to all the sklearn imports.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/756
https://github.com/scverse/scanpy/issues/757:253,modifiability,variab,variable,253,"Reproducible example:. ```python. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.mnn_correct(pbmc, batch_key=""phase""). ```. It looks like `mnn_correct` is only returning one variable, through its documentation looks like it should return three. @chriscainx, could you offer some guidance here? As a workaround for now, you could just call `mnnpy.mnn_correct` with the same signature you've been using. It'll return a one-tuple with a modified anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:452,security,sign,signature,452,"Reproducible example:. ```python. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.mnn_correct(pbmc, batch_key=""phase""). ```. It looks like `mnn_correct` is only returning one variable, through its documentation looks like it should return three. @chriscainx, could you offer some guidance here? As a workaround for now, you could just call `mnnpy.mnn_correct` with the same signature you've been using. It'll return a one-tuple with a modified anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:513,security,modif,modified,513,"Reproducible example:. ```python. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.mnn_correct(pbmc, batch_key=""phase""). ```. It looks like `mnn_correct` is only returning one variable, through its documentation looks like it should return three. @chriscainx, could you offer some guidance here? As a workaround for now, you could just call `mnnpy.mnn_correct` with the same signature you've been using. It'll return a one-tuple with a modified anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:275,usability,document,documentation,275,"Reproducible example:. ```python. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.mnn_correct(pbmc, batch_key=""phase""). ```. It looks like `mnn_correct` is only returning one variable, through its documentation looks like it should return three. @chriscainx, could you offer some guidance here? As a workaround for now, you could just call `mnnpy.mnn_correct` with the same signature you've been using. It'll return a one-tuple with a modified anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:358,usability,guidanc,guidance,358,"Reproducible example:. ```python. import scanpy as sc. import scanpy.external as ice. from itertools import cycle. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.mnn_correct(pbmc, batch_key=""phase""). ```. It looks like `mnn_correct` is only returning one variable, through its documentation looks like it should return three. @chriscainx, could you offer some guidance here? As a workaround for now, you could just call `mnnpy.mnn_correct` with the same signature you've been using. It'll return a one-tuple with a modified anndata object.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:88,availability,error,errors,88,"@ivirshup Sorry I need to correct my previous answer. `mnnpy.mnn_correct` is not giving errors, but is returning a tuple. Check my issue here https://github.com/chriscainx/mnnpy/issues/27",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:88,performance,error,errors,88,"@ivirshup Sorry I need to correct my previous answer. `mnnpy.mnn_correct` is not giving errors, but is returning a tuple. Check my issue here https://github.com/chriscainx/mnnpy/issues/27",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:88,safety,error,errors,88,"@ivirshup Sorry I need to correct my previous answer. `mnnpy.mnn_correct` is not giving errors, but is returning a tuple. Check my issue here https://github.com/chriscainx/mnnpy/issues/27",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:88,usability,error,errors,88,"@ivirshup Sorry I need to correct my previous answer. `mnnpy.mnn_correct` is not giving errors, but is returning a tuple. Check my issue here https://github.com/chriscainx/mnnpy/issues/27",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:23,availability,error,error,23,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png). ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:23,performance,error,error,23,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png). ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:23,safety,error,error,23,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png). ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:23,usability,error,error,23,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png). ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:47,usability,user,user-images,47,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png). ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:159,usability,user,user-images,159,I also got the similar error. ![image](https://user-images.githubusercontent.com/49429496/66826207-8652c580-ef7e-11e9-9168-5c19aa666354.png). ![image](https://user-images.githubusercontent.com/49429496/66826292-bd28db80-ef7e-11e9-801e-1d2dfbf01cb8.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:60,deployability,version,version,60,See above and use `mnnpy.mnn_correct()` the scanpy external version seems to no longer be maintained and is out of date.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:60,integrability,version,version,60,See above and use `mnnpy.mnn_correct()` the scanpy external version seems to no longer be maintained and is out of date.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:60,modifiability,version,version,60,See above and use `mnnpy.mnn_correct()` the scanpy external version seems to no longer be maintained and is out of date.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:90,modifiability,maintain,maintained,90,See above and use `mnnpy.mnn_correct()` the scanpy external version seems to no longer be maintained and is out of date.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:90,safety,maintain,maintained,90,See above and use `mnnpy.mnn_correct()` the scanpy external version seems to no longer be maintained and is out of date.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:14,modifiability,maintain,maintained,14,"Why is it not maintained? If it doesn’t work, that’s a bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:32,reliability,doe,doesn,32,"Why is it not maintained? If it doesn’t work, that’s a bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:14,safety,maintain,maintained,14,"Why is it not maintained? If it doesn’t work, that’s a bug.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:125,deployability,version,version,125,This issue has existed for quite a while now. So I've been using `mnnpy` directly. I would have expected the scanpy external version to work in the same way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:125,integrability,version,version,125,This issue has existed for quite a while now. So I've been using `mnnpy` directly. I would have expected the scanpy external version to work in the same way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:125,modifiability,version,version,125,This issue has existed for quite a while now. So I've been using `mnnpy` directly. I would have expected the scanpy external version to work in the same way.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:211,deployability,API,API,211,"Actually this is almost not a bug. The first line of mnn_correct is `if len(datas) < 2: return datas`. So we’re just holding it wrong, and it’d work if we passed it a list of anndatas as intended. Why isn’t the API `mnn_correct(adata: AnnData, batch_key: str, *, ...)`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:211,integrability,API,API,211,"Actually this is almost not a bug. The first line of mnn_correct is `if len(datas) < 2: return datas`. So we’re just holding it wrong, and it’d work if we passed it a list of anndatas as intended. Why isn’t the API `mnn_correct(adata: AnnData, batch_key: str, *, ...)`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/757:211,interoperability,API,API,211,"Actually this is almost not a bug. The first line of mnn_correct is `if len(datas) < 2: return datas`. So we’re just holding it wrong, and it’d work if we passed it a list of anndatas as intended. Why isn’t the API `mnn_correct(adata: AnnData, batch_key: str, *, ...)`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/757
https://github.com/scverse/scanpy/issues/758:19,availability,error,error,19,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:256,availability,error,error,256,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:385,availability,error,error,385,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:541,integrability,batch,batch,541,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:646,integrability,batch,batches,646,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:56,interoperability,specif,specified,56,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:19,performance,error,error,19,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:256,performance,error,error,256,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:385,performance,error,error,385,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:541,performance,batch,batch,541,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:646,performance,batch,batches,646,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:471,reliability,doe,does,471,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:19,safety,error,error,19,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:256,safety,error,error,256,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:385,safety,error,error,385,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:19,usability,error,error,19,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:256,usability,error,error,256,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:385,usability,error,error,385,"It looks like this error occurs whenever `batch_key` is specified and `inplace=False`. MCVE:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.X = pbmc.raw.X # So we have reasonable values to calculate on. # These do not throw an error:. sc.pp.highly_variable_genes(pbmc, batch_key=""phase""). sc.pp.highly_variable_genes(pbmc, inplace=False). # This throws an error. sc.pp.highly_variable_genes(pbmc, batch_key=""phase"", inplace=False). ```. This does raise the question of what `inplace=False` should return for the batch case. I'd think a recarray (maybe this should change to a dataframe?) with metrics for each of the batches. You could end up with columns with names like: `means_{batch1}`, `dispersions_{batch1}` etc. @danielStrobl, what were you expecting this to return?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:35,deployability,version,version,35,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:286,deployability,version,versions,286,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:35,integrability,version,version,35,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:73,integrability,batch,batch,73,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:244,integrability,filter,filtering,244,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:280,integrability,batch,batch,280,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:286,integrability,version,versions,286,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:315,integrability,filter,filtered,315,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:383,integrability,batch,batch,383,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:35,modifiability,version,version,35,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:286,modifiability,version,versions,286,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:73,performance,batch,batch,73,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:280,performance,batch,batch,280,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/758:383,performance,batch,batch,383,"There is a further issue with this version of the function as well. If a batch has 0 variance for multiple genes, then the `_highly_variable_genes_single_batch()` function will not work on this. Thus, it would be good to have some sort of gene filtering before running the single batch versions. Everything that is filtered out, would then just get a `nan` dispersion value for that batch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/758
https://github.com/scverse/scanpy/issues/759:124,deployability,API,API,124,"Regarding 1, I think this is a good idea. I've thought this would be a better solution to #709. What do you think the right API would be for this? Ideally, I think this should be a single argument. As a work-around, you could do something like this:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). ax = sc.pl.umap(pbmc, size=100, show=False). sc.pl.umap(. pbmc[pbmc.obs[""bulk_labels""] == ""Dendritic""],. size=100,. color=""n_genes"",. ax=ax. ). ```. ![Figure_1](https://user-images.githubusercontent.com/8238804/62194398-20ae5e80-b3bd-11e9-91f9-f8215e25937a.png). Note that you will have to explicitly pass the `size` argument, as the size of each point is determined by the total number of points.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:124,integrability,API,API,124,"Regarding 1, I think this is a good idea. I've thought this would be a better solution to #709. What do you think the right API would be for this? Ideally, I think this should be a single argument. As a work-around, you could do something like this:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). ax = sc.pl.umap(pbmc, size=100, show=False). sc.pl.umap(. pbmc[pbmc.obs[""bulk_labels""] == ""Dendritic""],. size=100,. color=""n_genes"",. ax=ax. ). ```. ![Figure_1](https://user-images.githubusercontent.com/8238804/62194398-20ae5e80-b3bd-11e9-91f9-f8215e25937a.png). Note that you will have to explicitly pass the `size` argument, as the size of each point is determined by the total number of points.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:124,interoperability,API,API,124,"Regarding 1, I think this is a good idea. I've thought this would be a better solution to #709. What do you think the right API would be for this? Ideally, I think this should be a single argument. As a work-around, you could do something like this:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). ax = sc.pl.umap(pbmc, size=100, show=False). sc.pl.umap(. pbmc[pbmc.obs[""bulk_labels""] == ""Dendritic""],. size=100,. color=""n_genes"",. ax=ax. ). ```. ![Figure_1](https://user-images.githubusercontent.com/8238804/62194398-20ae5e80-b3bd-11e9-91f9-f8215e25937a.png). Note that you will have to explicitly pass the `size` argument, as the size of each point is determined by the total number of points.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:490,usability,user,user-images,490,"Regarding 1, I think this is a good idea. I've thought this would be a better solution to #709. What do you think the right API would be for this? Ideally, I think this should be a single argument. As a work-around, you could do something like this:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). ax = sc.pl.umap(pbmc, size=100, show=False). sc.pl.umap(. pbmc[pbmc.obs[""bulk_labels""] == ""Dendritic""],. size=100,. color=""n_genes"",. ax=ax. ). ```. ![Figure_1](https://user-images.githubusercontent.com/8238804/62194398-20ae5e80-b3bd-11e9-91f9-f8215e25937a.png). Note that you will have to explicitly pass the `size` argument, as the size of each point is determined by the total number of points.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:358,availability,cluster,cluster,358,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:358,deployability,cluster,cluster,358,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:124,energy efficiency,cool,cool,124,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:244,integrability,batch,batches,244,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:332,integrability,batch,batches,332,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:516,integrability,sub,subset,516,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:153,interoperability,specif,specifying,153,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:244,performance,batch,batches,244,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:332,performance,batch,batches,332,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:426,safety,compl,complicate,426,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:310,security,ident,identify,310,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:426,security,compl,complicate,426,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/759:480,usability,prefer,prefer,480,"Thank you very much for the alternative method. . I'm obviously not familiar with with python and matplotlib yet. And it is cool to achieve this goal by specifying axes. . Not only this issue, I also found some functions of scanpy did not take batches into account. For example, tl.rank_genes_groups could not identify DEGs between batches in a same louvain cluster, and then plot them using pl.rank_genes_groups. . Let's not complicate things for the moment. . For this issue, I prefer adding `groupby` argument to subset `groups`, which may be a neat way. Thanks again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/759
https://github.com/scverse/scanpy/issues/761:40,deployability,version,version,40,This is still the case as of the latest version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/761
https://github.com/scverse/scanpy/issues/761:40,integrability,version,version,40,This is still the case as of the latest version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/761
https://github.com/scverse/scanpy/issues/761:40,modifiability,version,version,40,This is still the case as of the latest version.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/761
https://github.com/scverse/scanpy/issues/762:69,integrability,sub,submitting,69,"Thanks for the bug report! That sounds totally right, would you mind submitting a PR to fix that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:379,deployability,API,API,379,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:83,energy efficiency,load,load,83,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:449,energy efficiency,Current,Currently,449,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:379,integrability,API,API,379,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:45,interoperability,specif,specific,45,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:379,interoperability,API,API,379,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:140,modifiability,paramet,parameter,140,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:170,modifiability,layer,layers,170,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:628,modifiability,paramet,parameters,628,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:83,performance,load,load,83,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:421,usability,help,help,421,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:426,usability,user,users,426,"@coh-racng I would like to add that for your specific intention the best way is to load the `plot_scatter` function that accepts `basis` as parameter and works well with layers. The code should be:. ```PYTHON. from scanpy._plotting.scatterplots import plot_scatter`. plot_scatter(adata, basis='<name>'....). ```. @ivirshup, @falexwolf I think we should add `plot_scatter` to the API maybe renaming it `plot_embedding` to help users like @coh-racng. Currently we have two different ways to make scatter plots: One for embeddings (`plot_scatter`) and other more generic for obs and vars (`sc.pl.scatter`) that accepts `x` and `y` parameters.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:133,reliability,doe,doesn,133,"Definitely agree with you @fidelram, I think the main thing stopping us before was unfortunately just picking the name. `plot_{...}` doesn't really match any of our other functions. Names that come up for me are: `sc.pl.scatter` (obviously taken), `sc.pl.dimred`, or `sc.pl.scatter_obsm`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:60,usability,stop,stopping,60,"Definitely agree with you @fidelram, I think the main thing stopping us before was unfortunately just picking the name. `plot_{...}` doesn't really match any of our other functions. Names that come up for me are: `sc.pl.scatter` (obviously taken), `sc.pl.dimred`, or `sc.pl.scatter_obsm`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:52,usability,close,closed,52,"Hi @fidelram, did you get around to it? Can this be closed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:0,deployability,Updat,Update,0,"Update: The initial issue has been fixed, we don't have a more generic embedding plotting function yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:0,safety,Updat,Update,0,"Update: The initial issue has been fixed, we don't have a more generic embedding plotting function yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/762:0,security,Updat,Update,0,"Update: The initial issue has been fixed, we don't have a more generic embedding plotting function yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/762
https://github.com/scverse/scanpy/issues/763:26,availability,down,downstream,26,"Either that, or allow the downstream code to gracefully handle `inf` values. It is the binning procedure for both 'seurat' and 'cell_ranger' that seem to be a problem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:72,availability,fault,fault,72,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:49,deployability,log,logarithmized,49,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:72,energy efficiency,fault,fault,72,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:72,performance,fault,fault,72,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:72,reliability,fault,fault,72,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:49,safety,log,logarithmized,49,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:72,safety,fault,fault,72,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:49,security,log,logarithmized,49,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:49,testability,log,logarithmized,49,"Sorry, just realizing that this function expects logarithmized data. My fault.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:10,availability,error,error,10,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:99,deployability,log,log,99,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:16,integrability,messag,message,16,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:305,integrability,sub,subscribed,305,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:599,integrability,event,event-,599,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:16,interoperability,messag,message,16,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:10,performance,error,error,10,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:10,safety,error,error,10,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:99,safety,log,log,99,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:99,security,log,log,99,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:689,security,auth,auth,689,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:99,testability,log,log,99,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:10,usability,error,error,10,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:195,usability,Close,Closed,195,"Still the error message could be a lot better. I’ve made the same mistake,. it’s easy to forget to log the data. On Fri 2 Aug 2019 at 23:36, Stephen Fleming <notifications@github.com>. wrote:. > Closed #763 <https://github.com/theislab/scanpy/issues/763>. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/763?email_source=notifications&email_token=AACL4TL6QHUQMHIBKEQT5GLQCSSFFA5CNFSM4IJBAFAKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOS3M3XBA#event-2530851716>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AACL4TM5VZDC544TAQPK7NDQCSSFFANCNFSM4IJBAFAA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:9,availability,error,error,9,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:181,availability,error,error,181,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:155,deployability,log,logging,155,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:187,integrability,messag,messages,187,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:187,interoperability,messag,messages,187,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:9,performance,error,error,9,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:181,performance,error,error,181,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:221,performance,time,time,221,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:9,safety,error,error,9,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:155,safety,log,logging,155,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:181,safety,error,error,181,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:155,security,log,logging,155,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:155,testability,log,logging,155,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:9,usability,error,error,9,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:181,usability,error,error,181,"The same error in `sc.pp.highly_variable_genes` can pop up also if you forget to `sc.pp.filter_genes(adata, min_cells=0)` before running normalization and logging. Some informative error messages could for sure save some time here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:87,availability,error,error,87,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:14,deployability,scale,scale,14,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:14,energy efficiency,scale,scale,14,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:14,modifiability,scal,scale,14,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:14,performance,scale,scale,14,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:87,performance,error,error,87,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:87,safety,error,error,87,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:87,usability,error,error,87,do not `sc.pp.scale(adata)` before use `sc.pp.highly_variable_genes` will not show the error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:37,deployability,Log,Log-transform,37,"Thanks, all I had to do was:. ```. # Log-transform the data. sc.pp.log1p(adata). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:41,integrability,transform,transform,41,"Thanks, all I had to do was:. ```. # Log-transform the data. sc.pp.log1p(adata). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:41,interoperability,transform,transform,41,"Thanks, all I had to do was:. ```. # Log-transform the data. sc.pp.log1p(adata). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:37,safety,Log,Log-transform,37,"Thanks, all I had to do was:. ```. # Log-transform the data. sc.pp.log1p(adata). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:37,security,Log,Log-transform,37,"Thanks, all I had to do was:. ```. # Log-transform the data. sc.pp.log1p(adata). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/issues/763:37,testability,Log,Log-transform,37,"Thanks, all I had to do was:. ```. # Log-transform the data. sc.pp.log1p(adata). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/763
https://github.com/scverse/scanpy/pull/764:35,safety,test,test,35,Thanks for the PR! Could you add a test too?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764
https://github.com/scverse/scanpy/pull/764:35,testability,test,test,35,Thanks for the PR! Could you add a test too?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764
https://github.com/scverse/scanpy/pull/764:48,safety,test,test,48,"@coh-racng, I've merged your fix in #790 with a test added. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764
https://github.com/scverse/scanpy/pull/764:48,testability,test,test,48,"@coh-racng, I've merged your fix in #790 with a test added. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/764
https://github.com/scverse/scanpy/issues/766:27,availability,cluster,clustermap,27,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:105,availability,cluster,clustermap,105,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:27,deployability,cluster,clustermap,27,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:91,deployability,api,api,91,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:105,deployability,cluster,clustermap,105,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:91,integrability,api,api,91,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/766:91,interoperability,api,api,91,You are looking for [sc.pl.clustermap](https://icb-scanpy.readthedocs-hosted.com/en/stable/api/scanpy.pl.clustermap.html) I think.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/766
https://github.com/scverse/scanpy/issues/767:285,modifiability,paramet,parameters,285,"Could you tell us about how you've found it useful, or point us towards some literature on it being used? I think this would be easy enough to implement, but when I tried a naive implementation the results weren't that compelling. It's very possible I should've played around with the parameters more. @flying-sheep, do you have thoughts on this? Here's a simple implementation:. ```python. def ica(adata, n_components, inplace=True, **kwargs): . from sklearn.decomposition import FastICA . ica_transformer = FastICA(n_components=n_components, **kwargs) . x_ica = ica_transformer.fit_transform(adata.X) . if inplace:. adata.obsm[""X_ica""] = x_ica . adata.varm[""ICs""] = ica_transformer.components_.T . else:. return ica_transformer . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:460,modifiability,deco,decomposition,460,"Could you tell us about how you've found it useful, or point us towards some literature on it being used? I think this would be easy enough to implement, but when I tried a naive implementation the results weren't that compelling. It's very possible I should've played around with the parameters more. @flying-sheep, do you have thoughts on this? Here's a simple implementation:. ```python. def ica(adata, n_components, inplace=True, **kwargs): . from sklearn.decomposition import FastICA . ica_transformer = FastICA(n_components=n_components, **kwargs) . x_ica = ica_transformer.fit_transform(adata.X) . if inplace:. adata.obsm[""X_ica""] = x_ica . adata.varm[""ICs""] = ica_transformer.components_.T . else:. return ica_transformer . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:356,testability,simpl,simple,356,"Could you tell us about how you've found it useful, or point us towards some literature on it being used? I think this would be easy enough to implement, but when I tried a naive implementation the results weren't that compelling. It's very possible I should've played around with the parameters more. @flying-sheep, do you have thoughts on this? Here's a simple implementation:. ```python. def ica(adata, n_components, inplace=True, **kwargs): . from sklearn.decomposition import FastICA . ica_transformer = FastICA(n_components=n_components, **kwargs) . x_ica = ica_transformer.fit_transform(adata.X) . if inplace:. adata.obsm[""X_ica""] = x_ica . adata.varm[""ICs""] = ica_transformer.components_.T . else:. return ica_transformer . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:356,usability,simpl,simple,356,"Could you tell us about how you've found it useful, or point us towards some literature on it being used? I think this would be easy enough to implement, but when I tried a naive implementation the results weren't that compelling. It's very possible I should've played around with the parameters more. @flying-sheep, do you have thoughts on this? Here's a simple implementation:. ```python. def ica(adata, n_components, inplace=True, **kwargs): . from sklearn.decomposition import FastICA . ica_transformer = FastICA(n_components=n_components, **kwargs) . x_ica = ica_transformer.fit_transform(adata.X) . if inplace:. adata.obsm[""X_ica""] = x_ica . adata.varm[""ICs""] = ica_transformer.components_.T . else:. return ica_transformer . ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:472,modifiability,variab,variable,472,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:119,safety,compl,complexity,119,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:193,safety,detect,detecting,193,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:119,security,compl,complexity,119,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:193,security,detect,detecting,193,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:184,usability,help,helps,184,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:822,usability,help,helps,822,"Hi ! To answer about how it is useful, we are using ICA in our lab to a dataset of more than 100k cells, with a lot of complexity, and the main advantage of ICA against PCA is that it helps us detecting small populations of cells. As these small populations are not accounting for a lot of variance within the dataset, using a treshold on PCs, we discarded the PCs that would allow the separate them. Another advantage is that we do not make use of a selection of ""highly variable genes"" anymore, and use all genes expressed in more than 100 cells for the whole analysis... Doing the same and applying PCA gave us quite poor results.. . We made use of Seurat implementation.. and I tried fastICA from sklearn once but I couldn't obtain similar results... I have not looked thoroughly into seurat's code tough... . Hope it helps ! . Best",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:103,integrability,pub,pubmed,103,"Thank you both. In terms of literature, see [this paper (PMID: 30096299)](https://www.ncbi.nlm.nih.gov/pubmed/30096299), in particular [Figure S2](https://www.sciencedirect.com/science/article/pii/S0092867418309553#figs2)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:98,availability,toler,tolerance,98,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:335,deployability,version,version,335,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:335,integrability,version,version,335,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:33,modifiability,pac,package,33,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:335,modifiability,version,version,335,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:98,reliability,toleran,tolerance,98,"I looked through the R `fastica` package, and I think one of the main differences was the default tolerance. I've changed that and results seem a bit better. I don't think I have a great reference point to evaluate it though. Any chance you could provide a vignette of ICA being used with single cell data, so we can see if the python version can recapitulate the results?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:17,deployability,updat,update,17,@chris-rands Any update on this? Does the code from @ivirshup gives you any meaningful results?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:33,reliability,Doe,Does,33,@chris-rands Any update on this? Does the code from @ivirshup gives you any meaningful results?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:17,safety,updat,update,17,@chris-rands Any update on this? Does the code from @ivirshup gives you any meaningful results?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:17,security,updat,update,17,@chris-rands Any update on this? Does the code from @ivirshup gives you any meaningful results?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:92,modifiability,pac,package,92,"BTW there is a nice ""Faster ICA"" algorithm now, called Picard. It's implemented as a python package here:. https://pierreablin.github.io/picard/generated/picard.picard.html#picard.picard. It might be worthwhile to try this too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:92,availability,slo,slower,92,"@gokceneraslan, got around to giving `picard` a shot. For the pbmc3k dataset, it's a little slower than sklearns FastICA, though sklearn gives non-convergence warnings more often. Have you tried it before?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:92,reliability,slo,slower,92,"@gokceneraslan, got around to giving `picard` a shot. For the pbmc3k dataset, it's a little slower than sklearns FastICA, though sklearn gives non-convergence warnings more often. Have you tried it before?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:169,availability,down,downstream,169,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:302,availability,slo,slower,302,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:227,integrability,compon,components,227,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:227,interoperability,compon,components,227,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:81,modifiability,deco,decomposition,81,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:227,modifiability,compon,components,227,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:302,reliability,slo,slower,302,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:208,testability,simpl,simply,208,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:15,usability,feedback,feedback,15,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:185,usability,visual,visualisations,185,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:208,usability,simpl,simply,208,"Thanks for the feedback and sorry for the delay. The code snippet using `sklearn.decomposition.FastICA` gave me quite similar results to PCA for my data in terms of the downstream UMAP visualisations (when I simply embedded 50 components in the neighbourhood graph). One difference is that the ICA was slower to compute. I am not confident to create a vignette, as I'm unclear what the 'correct' results should look like. I have not tried the `picard` implementation yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:268,interoperability,standard,standard,268,"Hi, I tried the snippet, with fastICA and picard, and with a number of cells higher than 30,000, the whitening step cannot be completed. This seems be due to some Lapack limitations. . `ValueError: Too large work array required -- computation cannot be performed with standard 32-bit LAPACK.`. I don't know how to get around this.... . Best, . Chloé",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:253,performance,perform,performed,253,"Hi, I tried the snippet, with fastICA and picard, and with a number of cells higher than 30,000, the whitening step cannot be completed. This seems be due to some Lapack limitations. . `ValueError: Too large work array required -- computation cannot be performed with standard 32-bit LAPACK.`. I don't know how to get around this.... . Best, . Chloé",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:126,safety,compl,completed,126,"Hi, I tried the snippet, with fastICA and picard, and with a number of cells higher than 30,000, the whitening step cannot be completed. This seems be due to some Lapack limitations. . `ValueError: Too large work array required -- computation cannot be performed with standard 32-bit LAPACK.`. I don't know how to get around this.... . Best, . Chloé",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:126,security,compl,completed,126,"Hi, I tried the snippet, with fastICA and picard, and with a number of cells higher than 30,000, the whitening step cannot be completed. This seems be due to some Lapack limitations. . `ValueError: Too large work array required -- computation cannot be performed with standard 32-bit LAPACK.`. I don't know how to get around this.... . Best, . Chloé",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:253,usability,perform,performed,253,"Hi, I tried the snippet, with fastICA and picard, and with a number of cells higher than 30,000, the whitening step cannot be completed. This seems be due to some Lapack limitations. . `ValueError: Too large work array required -- computation cannot be performed with standard 32-bit LAPACK.`. I don't know how to get around this.... . Best, . Chloé",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:400,energy efficiency,load,loadings,400,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:319,integrability,compon,components,319,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:319,interoperability,compon,components,319,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:319,modifiability,compon,components,319,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:400,performance,load,loadings,400,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:29,safety,compl,completley,29,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:29,security,compl,completley,29,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:697,usability,user,user-images,697,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/767:870,usability,user,user-images,870,"Sorry for the late response, completley forgot to post my response here. @Fougere87, did that whitening issue occur with picard as well? I saw that with sklearn. I think we could get around that by whitening ourselves with ARPACK. Picard and sklearn look pretty similar to me in a quick comparison. Below are top 16/30 components (ranked by Geary's C, autocorrelation on the connectivity graph) cell loadings on the pbmc3k dataset. The umap and connectivity matrix here were computed on top of a PCA – which I should maybe do differently. However I think the results are similar enough that it's probably not of consequence. <details>. <summary> sklearn FastICA </summary>. ![sklearn_ica](https://user-images.githubusercontent.com/8238804/68647787-d53a4d80-0572-11ea-8b95-cde9122824f1.png). </details>. <details>. <summary> picard ICA </summary>. ![picard_ica2](https://user-images.githubusercontent.com/8238804/68647808-e5eac380-0572-11ea-8485-71a770849cc9.png). </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/767
https://github.com/scverse/scanpy/issues/768:0,reliability,Doe,Does,0,Does it work with anndata master?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:52,usability,close,close,52,"As we haven't heard back after the followup we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/768:113,usability,behavi,behaviour,113,"As we haven't heard back after the followup we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/768
https://github.com/scverse/scanpy/issues/769:33,availability,error,error,33,I have also got exactly the same error !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:33,performance,error,error,33,I have also got exactly the same error !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:33,safety,error,error,33,I have also got exactly the same error !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:33,usability,error,error,33,I have also got exactly the same error !,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:29,deployability,releas,release,29,"There hasn't actually been a release of UMAP since the pull request that should fix this (https://github.com/lmcinnes/umap/pull/261). I think I see what happened here, so I've opened a PR to fix it here. For now, this can be worked around by running:. ```python. sc.tl.umap(adata, init_pos=sc.tl._utils.get_init_pos_from_paga(adata)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:118,availability,error,error,118,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:142,deployability,modul,module,142,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:157,deployability,api,api,157,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:212,deployability,instal,install,212,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:231,deployability,instal,install,231,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:325,energy efficiency,load,loading,325,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:157,integrability,api,api,157,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:157,interoperability,api,api,157,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:142,modifiability,modul,module,142,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:118,performance,error,error,118,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:325,performance,load,loading,325,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:281,reliability,doe,doesn,281,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:118,safety,error,error,118,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:142,safety,modul,module,142,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:118,usability,error,error,118,"Hello @ivirshup thanks for this! Quick question (still very new to python). Upon following your suggestion I get this error:. AttributeError: module 'scanpy.api.tl' has no attribute '_utils'. I then proceeded to install utils (pip install utils), and then. import utils. But still doesn't work. I assume it's because I'm not loading it correctly into the environment for scanpy to use but I don't know how?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:151,deployability,api,api,151,"No worries! How did you import scanpy? It should be done like: `import scanpy as sc`, but I think you might have used the older method: `import scanpy.api as sc`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:151,integrability,api,api,151,"No worries! How did you import scanpy? It should be done like: `import scanpy as sc`, but I think you might have used the older method: `import scanpy.api as sc`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:151,interoperability,api,api,151,"No worries! How did you import scanpy? It should be done like: `import scanpy as sc`, but I think you might have used the older method: `import scanpy.api as sc`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:15,availability,error,error,15,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1. But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:15,performance,error,error,15,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1. But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:15,safety,error,error,15,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1. But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:15,usability,error,error,15,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1. But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/769:130,usability,learn,learn,130,I got the same error with scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.3 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.21.3 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1. But I am so glad to find answer here and thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/769
https://github.com/scverse/scanpy/issues/770:90,availability,error,error,90,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:5,deployability,version,version,5,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:5,integrability,version,version,5,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:5,modifiability,version,version,5,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:90,performance,error,error,90,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:90,safety,error,error,90,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:90,usability,error,error,90,"What version of bbknn are you using? I think it might be out of date if you didn't get an error from `save_knn=False`. Also, this works for me:. ```python. import scanpy as sc. import scanpy.external as sce. pbmc = sc.datasets.pbmc68k_reduced(). sce.pp.bbknn(pbmc, batch_key='bulk_labels'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:69,deployability,version,version,69,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:152,deployability,instal,install,152,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:186,deployability,instal,installed,186,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:69,integrability,version,version,69,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:246,integrability,Batch,Batches,246,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:69,modifiability,version,version,69,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:246,performance,Batch,Batches,246,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/770:271,usability,help,help,271,"Hi, . I faced the same problem. I solved it by using the development version of scanpy : . git clone https://github.com/theislab/scanpy. cd scanpy. pip install -e . For bbknn i just pip installed it . Then : . bbknn.bbknn(adata_bbknn, batch_key=""Batches""). Hope this can help,.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/770
https://github.com/scverse/scanpy/issues/774:340,performance,I/O,I/O,340,"Hi,. This might be better posted on the page where you found the code. That way if anyone else has this question, they'll find it there as well. As that's my page, I'll answer here quickly though. `pbmc_sce` is a SingleCellExperiment object that is used e.g., by `scater`. As that's an R object you can use `saveRDS` and `readRDS` for file I/O. You would have to use these commands within the R magics jupyter notebook cells though. Those are the cells that start with `%%R`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/774
https://github.com/scverse/scanpy/issues/774:373,usability,command,commands,373,"Hi,. This might be better posted on the page where you found the code. That way if anyone else has this question, they'll find it there as well. As that's my page, I'll answer here quickly though. `pbmc_sce` is a SingleCellExperiment object that is used e.g., by `scater`. As that's an R object you can use `saveRDS` and `readRDS` for file I/O. You would have to use these commands within the R magics jupyter notebook cells though. Those are the cells that start with `%%R`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/774
https://github.com/scverse/scanpy/issues/775:65,integrability,translat,translate,65,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:65,interoperability,translat,translate,65,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:500,interoperability,share,shared,500,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:54,modifiability,scal,scaling,54,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:184,modifiability,scal,scaling,184,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:298,modifiability,scal,scaling,298,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:8,testability,understand,understand,8,"So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. I'm very unsure if this is what you're actually proposing though ^^. Not sure what you mean by the quantile of colour vector that is shared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:554,deployability,api,api,554,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:67,integrability,translat,translate,67,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:554,integrability,api,api,554,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:67,interoperability,translat,translate,67,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:554,interoperability,api,api,554,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:940,interoperability,specif,specific,940,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:56,modifiability,scal,scaling,56,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:186,modifiability,scal,scaling,186,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:300,modifiability,scal,scaling,300,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:965,reliability,doe,does,965,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:10,testability,understand,understand,10,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1257,testability,simpl,simply,1257,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:392,usability,clear,clear,392,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:644,usability,minim,minimum,644,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:1257,usability,simpl,simply,1257,"> So if I understand correctly you want to use quantile scaling to translate values to colour? If that is what you're suggesting, I'm not sure I'm such a fan of that idea. With quantile scaling you would lose all sense of gradient in your e.g. expression values. I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. OK, I thought code was clear enough, here is more information :). vmin and vmax are used for determining the lowest and highest values of the colormap (see https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.Normalize.html). By default, these values are mapped to the minimum and maximum of the color vector of the scatter plot (e.g. gene expression). Right now, we can define only one vmin/vmax value in a sc.pl.* call (e.g. `sc.pl.umap(ad, color=..., vmax=2.0)`). But when we plot multiple genes (`sc.pl.umap(ad, color=['a', 'b'], vmax=2.0)`), setting vmax to a specific value sometimes does not make sense because each gene might have a different outlier range. . What I propose is the flexibility to use quantiles to set vmin/vmax e.g. `sc.pl.umap(ad, color=['a', 'b'], vmax_quantile=0.99)` where vmax values will be calculated per panel (i.e. per gene) by Scanpy. I mean it's simply winsorization, nothing fancy :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:33,availability,slo,slow,33,"Aaahhhh... okay. Sorry for being slow. That sounds like exactly what I was saying here:. >I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. Makes sense, and sounds like a good idea. I have previously created a new object and trimmed the values as I needed for the visualization... a super annoying workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:127,modifiability,scal,scaling,127,"Aaahhhh... okay. Sorry for being slow. That sounds like exactly what I was saying here:. >I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. Makes sense, and sounds like a good idea. I have previously created a new object and trimmed the values as I needed for the visualization... a super annoying workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:33,reliability,slo,slow,33,"Aaahhhh... okay. Sorry for being slow. That sounds like exactly what I was saying here:. >I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. Makes sense, and sounds like a good idea. I have previously created a new object and trimmed the values as I needed for the visualization... a super annoying workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:320,usability,visual,visualization,320,"Aaahhhh... okay. Sorry for being slow. That sounds like exactly what I was saying here:. >I would instead opt for trimming and scaling. The trimming could be done via a quantile threshold though. Makes sense, and sounds like a good idea. I have previously created a new object and trimmed the values as I needed for the visualization... a super annoying workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:25,testability,understand,understand,25,"I should correct. What I understand by trimming is apparently not what that word actually means. I was not advocating throwing out outlier values, but essentially clipping them. So basically what you propose.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:172,energy efficiency,frequenc,frequencies,172,"I think this would be good. I can think of cases where I wouldn't want every gene to have the same quantile normalization (e.g. when plotting markers for populations whose frequencies differ by orders of magnitude). In addition to including a quantile argument, would you also include a ""vectorized"" vmax, vmin argument? ```python. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[2.0, 3.0]). ```. If you want to get even more flexible about how cutoffs can be chosen, we could also allow `vmin` and `vmax` to be callables. That way you could get the behavior of specifying a quantile from:. ```python. from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=partial(np.quantile, q=.99)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:573,interoperability,specif,specifying,573,"I think this would be good. I can think of cases where I wouldn't want every gene to have the same quantile normalization (e.g. when plotting markers for populations whose frequencies differ by orders of magnitude). In addition to including a quantile argument, would you also include a ""vectorized"" vmax, vmin argument? ```python. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[2.0, 3.0]). ```. If you want to get even more flexible about how cutoffs can be chosen, we could also allow `vmin` and `vmax` to be callables. That way you could get the behavior of specifying a quantile from:. ```python. from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=partial(np.quantile, q=.99)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:561,usability,behavi,behavior,561,"I think this would be good. I can think of cases where I wouldn't want every gene to have the same quantile normalization (e.g. when plotting markers for populations whose frequencies differ by orders of magnitude). In addition to including a quantile argument, would you also include a ""vectorized"" vmax, vmin argument? ```python. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[2.0, 3.0]). ```. If you want to get even more flexible about how cutoffs can be chosen, we could also allow `vmin` and `vmax` to be callables. That way you could get the behavior of specifying a quantile from:. ```python. from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=partial(np.quantile, q=.99)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:741,deployability,depend,depending,741,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:741,integrability,depend,depending,741,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:107,interoperability,specif,specific,107,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:241,modifiability,paramet,parameters,241,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:741,modifiability,depend,depending,741,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:213,safety,avoid,avoid,213,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:741,safety,depend,depending,741,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:953,safety,valid,valid,953,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:741,testability,depend,depending,741,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:438,usability,document,document,438,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/issues/775:466,usability,user,user,466,"I sympathize with the problem which I tend to solve by plotting individual scatterplots, each one with its specific vmax. But I will be happy to have a better output. I like the idea of using quantile but I would avoid an increasing list of parameters. Thus @ivirshup suggestion to use `functools.partial` seems better. I like the flexibility it provides and I think we should implement it, but I don't know if this would be difficult to document and explain to the user that just would like to compute the quantile. An idea would be to allow some encoding for vmax as for example `vmax='q99'` which would be interpreted as np.quantile. My suggestion is to . - add vectorized vmax and vmin. - each entry of vmax or vmin would be interpreted depending on the data type. Besides a number, if it is a string then it is interpreted as for example quantile if it starts with 'q' or as a function if the type is `partial`. The following options would then be valid:. ```PYTHON. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[4., 3.]). sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=['q80', 'q90']). from functools import partial. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2""], vmax=[partial(np.mean), partial(np.median)]). # combination. sc.pl.{scatterfunc}(adata, color=[""gene1"", ""gene2"", ""gene3""], . vmax=[4., 'q85', partial(np.percentile, q=90]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/775
https://github.com/scverse/scanpy/pull/776:55,safety,test,test,55,@gokceneraslan Thanks for looking at this. Can you add test for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/776
https://github.com/scverse/scanpy/pull/776:55,testability,test,test,55,@gokceneraslan Thanks for looking at this. Can you add test for this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/776
https://github.com/scverse/scanpy/issues/777:75,availability,replic,replicating,75,"This looks like the same issue as #440. Similarly, I'm having some trouble replicating. @friedpine are those your full version numbers? If so, could you try upgrading to `scanpy==1.4.4.post1 anndata==0.6.22.post1` and seeing if this still occurs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:119,deployability,version,version,119,"This looks like the same issue as #440. Similarly, I'm having some trouble replicating. @friedpine are those your full version numbers? If so, could you try upgrading to `scanpy==1.4.4.post1 anndata==0.6.22.post1` and seeing if this still occurs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:157,deployability,upgrad,upgrading,157,"This looks like the same issue as #440. Similarly, I'm having some trouble replicating. @friedpine are those your full version numbers? If so, could you try upgrading to `scanpy==1.4.4.post1 anndata==0.6.22.post1` and seeing if this still occurs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:119,integrability,version,version,119,"This looks like the same issue as #440. Similarly, I'm having some trouble replicating. @friedpine are those your full version numbers? If so, could you try upgrading to `scanpy==1.4.4.post1 anndata==0.6.22.post1` and seeing if this still occurs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:119,modifiability,version,version,119,"This looks like the same issue as #440. Similarly, I'm having some trouble replicating. @friedpine are those your full version numbers? If so, could you try upgrading to `scanpy==1.4.4.post1 anndata==0.6.22.post1` and seeing if this still occurs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/777:157,modifiability,upgrad,upgrading,157,"This looks like the same issue as #440. Similarly, I'm having some trouble replicating. @friedpine are those your full version numbers? If so, could you try upgrading to `scanpy==1.4.4.post1 anndata==0.6.22.post1` and seeing if this still occurs?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/777
https://github.com/scverse/scanpy/issues/778:145,deployability,version,versions,145,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:218,deployability,version,versions,218,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:126,energy efficiency,current,current,126,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:145,integrability,version,versions,145,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:203,integrability,sub,subclass,203,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:218,integrability,version,versions,218,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:145,modifiability,version,versions,145,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:218,modifiability,version,versions,218,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:40,security,access,accessed,40,"Whoa, I had no idea you could have ever accessed elements of obsm and varm as attributes. That probably won't be the case for current and future versions of `anndata`, since `obsm` should be a `Mapping` subclass. What versions of scanpy and anndata are you using?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:7,deployability,updat,update,7,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:29,deployability,releas,releases,29,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:7,safety,updat,update,7,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:7,security,updat,update,7,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/778:60,security,access,access,60,"If you update to more recent releases, you won't be able to access elements of `obsm` or `varm` like an attribute. It should all be through `.__getitem__` (e.g. `adata.obsm[""X_tsne""]`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/778
https://github.com/scverse/scanpy/issues/779:380,deployability,version,version-dependent,380,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:565,deployability,releas,release,565,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:87,integrability,compon,component,87,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:380,integrability,version,version-dependent,380,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:87,interoperability,compon,component,87,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:87,modifiability,compon,component,87,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:380,modifiability,version,version-dependent,380,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:401,reliability,Doe,Does,401,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:141,safety,test,tests,141,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:388,safety,depend,dependent,388,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:483,safety,test,test,483,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:141,testability,test,tests,141,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:388,testability,depend,dependent,388,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:483,testability,test,test,483,"Haven't tried again but I have a suggestion. Since umap (or pynndescent) is a critical component of scanpy, I think it'd be great to run our tests against both ""stable"" and ""development"" branches of umap. However in order for this to happen, umap needs proper naming for the development and stable branches. Right now, there are master, 0.3dev and 0.4dev, therefore the names are version-dependent. . Does it make sense to file a bug report in umap repo? It'd be a lot easier to run test against two major branches of umap without changing the names in every major release. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:38,deployability,releas,release,38,"Do we know when UMAP 0.4 is due for a release? I wouldn't want to put too much effort into ensuring compatibility with something unstable. If it's really useful now, maybe it's worth it, but it could change again before something gets released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:235,deployability,releas,released,235,"Do we know when UMAP 0.4 is due for a release? I wouldn't want to put too much effort into ensuring compatibility with something unstable. If it's really useful now, maybe it's worth it, but it could change again before something gets released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:100,interoperability,compatib,compatibility,100,"Do we know when UMAP 0.4 is due for a release? I wouldn't want to put too much effort into ensuring compatibility with something unstable. If it's really useful now, maybe it's worth it, but it could change again before something gets released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:40,deployability,releas,released,40,"I don't know when it's due, but if it's released tomorrow scanpy will stop working and that scares me 😑",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/779:70,usability,stop,stop,70,"I don't know when it's due, but if it's released tomorrow scanpy will stop working and that scares me 😑",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/779
https://github.com/scverse/scanpy/issues/780:224,deployability,version,versions,224,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:118,energy efficiency,model,model,118,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:509,energy efficiency,estimat,estimated,509,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:224,integrability,version,versions,224,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:240,integrability,topic,topics,240,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:381,integrability,batch,batch,381,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:481,integrability,batch,batch,481,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:144,modifiability,paramet,parameter,144,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:211,modifiability,pac,packages,211,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:224,modifiability,version,versions,224,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:387,modifiability,variab,variable,387,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:381,performance,batch,batch,381,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:481,performance,batch,batch,481,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:118,security,model,model,118,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:400,testability,regress,regressed,400,"Hi Samuele,. `covariates` argument refers to the additional covariates (biological or technical) that are used in the model fit. It's the `mod` parameter in the R function combat (https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat) and `X` in equation 2.1 in Johnson et al. 2007, https://academic.oup.com/biostatistics/article/8/1/118/252073. Since only the batch variable is ""regressed out"" from the gene expression, adding extra covariates changes the way batch effect coefficient is estimated. By the way, https://scanpy.discourse.group is a better place to ask questions and start such discussions :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:2,modifiability,exten,extended,2,"I extended the documentation a bit now, see https://github.com/theislab/scanpy/commit/c7e58e3a8e32b7f395e25267cd3cba684d6d40c4.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/issues/780:15,usability,document,documentation,15,"I extended the documentation a bit now, see https://github.com/theislab/scanpy/commit/c7e58e3a8e32b7f395e25267cd3cba684d6d40c4.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/780
https://github.com/scverse/scanpy/pull/784:47,deployability,version,version,47,Do you think we also need to check if the umap version is >= 0.4 or so?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/pull/784:47,integrability,version,version,47,Do you think we also need to check if the umap version is >= 0.4 or so?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/pull/784:47,modifiability,version,version,47,Do you think we also need to check if the umap version is >= 0.4 or so?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/pull/784:22,safety,test,tests,22,Did anyone run scanpy tests with umap 0.4 branch?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/pull/784:22,testability,test,tests,22,Did anyone run scanpy tests with umap 0.4 branch?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/pull/784:26,energy efficiency,current,current,26,"Not me, but I checked the current and old umap code and found that this PR will only fix things and not cause problems. IDK if umap 0.4 causes further problems",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/784
https://github.com/scverse/scanpy/issues/786:8,deployability,instal,installing,8,"Hi, try installing python-igraph from the wheel here - https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph. And after that install louvain via pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:129,deployability,instal,install,129,"Hi, try installing python-igraph from the wheel here - https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph. And after that install louvain via pip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:47,deployability,instal,installing,47,"Yup, not a bug with scanpy, but a problem with installing louvain",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/786:87,deployability,instal,install,87,"I've talked to some other people who had trouble with this. If there's a better way to install it, I think we should mention it in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/786
https://github.com/scverse/scanpy/issues/787:27,deployability,version,version,27,Could you let us know some version information? In particular I'd like to know the version of scanpy and matplotlib that you're running.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:83,deployability,version,version,83,Could you let us know some version information? In particular I'd like to know the version of scanpy and matplotlib that you're running.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:27,integrability,version,version,27,Could you let us know some version information? In particular I'd like to know the version of scanpy and matplotlib that you're running.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:83,integrability,version,version,83,Could you let us know some version information? In particular I'd like to know the version of scanpy and matplotlib that you're running.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:27,modifiability,version,version,27,Could you let us know some version information? In particular I'd like to know the version of scanpy and matplotlib that you're running.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:83,modifiability,version,version,83,Could you let us know some version information? In particular I'd like to know the version of scanpy and matplotlib that you're running.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:14,availability,replic,replicate,14,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:45,availability,avail,available,45,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:45,reliability,availab,available,45,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:45,safety,avail,available,45,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:45,security,availab,available,45,"Also, can you replicate the problem with the available Scanpy datasets?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:260,deployability,depend,dependency,260,"None, there is no problem on our side right? @fidelram said in https://github.com/theislab/scanpy/pull/661#issuecomment-496144015 to wait for matplotlib/matplotlib#14298 to be fixed. It seems to be in matplotlib’s 3.1.2 milestone, so we can maybe just set the dependency to “matplotlib == 3.0.0 or matplotlib >= 3.1.2”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:260,integrability,depend,dependency,260,"None, there is no problem on our side right? @fidelram said in https://github.com/theislab/scanpy/pull/661#issuecomment-496144015 to wait for matplotlib/matplotlib#14298 to be fixed. It seems to be in matplotlib’s 3.1.2 milestone, so we can maybe just set the dependency to “matplotlib == 3.0.0 or matplotlib >= 3.1.2”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:260,modifiability,depend,dependency,260,"None, there is no problem on our side right? @fidelram said in https://github.com/theislab/scanpy/pull/661#issuecomment-496144015 to wait for matplotlib/matplotlib#14298 to be fixed. It seems to be in matplotlib’s 3.1.2 milestone, so we can maybe just set the dependency to “matplotlib == 3.0.0 or matplotlib >= 3.1.2”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:260,safety,depend,dependency,260,"None, there is no problem on our side right? @fidelram said in https://github.com/theislab/scanpy/pull/661#issuecomment-496144015 to wait for matplotlib/matplotlib#14298 to be fixed. It seems to be in matplotlib’s 3.1.2 milestone, so we can maybe just set the dependency to “matplotlib == 3.0.0 or matplotlib >= 3.1.2”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:260,testability,depend,dependency,260,"None, there is no problem on our side right? @fidelram said in https://github.com/theislab/scanpy/pull/661#issuecomment-496144015 to wait for matplotlib/matplotlib#14298 to be fixed. It seems to be in matplotlib’s 3.1.2 milestone, so we can maybe just set the dependency to “matplotlib == 3.0.0 or matplotlib >= 3.1.2”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:125,availability,failur,failures,125,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:81,deployability,version,version,81,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:99,deployability,upgrad,upgrading,99,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:125,deployability,fail,failures,125,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:151,energy efficiency,heat,heat,151,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:81,integrability,version,version,81,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:81,modifiability,version,version,81,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:99,modifiability,upgrad,upgrading,99,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:125,performance,failur,failures,125,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:125,reliability,fail,failures,125,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:141,safety,test,tests,141,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/issues/787:141,testability,test,tests,141,"It would be good to have an open issue here for why we pin matplotlib to a lower version. If I try upgrading it, I get a few failures in the tests for heat maps as well as 3d plotting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/787
https://github.com/scverse/scanpy/pull/789:51,availability,down,down,51,Thank you! IDK how I missed that it’s used further down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/789
https://github.com/scverse/scanpy/pull/791:4,deployability,fail,failing,4,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:161,deployability,fail,failing,161,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:4,reliability,fail,failing,4,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:161,reliability,fail,failing,161,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:12,safety,test,test,12,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:148,safety,test,test,148,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:12,testability,test,test,12,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:148,testability,test,test,148,"The failing test is here https://travis-ci.org/theislab/scanpy/jobs/574409535#L386. However test_var_df should not be affected by this PR, and this test is also failing on master,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:24,availability,fault,fault,24,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:24,energy efficiency,fault,fault,24,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:24,performance,fault,fault,24,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:24,reliability,fault,fault,24,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:24,safety,fault,fault,24,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:45,safety,test,tests,45,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/pull/791:45,testability,test,tests,45,"Yes, sorry, that was my fault. Rerunning the tests for this PR",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/791
https://github.com/scverse/scanpy/issues/792:95,energy efficiency,current,currently,95,I think it would make sense to fully delegate this stuff to velocyto. Does the arrows argument currently work?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:70,reliability,Doe,Does,70,I think it would make sense to fully delegate this stuff to velocyto. Does the arrows argument currently work?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:108,safety,reme,remember,108,"maybe @VolkerBergen can comment on this. My opinion is that the `rna_velocity` code should be deleted, if I remember correctly is not even functional.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:131,availability,sli,slimmed,131,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,deployability,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:139,deployability,version,version,139,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:691,deployability,modul,modules,691,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:735,energy efficiency,optim,optimized,735,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,integrability,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:139,integrability,version,version,139,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,interoperability,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,modifiability,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:139,modifiability,version,version,139,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:305,modifiability,exten,extending,305,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:691,modifiability,modul,modules,691,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:723,modifiability,extens,extensively,723,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:735,performance,optimiz,optimized,735,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,reliability,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:131,reliability,sli,slimmed,131,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:691,safety,modul,modules,691,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,security,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:81,testability,integr,integrating,81,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:192,testability,simpl,simplification,192,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:192,usability,simpl,simplification,192,"brief recap: https://github.com/theislab/scanpy/pull/130 was the initial work on integrating RNA velocity into scanpy, which was a slimmed version of velocyto; yet not working well due to its simplification and several missing required processing steps. Consequently, and with the additional objective of extending velocyto, we outsourced that to scvelo. For directed paga this is already adjusted. I think we missed https://github.com/theislab/scanpy/blob/740c4a510ec598ab03ff3de1d9b1c091f0aac292/scanpy/plotting/_utils.py#L334; the convention became `'velocity_' + basis ` (instead of `'Delta_' + basis `). This is used only for scatter plots, if I get it correctly. The velocity plotting modules within scvelo have been extensively optimized, thus questionable whether still needed within scanpy. Anything else I am missing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:142,deployability,modul,module,142,"@gokceneraslan Whoops, it’s #130, no idea why I linked the wrong one. > if I remember correctly is not even functional. @fidelram You do, the module containing the function doesn’t import things used in the function. So at least that’s broken, maybe more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:149,deployability,contain,containing,149,"@gokceneraslan Whoops, it’s #130, no idea why I linked the wrong one. > if I remember correctly is not even functional. @fidelram You do, the module containing the function doesn’t import things used in the function. So at least that’s broken, maybe more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:142,modifiability,modul,module,142,"@gokceneraslan Whoops, it’s #130, no idea why I linked the wrong one. > if I remember correctly is not even functional. @fidelram You do, the module containing the function doesn’t import things used in the function. So at least that’s broken, maybe more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:173,reliability,doe,doesn,173,"@gokceneraslan Whoops, it’s #130, no idea why I linked the wrong one. > if I remember correctly is not even functional. @fidelram You do, the module containing the function doesn’t import things used in the function. So at least that’s broken, maybe more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:77,safety,reme,remember,77,"@gokceneraslan Whoops, it’s #130, no idea why I linked the wrong one. > if I remember correctly is not even functional. @fidelram You do, the module containing the function doesn’t import things used in the function. So at least that’s broken, maybe more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:142,safety,modul,module,142,"@gokceneraslan Whoops, it’s #130, no idea why I linked the wrong one. > if I remember correctly is not even functional. @fidelram You do, the module containing the function doesn’t import things used in the function. So at least that’s broken, maybe more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:206,availability,robust,robust,206,"It's **a** thing, not yet **the** thing. For directed PAGA follow [this](https://github.com/theislab/paga/issues/11) while always double checking with your single cell velocities as it is not yet perfectly robust.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:206,reliability,robust,robust,206,"It's **a** thing, not yet **the** thing. For directed PAGA follow [this](https://github.com/theislab/paga/issues/11) while always double checking with your single cell velocities as it is not yet perfectly robust.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/792:206,safety,robust,robust,206,"It's **a** thing, not yet **the** thing. For directed PAGA follow [this](https://github.com/theislab/paga/issues/11) while always double checking with your single cell velocities as it is not yet perfectly robust.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/792
https://github.com/scverse/scanpy/issues/793:29,deployability,releas,released,29,Thanks. I merged your PR and released a new package. Closing this issue now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/793
https://github.com/scverse/scanpy/issues/793:44,modifiability,pac,package,44,Thanks. I merged your PR and released a new package. Closing this issue now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/793
https://github.com/scverse/scanpy/pull/794:89,availability,cluster,cluster,89,"This looks very cool! I wonder if there could also be an option to put a contour between cluster that have a fluid boundary (for example what I assume are clusters 6 and 7 above). I like the above plot, but I imagine this might help with colours being difficult to discern in certain colour maps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:155,availability,cluster,clusters,155,"This looks very cool! I wonder if there could also be an option to put a contour between cluster that have a fluid boundary (for example what I assume are clusters 6 and 7 above). I like the above plot, but I imagine this might help with colours being difficult to discern in certain colour maps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:89,deployability,cluster,cluster,89,"This looks very cool! I wonder if there could also be an option to put a contour between cluster that have a fluid boundary (for example what I assume are clusters 6 and 7 above). I like the above plot, but I imagine this might help with colours being difficult to discern in certain colour maps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:155,deployability,cluster,clusters,155,"This looks very cool! I wonder if there could also be an option to put a contour between cluster that have a fluid boundary (for example what I assume are clusters 6 and 7 above). I like the above plot, but I imagine this might help with colours being difficult to discern in certain colour maps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:16,energy efficiency,cool,cool,16,"This looks very cool! I wonder if there could also be an option to put a contour between cluster that have a fluid boundary (for example what I assume are clusters 6 and 7 above). I like the above plot, but I imagine this might help with colours being difficult to discern in certain colour maps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:228,usability,help,help,228,"This looks very cool! I wonder if there could also be an option to put a contour between cluster that have a fluid boundary (for example what I assume are clusters 6 and 7 above). I like the above plot, but I imagine this might help with colours being difficult to discern in certain colour maps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:126,usability,hint,hints,126,@flying-sheep 'outline' could be good. We already have font outline that works similarly. Can you take a look at the new type hints that I added. I am not sure if I did it right? @LuckyMD you mean to do something like this (top image)? ![image](https://user-images.githubusercontent.com/4964309/63446548-b5dfc880-c43a-11e9-8739-b581ac0acd1e.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:253,usability,user,user-images,253,@flying-sheep 'outline' could be good. We already have font outline that works similarly. Can you take a look at the new type hints that I added. I am not sure if I did it right? @LuckyMD you mean to do something like this (top image)? ![image](https://user-images.githubusercontent.com/4964309/63446548-b5dfc880-c43a-11e9-8739-b581ac0acd1e.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:114,modifiability,paramet,parameter,114,"@LuckyMD I will think about it. The implementation does not seem trivial at the moment and will require yet a new parameter which I am hesitant to add, unless `add_contour` can accept something line `add_contour='separate categories'`. But at least, using overlapping images and without further modifications the issue is solved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:51,reliability,doe,does,51,"@LuckyMD I will think about it. The implementation does not seem trivial at the moment and will require yet a new parameter which I am hesitant to add, unless `add_contour` can accept something line `add_contour='separate categories'`. But at least, using overlapping images and without further modifications the issue is solved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:295,security,modif,modifications,295,"@LuckyMD I will think about it. The implementation does not seem trivial at the moment and will require yet a new parameter which I am hesitant to add, unless `add_contour` can accept something line `add_contour='separate categories'`. But at least, using overlapping images and without further modifications the issue is solved.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1230,availability,error,error,1230,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1225,deployability,log,logg,1225,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:245,interoperability,specif,specific,245,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:701,interoperability,specif,specify,701,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:852,interoperability,specif,specify,852,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:279,modifiability,paramet,parameter,279,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1243,modifiability,paramet,parameter,1243,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1230,performance,error,error,1230,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:294,reliability,doe,does,294,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:844,reliability,doe,doesn,844,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1225,safety,log,logg,1225,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1230,safety,error,error,1230,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:713,security,sign,signature,713,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1225,security,log,logg,1225,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1225,testability,log,logg,1225,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:123,usability,hint,hints,123,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:460,usability,user,user,460,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1230,usability,error,error,1230,"> 'outline' could be good. We already have font outline that works similarly. Great! > Can you take a look at the new type hints that I added. I am not sure if I did it right? The typing is pretty good! There’s one rule I follow, which is to be specific:. - If your function has parameter `a`, does `for elem in a`, and expects `elem`s to be `str`s, you can say `Iterable[str]`. If you use `a[i]`, say `Sequence[str]`. You don’t want to artificially limit the user by saying you need a `List[str]` if a `Tuple[str]` can be passed or even any `Iterator[str]` is sufficient. - If you say what you *return*, be concrete, e.g. `List[str]`. You know what exact type you return. - If you accept a callable, specify its signature: `Callable[[ArgType1, ArgType2], RetType]`. There’s nothing more annoying than to dive into the code because the library doesn’t specify what kind of function you can supply. So you should change. - `callable`→`Callable[[???], ?]`. - `Sequence`→`Sequence[?]`. - `Optional[dict]`→`Optional[Mapping[?, ?]]`. Also stylewise: Once `(` and `)` aren on separate lines, never have anything after `(`, and before `)`:. ```py. def _get_vmin_vmax(. […]. color_vector: Sequence[float],. ):. '''. […]. ```. ```py. logg.error(. ""The parameter […]"". […]. ""of plots."". ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:114,reliability,doe,does,114,@flying-sheep I quite like your style guidelines. It might be a good idea to designate a particular function that does it well and is complex enough to include all of these options. That way it's easy to follow style when writing a new function. Something like a contributors template.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:134,safety,compl,complex,134,@flying-sheep I quite like your style guidelines. It might be a good idea to designate a particular function that does it well and is complex enough to include all of these options. That way it's easy to follow style when writing a new function. Something like a contributors template.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:134,security,compl,complex,134,@flying-sheep I quite like your style guidelines. It might be a good idea to designate a particular function that does it well and is complex enough to include all of these options. That way it's easy to follow style when writing a new function. Something like a contributors template.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:38,usability,guid,guidelines,38,@flying-sheep I quite like your style guidelines. It might be a good idea to designate a particular function that does it well and is complex enough to include all of these options. That way it's easy to follow style when writing a new function. Something like a contributors template.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:80,availability,cluster,clusters,80,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:168,availability,cluster,cluster,168,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:575,availability,operat,operations,575,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:819,availability,operat,operations,819,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1242,availability,Avail,Available,1242,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:80,deployability,cluster,clusters,80,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:168,deployability,cluster,cluster,168,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:809,energy efficiency,reduc,reduction,809,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:319,modifiability,exten,extent,319,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:546,modifiability,pac,package,546,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:600,modifiability,concern,concern,600,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:726,modifiability,exten,extend,726,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1242,reliability,Availab,Available,1242,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1242,safety,Avail,Available,1242,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:1242,security,Availab,Available,1242,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:600,testability,concern,concern,600,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:303,usability,clear,clear,303,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:435,usability,indicat,indication,435,"This looks great! A few ideas:. * For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above (https://github.com/theislab/scanpy/pull/794#issuecomment-523515331) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? * For the string based quantile selection, is there another package which allows writing operations like this? My concern is that string based DSLs can get messy. It would be nice to make sure we're choosing a unambiguous spec which we can extend in the future and use in other functions. An example of a spec would be SQL reduction operations (like `PERCENTILE_DISC`), but hopefully there would be something less verbose. * For the basis argument, could we not require the key in `obsm` start with `X_`? I'm thinking the key would just go through a check like:. ```python. if basis in adata.obsm:. basis_key = basis. elif f""X_{basis}"" in adata.obsm:. basis_key = f""X_{basis}"". else:. raise KeyError(. f""Could not find entry in `obsm` for '{basis}'.\n"". f""Available keys are: {list(adata.obsm.keys())}."". ). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:228,reliability,Doe,Does,228,"@flying-sheep regarding the typing I ended up with the following line:. ```PYTHON. vmax: Union[float, str, Callable[[Sequence[float]], float], Sequence[Union[str, float, Callable[[Sequence[float]], float]]], None] = None,. ```. Does it looks ok to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:16,energy efficiency,cool,cool,16,"This looks very cool Fidel. It's not a big deal but if we use numbers in 0-100 range for vmax-vmin, it's a percentile, so p80 makes more sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:22,reliability,Doe,Does,22,"> I ended up with […] Does it looks ok to you? Yeah! You could simplify though:. ```py. VMinMax = Union[str, float, Callable[[Sequence[float]], float]]. def embedding(. ... vmin: Union[VMinMax, Sequence[VMinMax], None] = None,. vmax: Union[VMinMax, Sequence[VMinMax], None] = None,. ... ): ... def _get_vmin_vmax(. vmin: Sequence[VMinMax],. vmax: Sequence[VMinMax],. ... ) -> ...: ... ```. > It's not a big deal but if we use numbers in 0-100 range for vmax-vmin, it's a percentile, so p80 makes more sense. you can also be more or less precise: `q001`→`0.001`, `q9`→`0.9`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:63,testability,simpl,simplify,63,"> I ended up with […] Does it looks ok to you? Yeah! You could simplify though:. ```py. VMinMax = Union[str, float, Callable[[Sequence[float]], float]]. def embedding(. ... vmin: Union[VMinMax, Sequence[VMinMax], None] = None,. vmax: Union[VMinMax, Sequence[VMinMax], None] = None,. ... ): ... def _get_vmin_vmax(. vmin: Sequence[VMinMax],. vmax: Sequence[VMinMax],. ... ) -> ...: ... ```. > It's not a big deal but if we use numbers in 0-100 range for vmax-vmin, it's a percentile, so p80 makes more sense. you can also be more or less precise: `q001`→`0.001`, `q9`→`0.9`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:63,usability,simpl,simplify,63,"> I ended up with […] Does it looks ok to you? Yeah! You could simplify though:. ```py. VMinMax = Union[str, float, Callable[[Sequence[float]], float]]. def embedding(. ... vmin: Union[VMinMax, Sequence[VMinMax], None] = None,. vmax: Union[VMinMax, Sequence[VMinMax], None] = None,. ... ): ... def _get_vmin_vmax(. vmin: Sequence[VMinMax],. vmax: Sequence[VMinMax],. ... ) -> ...: ... ```. > It's not a big deal but if we use numbers in 0-100 range for vmax-vmin, it's a percentile, so p80 makes more sense. you can also be more or less precise: `q001`→`0.001`, `q9`→`0.9`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:434,availability,robust,robust,434,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:132,energy efficiency,current,current,132,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:66,modifiability,pac,packages,66,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:236,modifiability,paramet,parameter,236,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:423,modifiability,paramet,parameter,423,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:434,reliability,robust,robust,434,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:84,safety,input,input,84,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:193,safety,compl,complicated,193,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:434,safety,robust,robust,434,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:193,security,compl,complicated,193,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:84,usability,input,input,84,"@ivirshup I looked around and could not find any example in other packages that use input strings as in this case. I agree that the current solution is not ideal, but other solutions seem more complicated. For example, we can add a new parameter called `percentile` that then interprets `vmin` and `vmax` as percentiles/quantiles. However, this limits the option to mix different types of values. . In seaborn they use the parameter `robust` to set vmin and vmax as the .02 and .98 quantiles but the quantiles can not be changed. . Unless we have a strong opinion against this solution I suggest we keep it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:13,energy efficiency,Optim,Optimally,13,"Looks great! Optimally we’d add a test image like the bottom one in https://github.com/theislab/scanpy/pull/794#issuecomment-523515331, but I’d be up for merging this as-is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:34,safety,test,test,34,"Looks great! Optimally we’d add a test image like the bottom one in https://github.com/theislab/scanpy/pull/794#issuecomment-523515331, but I’d be up for merging this as-is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:34,testability,test,test,34,"Looks great! Optimally we’d add a test image like the bottom one in https://github.com/theislab/scanpy/pull/794#issuecomment-523515331, but I’d be up for merging this as-is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:48,availability,cluster,clusters,48,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:136,availability,cluster,cluster,136,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:626,availability,cluster,clusters,626,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:688,availability,cluster,clusters,688,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:48,deployability,cluster,clusters,48,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:136,deployability,cluster,cluster,136,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:626,deployability,cluster,clusters,626,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:688,deployability,cluster,clusters,688,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:797,deployability,scale,scale,797,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:797,energy efficiency,scale,scale,797,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:305,modifiability,exten,extent,305,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:797,modifiability,scal,scale,797,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:797,performance,scale,scale,797,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:289,usability,clear,clear,289,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:421,usability,indicat,indication,421,"> For having an outline to separate overlapping clusters, I don't think I like that one of the outlines would be plotted over the other cluster. In the plots shown above ([#794 (comment)](https://github.com/theislab/scanpy/pull/794#issuecomment-523515331)) I think the upper image is less clear about the extent of the overlap than the lower one, and suggests a greater importance of group `3`. Maybe there could be some indication of ambiguity for the region of overlap? @ivirshup I see your point regarding the accurate representation of what is shown. My thoughts were more along the lines of making it easy to distinguish clusters. That would be particularly useful when you have >20 clusters that are hard to distinguish by colours alone. And the overlaps may not be as important for a large-scale overview.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:419,interoperability,format,format,419,"I cannot get the new percentile feature to work, am I doing something wrong? ```python. %pdb. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pl.embedding(adata, basis='umap', color='CST3', vmax='p90'). ```. ![image](https://user-images.githubusercontent.com/1140359/64831556-445fe980-d5a4-11e9-9449-c27a04c3227c.png). Even if the format is wrong it should be ignored, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:313,usability,user,user-images,313,"I cannot get the new percentile feature to work, am I doing something wrong? ```python. %pdb. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata). sc.tl.umap(adata). sc.pl.embedding(adata, basis='umap', color='CST3', vmax='p90'). ```. ![image](https://user-images.githubusercontent.com/1140359/64831556-445fe980-d5a4-11e9-9449-c27a04c3227c.png). Even if the format is wrong it should be ignored, no?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:218,usability,hint,hints,218,"Type checking would have caught this quite easily because `vmax` is not a sequence in `sc.pl.embedding(adata, basis='umap', color='CST3', vmax='p90')` call. @flying-sheep why don't we use mypy et al. for checking type hints?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:53,reliability,doe,doesn,53,"Hmm, there’s this code in `embedding` which probably doesn‘t work as `List` here is `typing.List` instead of `collections.abc.List`. ```r. if not isinstance(vmax, List):. vmax = [vmax]. ```. Don’t know how I missed this. The correct check would of course be:. ```r. if isinstance(vmax, str) or not isinstance(vmax, collections.abc.Sequence):. vmax = [vmax]. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:92,availability,error,error,92,I am surprised that this is coming out. I thought I had solved the issue as I don't get the error. Thanks @flying-sheep for addressing this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:92,performance,error,error,92,I am surprised that this is coming out. I thought I had solved the issue as I don't get the error. Thanks @flying-sheep for addressing this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:92,safety,error,error,92,I am surprised that this is coming out. I thought I had solved the issue as I don't get the error. Thanks @flying-sheep for addressing this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:92,usability,error,error,92,I am surprised that this is coming out. I thought I had solved the issue as I don't get the error. Thanks @flying-sheep for addressing this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/794:35,energy efficiency,current,current,35,"Hmm, the code in this PR isn’t the current code anymore. I’m fixing it in #839",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/794
https://github.com/scverse/scanpy/pull/797:12,deployability,fail,failing,12,The test is failing because `scipy.stats` is not a wanted import. Let me know how you'd like to deal with that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:12,reliability,fail,failing,12,The test is failing because `scipy.stats` is not a wanted import. Let me know how you'd like to deal with that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:4,safety,test,test,4,The test is failing because `scipy.stats` is not a wanted import. Let me know how you'd like to deal with that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:4,testability,test,test,4,The test is failing because `scipy.stats` is not a wanted import. Let me know how you'd like to deal with that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:58,usability,clear,clear,58,@fidelram lemme know if the new comments make things more clear,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:114,deployability,fail,failing,114,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing? - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:125,energy efficiency,Current,Currently,125,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing? - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:114,reliability,fail,failing,114,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing? - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:106,safety,test,test,106,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing? - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:106,testability,test,test,106,"@ivirshup @flying-sheep I would like to merge this code but I have some questions:. - Do you know why the test is failing? - Currently, this is located in `preprocessing`, but I think that the right place is `external.pp` would you agree on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:220,availability,slo,slow-to-import,220,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:472,availability,slo,slow,472,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:862,availability,state,state,862,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:30,deployability,fail,failing,30,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:85,energy efficiency,reduc,reducing,85,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:595,energy efficiency,Current,Currently,595,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:854,energy efficiency,current,current,854,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:862,integrability,state,state,862,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:235,modifiability,pac,packages,235,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:361,modifiability,pac,packages,361,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:101,performance,time,times,101,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:30,reliability,fail,failing,30,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:220,reliability,slo,slow-to-import,220,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:472,reliability,slo,slow,472,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:22,safety,test,test,22,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:288,safety,test,test,288,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:22,testability,test,test,22,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:288,testability,test,test,288,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:173,usability,effectiv,effectively,173,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:802,usability,tool,tool,802,"> Do you know why the test is failing? @flying-sheep and I have put some effort into reducing import times for scanpy (they were getting up to a few seconds). This can most effectively be done by deferring the import of slow-to-import packages until they're actually needed. Phil added a test which blacklists top level import of some of particularly egregious packages (scipy and seaboarn for example). Here, the imports for `argrelextrema` and `gaussian_kde` are pretty slow (about half a second). These should be moved inside `_demultiplex_per_barcode` function instead of being top level. > Currently, this is located in preprocessing, but I think that the right place is external.pp would you agree on that? I think I would be fine with this going in preprocessing, since it isn't tied to another tool/ code base. I'm also not too familiar with the current state of demultiplexing techniques so I'd be fine to defer to you on this. Could you elaborate on why you think it should go in external?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:90,availability,state,statements,90,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:158,availability,error,errors,158,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:90,integrability,state,statements,90,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:290,modifiability,responsibil,responsibility,290,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:158,performance,error,errors,158,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:153,safety,test,test,153,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:158,safety,error,errors,158,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:270,safety,test,tested,270,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:153,testability,test,test,153,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:270,testability,test,tested,270,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:158,usability,error,errors,158,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:180,usability,tool,tool,180,@ivirshup : Thanks for the background explanation. . @njbernstein Can you move the import statements inside the `_demultiplex_per_barcode` to remove the test errors? . I think the tool should go to `external` to point out that this is based on a method that we have not tested and thus the responsibility of its accuracy and implementation lies on the external contributor. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:260,performance,network,networkx,260,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:46,safety,test,test,46,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:260,security,network,networkx,260,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:46,testability,test,test,46,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:420,testability,assert,assert,420,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:451,testability,Assert,AssertionError,451,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:467,testability,assert,assert,467,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:35,usability,document,documented,35,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:233,usability,tool,tools,233,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:527,usability,clear,clearer,527,"Hmm, I’m pretty happy with my self-documented test code:. ```py. def test_deferred_imports(imported_modules):. slow_to_import = {. 'umap', # neighbors, tl.umap. 'seaborn', # plotting. 'sklearn.metrics', # neighbors. 'scipy.stats', # tools._embedding_density. 'networkx', # diffmap, paga, plotting._utils. # TODO: 'matplotlib.pyplot',. # TODO (maybe): 'numba',. }. falsely_imported = slow_to_import & imported_modules. > assert not falsely_imported. E AssertionError: assert not {'scipy.stats'}. ```. Do you think this could be clearer?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:82,availability,error,error,82,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:232,availability,Slo,Slow,232,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:286,availability,slo,slow-to-import,286,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:160,energy efficiency,reduc,reduce,160,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:301,modifiability,pac,packages,301,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:82,performance,error,error,82,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:174,performance,time,times,174,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:232,reliability,Slo,Slow,232,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:286,reliability,slo,slow-to-import,286,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:82,safety,error,error,82,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:244,safety,detect,detected,244,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:244,security,detect,detected,244,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:36,usability,clear,clear,36,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/pull/797:82,usability,error,error,82,"@flying-sheep I think the output is clear once you know what is about. Since this error may happen to future contributions that are not aware of the efforts to reduce import times, I think is better to be explicit. Something like: ""Slow import detected (scipy.stats). Please check that slow-to-import packages are not in top level calls but inside the functions that require them"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/797
https://github.com/scverse/scanpy/issues/799:10,usability,document,documentation,10,"check the documentation for AnnData concatenate: https://anndata.readthedocs.io/en/latest/anndata.AnnData.concatenate.html#anndata.AnnData.concatenate. You can add a label to each cell to know from which project it comes. ```. adata = adatas[0].concatenate(adatas[1:], batch_key='filename', batch_categories=filenames). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/799
https://github.com/scverse/scanpy/issues/800:150,availability,error,error,150,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:306,availability,error,error,306,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:150,performance,error,error,150,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:306,performance,error,error,306,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:150,safety,error,error,150,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:306,safety,error,error,306,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:150,usability,error,error,150,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:306,usability,error,error,306,Minor addendum that I'm not sure is worth it's own issue. I had thought we were gonna use `q` instead of `p` for the prefix of the string values. The error that raised was:. ```python. ValueError: could not convert string to float: 'q99'. ```. I think we should probably recommend the correct usage in the error instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:186,integrability,translat,translates,186,"Thanks for pointing this out. Now should be solved. . With respect to `q` for quantiles vs `p` for percentiles, I took one of the suggestions on the PR #794 as I agreed that `p99` which translates to `percentile=99` is more direct than `q99` translating to `q=.99`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:242,integrability,translat,translating,242,"Thanks for pointing this out. Now should be solved. . With respect to `q` for quantiles vs `p` for percentiles, I took one of the suggestions on the PR #794 as I agreed that `p99` which translates to `percentile=99` is more direct than `q99` translating to `q=.99`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:186,interoperability,translat,translates,186,"Thanks for pointing this out. Now should be solved. . With respect to `q` for quantiles vs `p` for percentiles, I took one of the suggestions on the PR #794 as I agreed that `p99` which translates to `percentile=99` is more direct than `q99` translating to `q=.99`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:242,interoperability,translat,translating,242,"Thanks for pointing this out. Now should be solved. . With respect to `q` for quantiles vs `p` for percentiles, I took one of the suggestions on the PR #794 as I agreed that `p99` which translates to `percentile=99` is more direct than `q99` translating to `q=.99`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:127,availability,error,error,127,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:133,integrability,messag,message,133,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:133,interoperability,messag,message,133,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:263,interoperability,specif,specified,263,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:127,performance,error,error,127,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:99,reliability,doe,doesn,99,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:127,safety,error,error,127,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:188,testability,understand,understand,188,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:73,usability,user,user,73,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:127,usability,error,error,127,"Thanks for the fix! For the `p` vs `q` thing, I was just thinking if the user passes a string that doesn't start with `p`, the error message could be something like `""ValueError: Couldn't understand string value '{passed_val}' for vmax. Percentile cutoffs can be specified like 'p99' (99th percentile).""`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:8,availability,error,error,8,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:8,performance,error,error,8,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:8,safety,error,error,8,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:50,safety,valid,valid,50,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:70,safety,valid,valid,70,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:8,usability,error,error,8,"Now the error is something like: The value is not valid, please use a valid number a percentile as `pN` or a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:58,availability,error,error,58,That's good too. Right now it's throwing a warning not an error. Is that meant to happen?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:58,performance,error,error,58,That's good too. Right now it's throwing a warning not an error. Is that meant to happen?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:58,safety,error,error,58,That's good too. Right now it's throwing a warning not an error. Is that meant to happen?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/800:58,usability,error,error,58,That's good too. Right now it's throwing a warning not an error. Is that meant to happen?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/800
https://github.com/scverse/scanpy/issues/909:447,availability,error,error,447,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:364,deployability,automat,automatically,364,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:447,performance,error,error,447,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:447,safety,error,error,447,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:364,testability,automat,automatically,364,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:447,usability,error,error,447,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:453,usability,indicat,indicates,453,"You can’t supply a string here, as mentioned in the docstring:. > `root`: If choosing a tree layout, this is the index of the root node or a list of root node indices. If this is a non-empty vector then the supplied node IDs are used as the roots of the trees (or a single tree if the graph is connected). If this is `None` or an empty list, the root vertices are automatically calculated based on topological sorting. @falexwolf the code for the error indicates that supplying a string is intended, but not properly implemented. I quickly whipped up #910, please finish it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:184,availability,error,error,184,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:184,performance,error,error,184,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:184,safety,error,error,184,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:100,testability,plan,planaria,100,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:109,testability,plan,planaria,109,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/issues/909:184,usability,error,error,184,"I do want to know why this [jupyter notebook](https://nbviewer.org/github/theislab/paga/blob/master/planaria/planaria.ipynb) can use 'neoblast 1' as root, a string you know, but cause error now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/909
https://github.com/scverse/scanpy/pull/805:17,usability,user,user-images,17,![image](https://user-images.githubusercontent.com/1140359/63978752-28792580-ca85-11e9-95db-fc905d7ac831.png). Maybe we should consider making this True by default.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:149,energy efficiency,load,loadings,149,"Is it that useful to see it by default? Why would you want to know unimportant genes? IMHO it would be more interesting to know genes that have high loadings in another early PC but not in this one, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:149,performance,load,loadings,149,"Is it that useful to see it by default? Why would you want to know unimportant genes? IMHO it would be more interesting to know genes that have high loadings in another early PC but not in this one, right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:12,energy efficiency,load,loadings,12,Hi negative loadings are also important genes as you can see on the example of `LTB` and `HLA-DRA`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:12,performance,load,loadings,12,Hi negative loadings are also important genes as you can see on the example of `LTB` and `HLA-DRA`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:91,integrability,discover,discovered,91,"I didn't see these comments @flying-sheep , sorry about that and thanks for taking care. I discovered a bug today, ""⋮"" character is not visible on some machines:. ![image](https://user-images.githubusercontent.com/1140359/64285676-facf2900-cf29-11e9-88e7-e8fbeae1fd8f.png). Any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:91,interoperability,discover,discovered,91,"I didn't see these comments @flying-sheep , sorry about that and thanks for taking care. I discovered a bug today, ""⋮"" character is not visible on some machines:. ![image](https://user-images.githubusercontent.com/1140359/64285676-facf2900-cf29-11e9-88e7-e8fbeae1fd8f.png). Any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:91,usability,discov,discovered,91,"I didn't see these comments @flying-sheep , sorry about that and thanks for taking care. I discovered a bug today, ""⋮"" character is not visible on some machines:. ![image](https://user-images.githubusercontent.com/1140359/64285676-facf2900-cf29-11e9-88e7-e8fbeae1fd8f.png). Any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:180,usability,user,user-images,180,"I didn't see these comments @flying-sheep , sorry about that and thanks for taking care. I discovered a bug today, ""⋮"" character is not visible on some machines:. ![image](https://user-images.githubusercontent.com/1140359/64285676-facf2900-cf29-11e9-88e7-e8fbeae1fd8f.png). Any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:80,availability,avail,available,80,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:59,deployability,Depend,Depends,59,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:135,deployability,stack,stack,135,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:306,deployability,version,versions,306,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:59,integrability,Depend,Depends,59,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:306,integrability,version,versions,306,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:402,interoperability,distribut,distribution,402,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:593,interoperability,heterogen,heterogenous,593,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:59,modifiability,Depend,Depends,59,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:306,modifiability,version,versions,306,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:80,reliability,availab,available,80,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:59,safety,Depend,Depends,59,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:80,safety,avail,available,80,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:80,security,availab,available,80,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:59,testability,Depend,Depends,59,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:373,usability,support,supported,373,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:519,usability,minim,minimalistically,519,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:572,usability,support,support,572,"I think it’s pretty impossible to know if they’ll render – Depends on the fonts available on the system and the way the font rendering stack falls back to other fonts. My approach would be to check which systems have the problem, and if it’s only some Linux server or some obsolete stuff like e.g. Windows versions up to Vista, ignore it. If it’s a commonly used and still supported desktop OS / Linux distribution, we have to deal with it. The reason I excluded Linux servers is that server admins often set up things minimalistically, excluding “GUI stuff” so trying to support those highly heterogenous systems will only bring pain. When people want better fonts, then fontconfig is happy to provide them with the means to do so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:372,usability,user,user-images,372,"@flying-sheep I hit this vertical ellipsis bug again. I think the problem is that, at least on this machine, setting default sans-serif font to Arial messes up the rendering of ""⋮"" character. Rendering is fine with DejaVu or Helvetica though. Any ideas why Arial is problematic on Mac OS? Why do we change Matplotlib ""font.sans-serif"" anyway? See below:. ![image](https://user-images.githubusercontent.com/1140359/67689171-4d005980-f971-11e9-930a-d5419fccf2f4.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:95,deployability,updat,updated,95,"> Why do we change Matplotlib ""font.sans-serif"" anyway? No idea, I don’t even like Arial. Alex updated the fonts last in 6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2, and setting the fonts happened in the initial commit:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. @falexwolf do you recall why you did that? Can we just remove that line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:95,safety,updat,updated,95,"> Why do we change Matplotlib ""font.sans-serif"" anyway? No idea, I don’t even like Arial. Alex updated the fonts last in 6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2, and setting the fonts happened in the initial commit:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. @falexwolf do you recall why you did that? Can we just remove that line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:95,security,updat,updated,95,"> Why do we change Matplotlib ""font.sans-serif"" anyway? No idea, I don’t even like Arial. Alex updated the fonts last in 6c68b8ba2821f27bd0b8f499a1d543dff9cc51b2, and setting the fonts happened in the initial commit:. https://github.com/theislab/scanpy/blob/c22e48abe45a6ccca5918bbf689637caa4b31250/scanpy/plotting.py#L605. @falexwolf do you recall why you did that? Can we just remove that line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:137,integrability,standardiz,standardize,137,"There are plots that are very sensitive to font type/size, I think, like rank plots (e.g. `sc.pl.pca_loadings`). Alex did it in order to standardize the style of plots and to prevent unexpected things, I guess. . If this is only a ⋮ problem, we can switch to ""..."", it's not a big deal. Interestingly, Arial on my laptop can render other unicode characters well, ⋮ is problematic though :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:137,interoperability,standard,standardize,137,"There are plots that are very sensitive to font type/size, I think, like rank plots (e.g. `sc.pl.pca_loadings`). Alex did it in order to standardize the style of plots and to prevent unexpected things, I guess. . If this is only a ⋮ problem, we can switch to ""..."", it's not a big deal. Interestingly, Arial on my laptop can render other unicode characters well, ⋮ is problematic though :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:175,safety,prevent,prevent,175,"There are plots that are very sensitive to font type/size, I think, like rank plots (e.g. `sc.pl.pca_loadings`). Alex did it in order to standardize the style of plots and to prevent unexpected things, I guess. . If this is only a ⋮ problem, we can switch to ""..."", it's not a big deal. Interestingly, Arial on my laptop can render other unicode characters well, ⋮ is problematic though :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:175,security,preven,prevent,175,"There are plots that are very sensitive to font type/size, I think, like rank plots (e.g. `sc.pl.pca_loadings`). Alex did it in order to standardize the style of plots and to prevent unexpected things, I guess. . If this is only a ⋮ problem, we can switch to ""..."", it's not a big deal. Interestingly, Arial on my laptop can render other unicode characters well, ⋮ is problematic though :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/805:0,deployability,Continu,Continued,0,Continued in #897,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/805
https://github.com/scverse/scanpy/pull/806:28,safety,test,test,28,Great! Will this change the test pics? If not LGTM.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806
https://github.com/scverse/scanpy/pull/806:28,testability,test,test,28,Great! Will this change the test pics? If not LGTM.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806
https://github.com/scverse/scanpy/pull/806:21,safety,test,test,21,"There is no plotting test for PAGA, I think. It'd be great to have some :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806
https://github.com/scverse/scanpy/pull/806:21,testability,test,test,21,"There is no plotting test for PAGA, I think. It'd be great to have some :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806
https://github.com/scverse/scanpy/pull/806:20,safety,test,tests,20,Added PAGA plotting tests and merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806
https://github.com/scverse/scanpy/pull/806:20,testability,test,tests,20,Added PAGA plotting tests and merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/806
https://github.com/scverse/scanpy/issues/807:54,deployability,instal,installed,54,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:70,deployability,contain,contains,70,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:147,deployability,contain,containing,147,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:32,interoperability,distribut,distribution,32,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:118,interoperability,distribut,distribution,118,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:92,modifiability,pac,package,92,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:162,modifiability,pac,package,162,for the record: @odorea had the distribution “igraph” installed which contains the “jgraph” package. Scanpy needs the distribution “python-igraph” containing hte package “igraph”. … which is all confusing and annoying so I appreciate that “jgraph” has changed its name away from “igraph”.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:27,availability,error,error,27,"Hi, I encountered the same error as odorea. But it could not be solved by renaming `igraph` to `jgraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:27,performance,error,error,27,"Hi, I encountered the same error as odorea. But it could not be solved by renaming `igraph` to `jgraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:27,safety,error,error,27,"Hi, I encountered the same error as odorea. But it could not be solved by renaming `igraph` to `jgraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:27,usability,error,error,27,"Hi, I encountered the same error as odorea. But it could not be solved by renaming `igraph` to `jgraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:22,deployability,instal,install,22,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:84,deployability,instal,install,84,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:160,deployability,updat,update,160,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:135,modifiability,pac,package,135,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:160,safety,updat,update,160,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:160,security,updat,update,160,"Hi @YiweiNiu,. Please install `python-igraph` and not `igraph` via pip. So run `pip install python-igraph` and get rid of the `igraph` package. You may have to update you `pip` as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:293,integrability,sub,subscribed,293,"Is there a way to blacklist igraph and umap packages in setup.py to avoid. further confusion? On Tue, Sep 24, 2019, 12:13 PM Yiwei Niu <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD> Thank you very much! It woks now. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/807?email_source=notifications&email_token=AAIWNB5YP7V74NDJXNEZJ6DQLHR4HA5CNFSM4ISZVL6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7N3DPA#issuecomment-534491580>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAIWNBZCSV4KT2AYXIS43BTQLHR4HANCNFSM4ISZVL6A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:44,modifiability,pac,packages,44,"Is there a way to blacklist igraph and umap packages in setup.py to avoid. further confusion? On Tue, Sep 24, 2019, 12:13 PM Yiwei Niu <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD> Thank you very much! It woks now. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/807?email_source=notifications&email_token=AAIWNB5YP7V74NDJXNEZJ6DQLHR4HA5CNFSM4ISZVL6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7N3DPA#issuecomment-534491580>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAIWNBZCSV4KT2AYXIS43BTQLHR4HANCNFSM4ISZVL6A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:68,safety,avoid,avoid,68,"Is there a way to blacklist igraph and umap packages in setup.py to avoid. further confusion? On Tue, Sep 24, 2019, 12:13 PM Yiwei Niu <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD> Thank you very much! It woks now. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/807?email_source=notifications&email_token=AAIWNB5YP7V74NDJXNEZJ6DQLHR4HA5CNFSM4ISZVL6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7N3DPA#issuecomment-534491580>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAIWNBZCSV4KT2AYXIS43BTQLHR4HANCNFSM4ISZVL6A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:667,security,auth,auth,667,"Is there a way to blacklist igraph and umap packages in setup.py to avoid. further confusion? On Tue, Sep 24, 2019, 12:13 PM Yiwei Niu <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD> Thank you very much! It woks now. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/807?email_source=notifications&email_token=AAIWNB5YP7V74NDJXNEZJ6DQLHR4HA5CNFSM4ISZVL6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7N3DPA#issuecomment-534491580>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAIWNBZCSV4KT2AYXIS43BTQLHR4HANCNFSM4ISZVL6A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:52,deployability,instal,installed,52,"scanpy could just check on import if one of them is installed instead of the package that should be installed, and raise a nicely phrased ImportError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:100,deployability,instal,installed,100,"scanpy could just check on import if one of them is installed instead of the package that should be installed, and raise a nicely phrased ImportError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:77,modifiability,pac,package,77,"scanpy could just check on import if one of them is installed instead of the package that should be installed, and raise a nicely phrased ImportError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:111,availability,error,error,111,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:177,availability,ERROR,ERROR,177,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:262,availability,error,error,262,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:64,deployability,instal,installing,64,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:120,deployability,Instal,Installing,120,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:194,deployability,instal,install,194,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:345,energy efficiency,draw,drawing,345,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:141,modifiability,pac,packages,141,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:202,modifiability,pac,packages,202,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:329,modifiability,pac,packages,329,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:111,performance,error,error,111,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:177,performance,ERROR,ERROR,177,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:262,performance,error,error,262,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:372,reliability,doe,doesn,372,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:111,safety,error,error,111,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:177,safety,ERROR,ERROR,177,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:249,safety,Input,Input,249,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:262,safety,error,error,262,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:111,usability,error,error,111,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:177,usability,ERROR,ERROR,177,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:249,usability,Input,Input,249,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:262,usability,error,error,262,"@LuckyMD . Hi, LuckyMD. I tried pip uninstalling igraph and pip installing python-igraph and got the following error:. ""Installing collected packages: texttable, python-igraph. ERROR: Could not install packages due to an EnvironmentError: [Errno 5] Input/output error: '/home/blahblah/miniconda2/envs/funkyLab/lib/python3.7/site-packages/igraph/drawing/__pycache__' "". It doesn't say anything more. Do you have an idea of what the problem may be? . Thank you. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:52,energy efficiency,load,loaded,52,"Hi @o0stsou0o ,. Could it be that you have `igraph` loaded somewhere while you were uninstalling? Not sure why you can't remove `igraph` otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:52,performance,load,loaded,52,"Hi @o0stsou0o ,. Could it be that you have `igraph` loaded somewhere while you were uninstalling? Not sure why you can't remove `igraph` otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/807:58,deployability,instal,installing,58,"Hi @LuckyMD,. Thank you. Oddly, I went to sleep and tried installing 'python-igraph' again the next day and it worked just fine. I can only assume pip was being moody the first day. Thank you again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/807
https://github.com/scverse/scanpy/issues/808:391,usability,close,closed,391,"Hey! . Check out [anndata2ri](https://github.com/theislab/anndata2ri) and how to use it to convert Seurat objects into scanpy on the fly in a Juptyer notebook [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb). This is the easiest way to convert between the two objects. However, going via loom files should also work. If you search the scanpy issues (also closed issues) you should find some examples. You can of course also use the anndata creator `anndata.AnnData()` to create a new object. Note that the expression matrix needs to be transposed between R and python analysis tools though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:613,usability,tool,tools,613,"Hey! . Check out [anndata2ri](https://github.com/theislab/anndata2ri) and how to use it to convert Seurat objects into scanpy on the fly in a Juptyer notebook [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb). This is the easiest way to convert between the two objects. However, going via loom files should also work. If you search the scanpy issues (also closed issues) you should find some examples. You can of course also use the anndata creator `anndata.AnnData()` to create a new object. Note that the expression matrix needs to be transposed between R and python analysis tools though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:134,availability,error,error,134,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:53,deployability,fail,failed,53,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:170,interoperability,specif,specific,170,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:134,performance,error,error,134,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:53,reliability,fail,failed,53,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:134,safety,error,error,134,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/issues/808:134,usability,error,error,134,"> anndata.AnnData(). Thank you for you suggestion! I failed all other methods, including anndata2ri. God know why I encounter so much error. And I've posted issue in the specific place.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/808
https://github.com/scverse/scanpy/pull/809:74,energy efficiency,heat,heatmap,74,"LGTM! Any idea if this effects any of the matrix plotting functions, like heatmap?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809
https://github.com/scverse/scanpy/pull/809:196,availability,cluster,clustermap,196,"We already have tests for heatmap and matrixplot and it seems they are unaffected. We process the color vector differently there, I think. I'm not entirely sure how that happened and for how long clustermap is broken. Maybe a recent change in seaborn or pandas triggered it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809
https://github.com/scverse/scanpy/pull/809:196,deployability,cluster,clustermap,196,"We already have tests for heatmap and matrixplot and it seems they are unaffected. We process the color vector differently there, I think. I'm not entirely sure how that happened and for how long clustermap is broken. Maybe a recent change in seaborn or pandas triggered it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809
https://github.com/scverse/scanpy/pull/809:26,energy efficiency,heat,heatmap,26,"We already have tests for heatmap and matrixplot and it seems they are unaffected. We process the color vector differently there, I think. I'm not entirely sure how that happened and for how long clustermap is broken. Maybe a recent change in seaborn or pandas triggered it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809
https://github.com/scverse/scanpy/pull/809:16,safety,test,tests,16,"We already have tests for heatmap and matrixplot and it seems they are unaffected. We process the color vector differently there, I think. I'm not entirely sure how that happened and for how long clustermap is broken. Maybe a recent change in seaborn or pandas triggered it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809
https://github.com/scverse/scanpy/pull/809:16,testability,test,tests,16,"We already have tests for heatmap and matrixplot and it seems they are unaffected. We process the color vector differently there, I think. I'm not entirely sure how that happened and for how long clustermap is broken. Maybe a recent change in seaborn or pandas triggered it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/809
https://github.com/scverse/scanpy/issues/810:89,energy efficiency,profil,profiling,89,"Did you simply set the verbosity to a higher level to get timings or did you have to use profiling or modify the code? If the latter, it might be helpful for more people to do more fine-grained timings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:89,performance,profil,profiling,89,"Did you simply set the verbosity to a higher level to get timings or did you have to use profiling or modify the code? If the latter, it might be helpful for more people to do more fine-grained timings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:102,security,modif,modify,102,"Did you simply set the verbosity to a higher level to get timings or did you have to use profiling or modify the code? If the latter, it might be helpful for more people to do more fine-grained timings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:8,testability,simpl,simply,8,"Did you simply set the verbosity to a higher level to get timings or did you have to use profiling or modify the code? If the latter, it might be helpful for more people to do more fine-grained timings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:8,usability,simpl,simply,8,"Did you simply set the verbosity to a higher level to get timings or did you have to use profiling or modify the code? If the latter, it might be helpful for more people to do more fine-grained timings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:146,usability,help,helpful,146,"Did you simply set the verbosity to a higher level to get timings or did you have to use profiling or modify the code? If the latter, it might be helpful for more people to do more fine-grained timings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:124,deployability,depend,depend,124,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:124,integrability,depend,depend,124,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:124,modifiability,depend,depend,124,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:55,performance,time,time,55,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:114,performance,time,time,114,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:124,safety,depend,depend,124,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:124,testability,depend,depend,124,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:3,usability,intuit,intuition,3,"My intuition would be neighbor finding would take more time as dataset size increases. What exact fraction of the time will depend a lot on number of samples, number of features, and possibly distance metric. If you're investigating yourself, I think trying `line_profiler`'s `%lprun` on `umap.UMAP.fit` would be a good bet. I'd also bet that they'd have a better idea over at `UMAP` or Pynndescent.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:72,deployability,continu,continue,72,"I’ll close this so the issue tracker isn’t blown up too much, but we’ll continue to reply",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:5,usability,close,close,5,"I’ll close this so the issue tracker isn’t blown up too much, but we’ll continue to reply",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:11,safety,test,tested,11,"hi, I just tested a few runs where I added a few lines of code within the compute_neighbors() and compute_connectivites() functions and get the following (in seconds) (thanks for the suggestion using line_profiler, i'll give that a shot later:. ![image](https://user-images.githubusercontent.com/35950152/64389655-20694900-d076-11e9-8b39-e0ee75c36db9.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:11,testability,test,tested,11,"hi, I just tested a few runs where I added a few lines of code within the compute_neighbors() and compute_connectivites() functions and get the following (in seconds) (thanks for the suggestion using line_profiler, i'll give that a shot later:. ![image](https://user-images.githubusercontent.com/35950152/64389655-20694900-d076-11e9-8b39-e0ee75c36db9.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/issues/810:262,usability,user,user-images,262,"hi, I just tested a few runs where I added a few lines of code within the compute_neighbors() and compute_connectivites() functions and get the following (in seconds) (thanks for the suggestion using line_profiler, i'll give that a shot later:. ![image](https://user-images.githubusercontent.com/35950152/64389655-20694900-d076-11e9-8b39-e0ee75c36db9.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/810
https://github.com/scverse/scanpy/pull/812:156,testability,context,context,156,Thanks for the PR! Gene-set based annotation would be pretty useful to have here. Is there any chance there's a preprint we could look at for a little more context on the method?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:16,energy efficiency,current,currently,16,@ivirshup it is currently in writing. Will write back to you when we will have it ready.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:4,deployability,updat,update,4,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:49,modifiability,reu,reusing,49,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:4,safety,updat,update,4,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:34,safety,test,test,34,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:4,security,updat,update,4,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:34,testability,test,test,34,Any update on this? Can you add a test (probably reusing the example already in the method docstring)?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:178,deployability,observ,observed,178,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:210,modifiability,pac,packages,210,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:82,safety,test,tests,82,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:109,safety,test,test,109,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:82,testability,test,tests,82,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:109,testability,test,test,109,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:178,testability,observ,observed,178,"@fidelram, we are still working paper/preprint. I will post it soon. . I will add tests. So in order for the test to work should I add my library in the requirements.txt? What I observed is that other external packages are not included in project requirements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:106,deployability,instal,install,106,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python. from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""). ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:305,deployability,instal,installed,305,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python. from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""). ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:504,integrability,event,eventually,504,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python. from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""). ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:357,modifiability,pac,package,357,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python. from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""). ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:554,safety,test,testing,554,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python. from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""). ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:554,testability,test,testing,554,"@PrimozGodec, probably don't add this to `requirements.txt`, since the requirement should be optional for install. I think instead you should mark it with something like:. ```python. from importlib.util import find_spec. @pytest.mark.skipif(find_spec('pointannotator') is None, reason=""pointannotator not installed""). ```. You can add a requirement for the package to this line in `setup.py`: https://github.com/theislab/scanpy/blob/d8f32c040f3a5f4fc07998b269796ca58de84b40/setup.py#L41. Maybe we should eventually have a second requirements file for CI testing, like we do for anndata.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:13,safety,test,tests,13,I added unit tests and reformated the code. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:8,testability,unit,unit,8,I added unit tests and reformated the code. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:13,testability,test,tests,13,I added unit tests and reformated the code. .,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:58,safety,test,tests,58,"Thank you. We’re using pytest though, so please write the tests that way:. 1. Remove the class and make all its methods top-level functions. 2. Make `setUp` into `fixture`s. 3. Just use `assert`. ```py. @pytest.fixture. def markers():. return pd.DataFrame(. ... ). @pytest.fixture. def adata():. ... return AnnData(data.values, var=data.columns.values). def test_remove_empty_column(adata, markers):. ... annotations = annotator(adata, markers, num_genes=20). ... assert len(annotations) == len(self.anndata). ... ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:58,testability,test,tests,58,"Thank you. We’re using pytest though, so please write the tests that way:. 1. Remove the class and make all its methods top-level functions. 2. Make `setUp` into `fixture`s. 3. Just use `assert`. ```py. @pytest.fixture. def markers():. return pd.DataFrame(. ... ). @pytest.fixture. def adata():. ... return AnnData(data.values, var=data.columns.values). def test_remove_empty_column(adata, markers):. ... annotations = annotator(adata, markers, num_genes=20). ... assert len(annotations) == len(self.anndata). ... ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:187,testability,assert,assert,187,"Thank you. We’re using pytest though, so please write the tests that way:. 1. Remove the class and make all its methods top-level functions. 2. Make `setUp` into `fixture`s. 3. Just use `assert`. ```py. @pytest.fixture. def markers():. return pd.DataFrame(. ... ). @pytest.fixture. def adata():. ... return AnnData(data.values, var=data.columns.values). def test_remove_empty_column(adata, markers):. ... annotations = annotator(adata, markers, num_genes=20). ... assert len(annotations) == len(self.anndata). ... ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:464,testability,assert,assert,464,"Thank you. We’re using pytest though, so please write the tests that way:. 1. Remove the class and make all its methods top-level functions. 2. Make `setUp` into `fixture`s. 3. Just use `assert`. ```py. @pytest.fixture. def markers():. return pd.DataFrame(. ... ). @pytest.fixture. def adata():. ... return AnnData(data.values, var=data.columns.values). def test_remove_empty_column(adata, markers):. ... annotations = annotator(adata, markers, num_genes=20). ... assert len(annotations) == len(self.anndata). ... ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:31,availability,sli,slight,31,"Only remaining thought: I have slight concerns about the name being too generic, but then again, this does exactly what people expect a “cell type annotator based on marker genes” to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:38,modifiability,concern,concerns,38,"Only remaining thought: I have slight concerns about the name being too generic, but then again, this does exactly what people expect a “cell type annotator based on marker genes” to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:31,reliability,sli,slight,31,"Only remaining thought: I have slight concerns about the name being too generic, but then again, this does exactly what people expect a “cell type annotator based on marker genes” to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:102,reliability,doe,does,102,"Only remaining thought: I have slight concerns about the name being too generic, but then again, this does exactly what people expect a “cell type annotator based on marker genes” to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:38,testability,concern,concerns,38,"Only remaining thought: I have slight concerns about the name being too generic, but then again, this does exactly what people expect a “cell type annotator based on marker genes” to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:27,modifiability,pac,packages,27,We decided not to add more packages to `external` but you are more than welcome to add your own package to the scverse ecosystem: https://scverse.org/packages/#ecosystem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:96,modifiability,pac,package,96,We decided not to add more packages to `external` but you are more than welcome to add your own package to the scverse ecosystem: https://scverse.org/packages/#ecosystem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/pull/812:150,modifiability,pac,packages,150,We decided not to add more packages to `external` but you are more than welcome to add your own package to the scverse ecosystem: https://scverse.org/packages/#ecosystem,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/812
https://github.com/scverse/scanpy/issues/815:92,energy efficiency,current,currently,92,Will be fixed soon with merging scvelo's scatter. Running the same with `scvelo.pl.scatter` currently yields the following. ![image](https://user-images.githubusercontent.com/31883718/71021640-189e5380-20ff-11ea-87b9-9b20a13734a6.png). where the same color range and colorbar can be enforced by setting `vmin` and `vmax`. [using artificial values for demonstration purposes],MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/815
https://github.com/scverse/scanpy/issues/815:141,usability,user,user-images,141,Will be fixed soon with merging scvelo's scatter. Running the same with `scvelo.pl.scatter` currently yields the following. ![image](https://user-images.githubusercontent.com/31883718/71021640-189e5380-20ff-11ea-87b9-9b20a13734a6.png). where the same color range and colorbar can be enforced by setting `vmin` and `vmax`. [using artificial values for demonstration purposes],MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/815
https://github.com/scverse/scanpy/pull/816:127,usability,efficien,efficient,127,"So what’s the difference between normalize_per_cell and normalize_total? If they’re replacable, why don’t we just use the more efficient one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/816
https://github.com/scverse/scanpy/pull/816:50,usability,efficien,efficient,50,"@flying-sheep `normalize_total` is newer and more efficient. And we should use it instead of `normalize_per_cell`, yes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/816
https://github.com/scverse/scanpy/pull/816:14,deployability,fail,failing,14,"The tests are failing because there’s some master fixes missing from your branch, so this is fine!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/816
https://github.com/scverse/scanpy/pull/816:14,reliability,fail,failing,14,"The tests are failing because there’s some master fixes missing from your branch, so this is fine!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/816
https://github.com/scverse/scanpy/pull/816:4,safety,test,tests,4,"The tests are failing because there’s some master fixes missing from your branch, so this is fine!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/816
https://github.com/scverse/scanpy/pull/816:4,testability,test,tests,4,"The tests are failing because there’s some master fixes missing from your branch, so this is fine!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/816
https://github.com/scverse/scanpy/issues/817:67,modifiability,variab,variables,67,"Do you have values in `adata.raw`? Raw can have a different set of variables than `adata.var`, which could be causing the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/817
https://github.com/scverse/scanpy/issues/817:78,usability,help,help,78,"Yes, it is the adata.raw issues, fixed for set use_raw-False. Thanks for your help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/817
https://github.com/scverse/scanpy/issues/818:59,usability,interact,interactive,59,@Marius1311 might be able to tell you some more about his [interactive plotting library](https://github.com/theislab/interactive_plotting). This is however more targeted at interactive plotting in notebooks rather communicating with collaborators via servers. [Cellxgene](https://github.com/chanzuckerberg/cellxgene) from CZI is also worth taking a look at for communicating results to non-bioninformaticians.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/818
https://github.com/scverse/scanpy/issues/818:173,usability,interact,interactive,173,@Marius1311 might be able to tell you some more about his [interactive plotting library](https://github.com/theislab/interactive_plotting). This is however more targeted at interactive plotting in notebooks rather communicating with collaborators via servers. [Cellxgene](https://github.com/chanzuckerberg/cellxgene) from CZI is also worth taking a look at for communicating results to non-bioninformaticians.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/818
https://github.com/scverse/scanpy/issues/818:64,modifiability,pac,package,64,@wangjiawen2013 feel free to check out our interactive plotting package for scanpy mentioned by @LuckyMD above (https://github.com/theislab/interactive_plotting) and let me know if you have any questions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/818
https://github.com/scverse/scanpy/issues/818:43,usability,interact,interactive,43,@wangjiawen2013 feel free to check out our interactive plotting package for scanpy mentioned by @LuckyMD above (https://github.com/theislab/interactive_plotting) and let me know if you have any questions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/818
https://github.com/scverse/scanpy/issues/818:95,usability,close,close,95,There is already a discussion at https://github.com/theislab/scanpy/issues/253. I think we can close this issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/818
https://github.com/scverse/scanpy/pull/819:131,deployability,modul,modularity,131,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,deployability,modul,modularity,171,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:247,deployability,modul,modularity,247,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:59,integrability,coupl,couple,59,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:131,integrability,modular,modularity,131,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,integrability,modular,modularity,171,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:247,integrability,modular,modularity,247,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:59,modifiability,coupl,couple,59,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:131,modifiability,modul,modularity,131,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,modifiability,modul,modularity,171,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:247,modifiability,modul,modularity,247,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:131,safety,modul,modularity,131,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,safety,modul,modularity,171,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:247,safety,modul,modularity,247,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:59,testability,coupl,couple,59,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:131,testability,modula,modularity,131,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,testability,modula,modularity,171,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:247,testability,modula,modularity,247,"I think it's really good to record the key added. I have a couple questions about the quality score. * Should it still be called a modularity score if we aren't using the modularity quality function? * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. Also, should this stuff be mirrored to `leiden`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:33,deployability,modul,modularity,33,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:305,deployability,modul,modularity,305,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:191,energy efficiency,optim,optimal,191,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:33,integrability,modular,modularity,33,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:305,integrability,modular,modularity,305,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:33,modifiability,modul,modularity,33,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:305,modifiability,modul,modularity,305,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:102,performance,network,network,102,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:33,safety,modul,modularity,33,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:305,safety,modul,modularity,305,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:56,security,assess,assess,56,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:102,security,network,network,102,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:33,testability,modula,modularity,33,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:305,testability,modula,modularity,305,"I think a use case for recording modularity would be to assess the quality of a partition on the same network. Louvain or Leiden are both heuristics that are not guaranteed to get the global optimal partition. So if you run with a different random seed, you will get a different result. By outputting the modularity you can compare the quality of the partition from different random seeds.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:899,availability,cluster,clustered,899,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:139,deployability,modul,modularity,139,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:179,deployability,modul,modularity,179,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:393,deployability,modul,modularity,393,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:481,deployability,scale,scaled,481,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:488,deployability,modul,modularity,488,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:558,deployability,modul,modularity,558,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:691,deployability,scale,scaled,691,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:698,deployability,modul,modularity,698,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:899,deployability,cluster,clustered,899,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:404,energy efficiency,optim,optimization,404,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:481,energy efficiency,scale,scaled,481,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:691,energy efficiency,scale,scaled,691,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:733,energy efficiency,measur,measure,733,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:997,energy efficiency,measur,measures,997,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:61,integrability,coupl,couple,61,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:139,integrability,modular,modularity,139,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:179,integrability,modular,modularity,179,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:393,integrability,modular,modularity,393,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:488,integrability,modular,modularity,488,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:558,integrability,modular,modularity,558,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:698,integrability,modular,modularity,698,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:61,modifiability,coupl,couple,61,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:139,modifiability,modul,modularity,139,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:179,modifiability,modul,modularity,179,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:393,modifiability,modul,modularity,393,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:481,modifiability,scal,scaled,481,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:488,modifiability,modul,modularity,488,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:558,modifiability,modul,modularity,558,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:691,modifiability,scal,scaled,691,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:698,modifiability,modul,modularity,698,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:404,performance,optimiz,optimization,404,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:481,performance,scale,scaled,481,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:691,performance,scale,scaled,691,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:139,safety,modul,modularity,139,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:179,safety,modul,modularity,179,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:393,safety,modul,modularity,393,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:488,safety,modul,modularity,488,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:558,safety,modul,modularity,558,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:698,safety,modul,modularity,698,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:969,safety,compl,complementing,969,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:969,security,compl,complementing,969,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:61,testability,coupl,couple,61,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:139,testability,modula,modularity,139,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:179,testability,modula,modularity,179,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:393,testability,modula,modularity,393,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:488,testability,modula,modularity,488,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:558,testability,modula,modularity,558,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:698,testability,modula,modularity,698,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:324,usability,user,user,324,"> I think it's really good to record the key added. I have a couple questions about the quality score. > . > * Should it still be called a modularity score if we aren't using the modularity quality function? If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term `scaled modularity` anymore. > * Do you have some use cases for recording the modularity score? My impression was that it may not have much interpretable meaning, especially between different graphs. > . To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > Also, should this stuff be mirrored to `leiden`? It's done.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:912,availability,cluster,clustered,912,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1268,availability,cluster,clusterings,1268,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1312,availability,cluster,clusterings,1312,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:187,deployability,modul,modularity,187,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:274,deployability,scale,scaled,274,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:281,deployability,modul,modularity,281,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:325,deployability,modul,modularity,325,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:704,deployability,scale,scaled,704,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:711,deployability,modul,modularity,711,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:912,deployability,cluster,clustered,912,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1268,deployability,cluster,clusterings,1268,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1312,deployability,cluster,clusterings,1312,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:198,energy efficiency,optim,optimization,198,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:274,energy efficiency,scale,scaled,274,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:704,energy efficiency,scale,scaled,704,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:746,energy efficiency,measur,measure,746,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1010,energy efficiency,measur,measures,1010,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:187,integrability,modular,modularity,187,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:281,integrability,modular,modularity,281,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:325,integrability,modular,modularity,325,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:711,integrability,modular,modularity,711,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1062,integrability,coupl,couple,1062,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:187,modifiability,modul,modularity,187,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:274,modifiability,scal,scaled,274,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:281,modifiability,modul,modularity,281,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:325,modifiability,modul,modularity,325,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:479,modifiability,pac,packages,479,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:704,modifiability,scal,scaled,704,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:711,modifiability,modul,modularity,711,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1062,modifiability,coupl,couple,1062,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:198,performance,optimiz,optimization,198,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:274,performance,scale,scaled,274,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:704,performance,scale,scaled,704,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:187,safety,modul,modularity,187,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:281,safety,modul,modularity,281,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:325,safety,modul,modularity,325,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:711,safety,modul,modularity,711,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:982,safety,compl,complementing,982,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:982,security,compl,complementing,982,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:187,testability,modula,modularity,187,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:281,testability,modula,modularity,281,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:325,testability,modula,modularity,325,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:711,testability,modula,modularity,711,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1062,testability,coupl,couple,1062,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:118,usability,user,user,118,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1380,usability,user,user,1380,"> If another flavor is used, we do not record or print anything about quality, so it's ok. But there is a chance that user supplies a partition type from Louvain/Leiden that is not using modularity optimization (e.g. CPM or Surprize). In this case, we do not print the term scaled modularity anymore. By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). A couple follow up points on this and @LuckyMD's points. * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:210,availability,cluster,clusterings,210,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:254,availability,cluster,clusterings,254,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:210,deployability,cluster,clusterings,210,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:254,deployability,cluster,clusterings,254,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:557,deployability,modul,modularity,557,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:923,deployability,modul,modularity,923,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:578,energy efficiency,optim,optimized,578,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:977,energy efficiency,optim,optimal,977,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1058,energy efficiency,optim,optimized,1058,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:3,integrability,coupl,couple,3,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:557,integrability,modular,modularity,557,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:923,integrability,modular,modularity,923,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:3,modifiability,coupl,couple,3,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:557,modifiability,modul,modularity,557,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:923,modifiability,modul,modularity,923,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:578,performance,optimiz,optimized,578,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:769,performance,network,networks,769,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1058,performance,optimiz,optimized,1058,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1021,reliability,doe,doesn,1021,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:557,safety,modul,modularity,557,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:923,safety,modul,modularity,923,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:769,security,network,networks,769,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:3,testability,coupl,couple,3,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:513,testability,understand,understand,513,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:557,testability,modula,modularity,557,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:923,testability,modula,modularity,923,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:322,usability,user,user,322,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:757,usability,interact,interaction,757,">A couple follow up points on this and @LuckyMD's points:. > I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. I'm not sure I entirely understand your point. The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? . I have looked at some stats for communities in protein-protein interaction networks, and the quality of the communities can change dramatically with louvain output there (could find the link if you think it's relevant). However, modularity as a score is fairly degenerate toward the optimal score and therefore the value often doesn't change that much between the optimized partitions. I'm not sure how this is on the knn graphs though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2165,availability,cluster,clustered,2165,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2533,availability,cluster,clusterings,2533,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2577,availability,cluster,clusterings,2577,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2949,availability,avail,available,2949,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:26,deployability,modul,modularity,26,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:524,deployability,modul,modularity,524,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:567,deployability,modul,modularity,567,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:767,deployability,Modul,ModularityVertexPartition,767,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:812,deployability,modul,modularity,812,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1149,deployability,modul,modularity,1149,"om the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1428,deployability,modul,modularity,1428,"t that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1517,deployability,Modul,ModularityVertexPartition,1517,"rity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1705,deployability,modul,modularity,1705,"n differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meanin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1957,deployability,scale,scaled,1957,"h.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1964,deployability,modul,modularity,1964,"docs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2165,deployability,cluster,clustered,2165,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2533,deployability,cluster,clusterings,2533,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2577,deployability,cluster,clusterings,2577,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2858,deployability,modul,modularity,2858,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2888,deployability,modul,modularity,2888,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2935,deployability,modul,modularity,2935,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:823,energy efficiency,optim,optimization,823,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1362,energy efficiency,optim,optimization,1362,"= partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1957,energy efficiency,scale,scaled,1957,"h.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1999,energy efficiency,measur,measure,1999,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2263,energy efficiency,measur,measures,2263,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:26,integrability,modular,modularity,26,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:524,integrability,modular,modularity,524,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:567,integrability,modular,modularity,567,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:767,integrability,Modular,ModularityVertexPartition,767,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:812,integrability,modular,modularity,812,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1149,integrability,modular,modularity,1149,"om the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1428,integrability,modular,modularity,1428,"t that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1517,integrability,Modular,ModularityVertexPartition,1517,"rity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1705,integrability,modular,modularity,1705,"n differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meanin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1964,integrability,modular,modularity,1964,"docs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2321,integrability,coupl,couple,2321,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2858,integrability,modular,modularity,2858,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2888,integrability,modular,modularity,2888,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2935,integrability,modular,modularity,2935,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:26,modifiability,modul,modularity,26,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:180,modifiability,pac,packages,180,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:524,modifiability,modul,modularity,524,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:567,modifiability,modul,modularity,567,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:767,modifiability,Modul,ModularityVertexPartition,767,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:812,modifiability,modul,modularity,812,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:840,modifiability,Scal,Scaling,840,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:893,modifiability,paramet,parameter,893,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1088,modifiability,paramet,parameter,1088,"exPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's fa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1149,modifiability,modul,modularity,1149,"om the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1428,modifiability,modul,modularity,1428,"t that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1517,modifiability,Modul,ModularityVertexPartition,1517,"rity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1705,modifiability,modul,modularity,1705,"n differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meanin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1957,modifiability,scal,scaled,1957,"h.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1964,modifiability,modul,modularity,1964,"docs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2321,modifiability,coupl,couple,2321,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2858,modifiability,modul,modularity,2858,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2888,modifiability,modul,modularity,2888,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2935,modifiability,modul,modularity,2935,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:823,performance,optimiz,optimization,823,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1362,performance,optimiz,optimization,1362,"= partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1957,performance,scale,scaled,1957,"h.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2949,reliability,availab,available,2949,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:26,safety,modul,modularity,26,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:524,safety,modul,modularity,524,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:567,safety,modul,modularity,567,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:767,safety,Modul,ModularityVertexPartition,767,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:812,safety,modul,modularity,812,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1149,safety,modul,modularity,1149,"om the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1428,safety,modul,modularity,1428,"t that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1517,safety,Modul,ModularityVertexPartition,1517,"rity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1705,safety,modul,modularity,1705,"n differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meanin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1964,safety,modul,modularity,1964,"docs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2235,safety,compl,complementing,2235,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2858,safety,modul,modularity,2858,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2888,safety,modul,modularity,2888,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2902,safety,safe,safe,2902,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2935,safety,modul,modularity,2935,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2949,safety,avail,available,2949,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2235,security,compl,complementing,2235,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2949,security,availab,available,2949,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:26,testability,modula,modularity,26,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:524,testability,modula,modularity,524,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:567,testability,modula,modularity,567,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:767,testability,Modula,ModularityVertexPartition,767,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:812,testability,modula,modularity,812,"> By default we don't use modularity as the quality function, we use the `RBConfigurationVertexPartition`. I believe that we should get a quality score from the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1149,testability,modula,modularity,1149,"om the leiden and louvain packages regardless of quality function though. Could we use the term `quality_score` and also store `quality_function` used in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1428,testability,modula,modularity,1428,"t that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1517,testability,Modula,ModularityVertexPartition,1517,"rity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multip",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1705,testability,modula,modularity,1705,"n differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meanin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1964,testability,modula,modularity,1964,"docs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2321,testability,coupl,couple,2321,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2858,testability,modula,modularity,2858,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2888,testability,modula,modularity,2888,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2935,testability,modula,modularity,2935,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1302,usability,user,users,1302,"in params like: `.uns[key_added][""params""][""quality_function""] = partition_type.__name__`? > . Strictly speaking, you are correct that the quality function of `RBConfigurationVertexPartition` is not exactly the same as modularity, although it is called unscaled modularity in the [code](https://github.com/vtraag/louvain-igraph/blob/master/src/RBConfigurationVertexPartition.cpp#L123). . There are two main differences between RBConfigurationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeli",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1739,usability,hint,hint,1739,"rationVertexPartition and ModularityVertexPartition which uses typical modularity optimization. 1) Scaling by the number of edges and 2) the resolution parameter (as it's written [here in the note](https://louvain-igraph.readthedocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I thi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:2647,usability,user,user,2647,"ocs.io/en/latest/reference.html#rbconfigurationvertexpartition)). I account for 1) in the code but using a resolution parameter other than 1.0 would lead to values different than modularity due to 2). Right now, for example, you can get a perfect quality (=1.0) by just setting the resolution to 0.0 :D I don't think that'd mislead users though. After all, that's what the algorithm uses for optimization. I can think of two solutions. We can report typical modularity regardless of the `partition_type`, namely:. ```. modularity_part = leidenalg.ModularityVertexPartition(g, initial_membership=part.membership). q = modularity_part.quality(). ```. or we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. It's in the ""hint"" verbosity level anyway. Regarding the suggestion to record `partition_type.__name__`, I think it's a good idea. I'd record it in the `uns[uns_key]['partition_type']` though, not in `quality_function`. > > To me, scaled modularity is like any statistical measure which gives a rough idea about a concept, like correlation or silhouette coef. It's far from conclusive just by itself, but it gives a ""feeling"" of how ""well-clustered"" the data is (and how good we are at finding them). Without complementing it with other measures, it's not more than just a ""feeling"" :). > . > A couple follow up points on this and @LuckyMD's points. > . > * I don't actually know how different the quality score can be for different solutions. Any chance you have some stats on quality scores from multiple clusterings? I'm mostly wondering if ""good"" clusterings are associated with high quality scores. > * I think if a user sees a value like ""quality"" they could ascribe more meaning to it than it deserves. I think we should add some docs about what it means, and how to interpret it. That makes sense. Maybe calculating typical modularity and using the term modularity is safe enough, since definition of modularity is available everywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:21,deployability,modul,modularity,21,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:81,deployability,modul,modularity,81,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:249,deployability,modul,modularityvertexpartition,249,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:296,deployability,modul,modularity,296,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:565,deployability,modul,modularity,565,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1197,deployability,modul,modularity,1197,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:307,energy efficiency,optim,optimization,307,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:363,energy efficiency,optim,optimizing,363,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:586,energy efficiency,optim,optimized,586,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1375,energy efficiency,optim,optimization,1375,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1422,energy efficiency,measur,measured,1422,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1449,energy efficiency,optim,optimized,1449,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:21,integrability,modular,modularity,21,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:81,integrability,modular,modularity,81,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:249,integrability,modular,modularityvertexpartition,249,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:296,integrability,modular,modularity,296,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:565,integrability,modular,modularity,565,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1197,integrability,modular,modularity,1197,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:164,interoperability,specif,specific,164,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:21,modifiability,modul,modularity,21,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:81,modifiability,modul,modularity,81,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:249,modifiability,modul,modularityvertexpartition,249,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:296,modifiability,modul,modularity,296,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:565,modifiability,modul,modularity,565,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1197,modifiability,modul,modularity,1197,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:307,performance,optimiz,optimization,307,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:363,performance,optimiz,optimizing,363,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:586,performance,optimiz,optimized,586,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1375,performance,optimiz,optimization,1375,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1449,performance,optimiz,optimized,1449,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:21,safety,modul,modularity,21,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:81,safety,modul,modularity,81,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:249,safety,modul,modularityvertexpartition,249,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:296,safety,modul,modularity,296,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:565,safety,modul,modularity,565,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1197,safety,modul,modularity,1197,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:21,testability,modula,modularity,21,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:81,testability,modula,modularity,81,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:249,testability,modula,modularityvertexpartition,249,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:296,testability,modula,modularity,296,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:565,testability,modula,modularity,565,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1197,testability,modula,modularity,1197,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1482,testability,simpl,simplify,1482,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1218,usability,Person,Personally,1218,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1482,usability,simpl,simplify,1482,"On the definition of modularity, I did go back over some literature and saw that modularity sometimes takes multiple meanings within a paper. It can be either the [specific quality function](https://leidenalg.readthedocs.io/en/latest/reference.html#modularityvertexpartition), or when used like ""modularity optimization"" can refer to the whole class of partition optimizing algorithms (which are generic wrt quality function) like `louvain` ([I like section IV F of this paper for an overview](https://arxiv.org/abs/1608.00163v2)). @LuckyMD. > The quality score is modularity, which is optimized. Thus a ""good"" partition is a high quality score by definition. Or what are you referring to as ""good""? I think of the quality function/score as being determined by the `partition_type`. . To me, a good partition is one that seperates data points into discrete groups which reflect some true underlying structure. I put this in quotes since it’s ill-defined, however we can tell when it’s definitely not true. A high quality score for a partitioning is just a high quality score for a partitioning. @gokceneraslan . > we can report the original quality value as ""raw quality"" (whatever it is) and the modularity together. Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. This would also simplify the code a bunch. I think there's another case for trying to tell if it's a ""good"" partitioning, but I think that should be handled seperatly. > Regarding the suggestion to record partition_type.__name__, I think it's a good idea. I'd record it in the uns[uns_key]['partition_type'] though, not in quality_function. That's reasonable. Just to be sure, we'd keep it in `uns[uns_key][""params""]['partition_type']` like it is now?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:335,deployability,modul,modularity,335,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,energy efficiency,optim,optimization,171,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:218,energy efficiency,measur,measured,218,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:245,energy efficiency,optim,optimized,245,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:335,integrability,modular,modularity,335,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:335,modifiability,modul,modularity,335,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:171,performance,optimiz,optimization,171,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:245,performance,optimiz,optimized,245,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:335,safety,modul,modularity,335,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:335,testability,modula,modularity,335,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:14,usability,Person,Personally,14,"@ivirshup . > Personally, I would just report the quality metric calculated by the quality function used. To me, the point of returning this value would be to know if the optimization went well, which is probably best measured by looking at the optimized value. The quality score returned by RBConfigurationVertexPartition is unscaled modularity, so it's something like `41726.23`. So how would one interpret that? I don't think there is any point in reporting raw RBConfigurationVertexPartition quality value.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:62,deployability,modul,modularity,62,"After the discussions we had here, I'm reporting the standard modularity now, regardless of the partition_type. Please have a look and let me know if it makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:62,integrability,modular,modularity,62,"After the discussions we had here, I'm reporting the standard modularity now, regardless of the partition_type. Please have a look and let me know if it makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:53,interoperability,standard,standard,53,"After the discussions we had here, I'm reporting the standard modularity now, regardless of the partition_type. Please have a look and let me know if it makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:62,modifiability,modul,modularity,62,"After the discussions we had here, I'm reporting the standard modularity now, regardless of the partition_type. Please have a look and let me know if it makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:62,safety,modul,modularity,62,"After the discussions we had here, I'm reporting the standard modularity now, regardless of the partition_type. Please have a look and let me know if it makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:62,testability,modula,modularity,62,"After the discussions we had here, I'm reporting the standard modularity now, regardless of the partition_type. Please have a look and let me know if it makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:861,availability,cluster,clustering,861,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1002,availability,cluster,clustering,1002,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:152,deployability,modul,modularity,152,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:214,deployability,modul,modularity,214,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:473,deployability,modul,modularity,473,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:561,deployability,modul,modularity,561,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:627,deployability,modul,modularity,627,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:697,deployability,modul,modularity,697,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:737,deployability,log,logging,737,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:861,deployability,cluster,clustering,861,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:1002,deployability,cluster,clustering,1002,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:792,energy efficiency,optim,optimization,792,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:152,integrability,modular,modularity,152,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:214,integrability,modular,modularity,214,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:473,integrability,modular,modularity,473,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:561,integrability,modular,modularity,561,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:627,integrability,modular,modularity,627,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:697,integrability,modular,modularity,697,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:143,interoperability,standard,standard,143,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:152,modifiability,modul,modularity,152,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:214,modifiability,modul,modularity,214,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:473,modifiability,modul,modularity,473,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:561,modifiability,modul,modularity,561,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:627,modifiability,modul,modularity,627,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:697,modifiability,modul,modularity,697,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:792,performance,optimiz,optimization,792,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:152,safety,modul,modularity,152,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:214,safety,modul,modularity,214,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:473,safety,modul,modularity,473,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:561,safety,modul,modularity,561,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:627,safety,modul,modularity,627,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:697,safety,modul,modularity,697,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:737,safety,log,logging,737,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:737,security,log,logging,737,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:835,security,assess,assess,835,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:111,testability,understand,understand,111,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:152,testability,modula,modularity,152,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:214,testability,modula,modularity,214,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:473,testability,modula,modularity,473,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:561,testability,modula,modularity,561,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:627,testability,modula,modularity,627,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:697,testability,modula,modularity,697,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:737,testability,log,logging,737,"Sorry for the long delay – I was away on a retreat. By the way, congrats on the spatial letter! I'm not sure I understand why you'd report the standard modularity if the partitioning was done with multi resolution modularity or some other quality function. To me, this makes the metric being pretty disconnected from the computation that was run. It seems likely that there could be non-proportional relationships between the whatever quality function is used and unscaled modularity. For example there could be a case where: partitioning A has higher unscaled modularity than partitioning B, but B has higher multi resolution modularity quality with resolution .8 than A. If the multi resolution modularity is what was run, I think the logging should reflect that run resulted in a ""better"" optimization. Separately, if it's meant to assess the quality of the clustering, why not calculate something like silhouette? From my perspective, it would be because that's separate enough from the process of clustering that it should be run separately.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:150,deployability,updat,update,150,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:64,performance,time,time,64,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:93,performance,time,time,93,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:150,safety,updat,update,150,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:150,security,updat,update,150,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/819:143,usability,close,close,143,"I think the PR is now good as is. I will be quite busy for some time, therefore I won't have time for further discussions. Please feel free to close, update or merge it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/819
https://github.com/scverse/scanpy/pull/820:74,safety,reme,remember,74,"> since these matrices are symmetrized. This sounds familiar, but I don't remember where it happens. Could you point me towards that? Never mind, I think I found it in [`fuzzy_simplical_set`](https://github.com/lmcinnes/umap/blob/439db748b9959b53d6678b6fdc6cb18e8f49c6c6/umap/umap_.py#L566-L574), but made me think of another question:. Do we want to save the indices and distances as a pair of arrays, or just save a sparse matrix of the original distances? I think the latter would be easier to work with.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:1080,deployability,build,building,1080,"> This sounds familiar, but I don't remember where it happens. Could you point me towards that? > . > Never mind, I think I found it in [`fuzzy_simplical_set`](https://github.com/lmcinnes/umap/blob/439db748b9959b53d6678b6fdc6cb18e8f49c6c6/umap/umap_.py#L566-L574), . Yes, exactly. > but made me think of another question:. > . > Do we want to save the indices and distances as a pair of arrays, . What do you mean? If we merge this, we will have `adata.uns['neighbors']['knn_indices']` and `adata.uns['neighbors']['distances']` (only if it's requested by the user). Is this what you mean? . > or just save a sparse matrix of the original distances? I think the latter would be easier to work with. I'm not following. `adata.uns['neighbors']['distances']` encodes a different type of information since it represents the graph structure and it's symmetrized. `knn_indices` on the other hand represents the ""raw"" output of kNN method. Just like `adata.uns['neighbors']['rp_forest']`, it's additional information about the kNN. It can be used for other things like kNN classifiers or building other types of graphs like mutual kNN as I mentioned. Just to clarify, I don't propose using knn_indices as a replacement of distance or connectivitiy matrix. It's just to be able to access more details of the kNN construction. Furthermore, it's optional and it's False by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:36,safety,reme,remember,36,"> This sounds familiar, but I don't remember where it happens. Could you point me towards that? > . > Never mind, I think I found it in [`fuzzy_simplical_set`](https://github.com/lmcinnes/umap/blob/439db748b9959b53d6678b6fdc6cb18e8f49c6c6/umap/umap_.py#L566-L574), . Yes, exactly. > but made me think of another question:. > . > Do we want to save the indices and distances as a pair of arrays, . What do you mean? If we merge this, we will have `adata.uns['neighbors']['knn_indices']` and `adata.uns['neighbors']['distances']` (only if it's requested by the user). Is this what you mean? . > or just save a sparse matrix of the original distances? I think the latter would be easier to work with. I'm not following. `adata.uns['neighbors']['distances']` encodes a different type of information since it represents the graph structure and it's symmetrized. `knn_indices` on the other hand represents the ""raw"" output of kNN method. Just like `adata.uns['neighbors']['rp_forest']`, it's additional information about the kNN. It can be used for other things like kNN classifiers or building other types of graphs like mutual kNN as I mentioned. Just to clarify, I don't propose using knn_indices as a replacement of distance or connectivitiy matrix. It's just to be able to access more details of the kNN construction. Furthermore, it's optional and it's False by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:1272,security,access,access,1272,"> This sounds familiar, but I don't remember where it happens. Could you point me towards that? > . > Never mind, I think I found it in [`fuzzy_simplical_set`](https://github.com/lmcinnes/umap/blob/439db748b9959b53d6678b6fdc6cb18e8f49c6c6/umap/umap_.py#L566-L574), . Yes, exactly. > but made me think of another question:. > . > Do we want to save the indices and distances as a pair of arrays, . What do you mean? If we merge this, we will have `adata.uns['neighbors']['knn_indices']` and `adata.uns['neighbors']['distances']` (only if it's requested by the user). Is this what you mean? . > or just save a sparse matrix of the original distances? I think the latter would be easier to work with. I'm not following. `adata.uns['neighbors']['distances']` encodes a different type of information since it represents the graph structure and it's symmetrized. `knn_indices` on the other hand represents the ""raw"" output of kNN method. Just like `adata.uns['neighbors']['rp_forest']`, it's additional information about the kNN. It can be used for other things like kNN classifiers or building other types of graphs like mutual kNN as I mentioned. Just to clarify, I don't propose using knn_indices as a replacement of distance or connectivitiy matrix. It's just to be able to access more details of the kNN construction. Furthermore, it's optional and it's False by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:559,usability,user,user,559,"> This sounds familiar, but I don't remember where it happens. Could you point me towards that? > . > Never mind, I think I found it in [`fuzzy_simplical_set`](https://github.com/lmcinnes/umap/blob/439db748b9959b53d6678b6fdc6cb18e8f49c6c6/umap/umap_.py#L566-L574), . Yes, exactly. > but made me think of another question:. > . > Do we want to save the indices and distances as a pair of arrays, . What do you mean? If we merge this, we will have `adata.uns['neighbors']['knn_indices']` and `adata.uns['neighbors']['distances']` (only if it's requested by the user). Is this what you mean? . > or just save a sparse matrix of the original distances? I think the latter would be easier to work with. I'm not following. `adata.uns['neighbors']['distances']` encodes a different type of information since it represents the graph structure and it's symmetrized. `knn_indices` on the other hand represents the ""raw"" output of kNN method. Just like `adata.uns['neighbors']['rp_forest']`, it's additional information about the kNN. It can be used for other things like kNN classifiers or building other types of graphs like mutual kNN as I mentioned. Just to clarify, I don't propose using knn_indices as a replacement of distance or connectivitiy matrix. It's just to be able to access more details of the kNN construction. Furthermore, it's optional and it's False by default.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:284,integrability,discover,discovering,284,"Oooooh, that's so true :D I didn't know that distance matrix is asymmetric:. ![image](https://user-images.githubusercontent.com/1140359/64660380-0cbf3900-d40e-11e9-9fa3-0ab0a7eefb8d.png). I was always using the connectivity matrix, that's why I didn't figure it out. Thanks a lot for discovering this, I'm closing the PR then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:284,interoperability,discover,discovering,284,"Oooooh, that's so true :D I didn't know that distance matrix is asymmetric:. ![image](https://user-images.githubusercontent.com/1140359/64660380-0cbf3900-d40e-11e9-9fa3-0ab0a7eefb8d.png). I was always using the connectivity matrix, that's why I didn't figure it out. Thanks a lot for discovering this, I'm closing the PR then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:94,usability,user,user-images,94,"Oooooh, that's so true :D I didn't know that distance matrix is asymmetric:. ![image](https://user-images.githubusercontent.com/1140359/64660380-0cbf3900-d40e-11e9-9fa3-0ab0a7eefb8d.png). I was always using the connectivity matrix, that's why I didn't figure it out. Thanks a lot for discovering this, I'm closing the PR then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/pull/820:284,usability,discov,discovering,284,"Oooooh, that's so true :D I didn't know that distance matrix is asymmetric:. ![image](https://user-images.githubusercontent.com/1140359/64660380-0cbf3900-d40e-11e9-9fa3-0ab0a7eefb8d.png). I was always using the connectivity matrix, that's why I didn't figure it out. Thanks a lot for discovering this, I'm closing the PR then.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/820
https://github.com/scverse/scanpy/issues/821:198,deployability,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:198,integrability,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:198,interoperability,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:198,modifiability,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:198,reliability,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:62,safety,test,testing,62,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:198,security,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:62,testability,test,testing,62,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:198,testability,integr,integrated,198,"Hi @sygongcode,. Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,deployability,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,integrability,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,interoperability,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,modifiability,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,reliability,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:70,safety,test,testing,70,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,security,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:70,testability,test,testing,70,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/issues/821:206,testability,integr,integrated,206,"> Hi @sygongcode,. > . > Are you referring to differential expression testing between conditions? You can do that with `sc.tl.rank_genes_groups()` or in a more advanced way using `diffxpy`, which is easily integrated with `scanpy`. You can find it [here](https://github.com/theislab/diffxpy). Yes, that is what I want to do. Thank you so much.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/821
https://github.com/scverse/scanpy/pull/822:32,deployability,build,builds,32,"@gokceneraslan . This fixes the builds for now. I'm guessing there's some bug added on their end, but haven't confirmed this yet. Some more notes:. A reason I think a bug could be on our end is that current master of anndata reads that dataset just fine, so maybe the previous code relied on unintended behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:199,energy efficiency,current,current,199,"@gokceneraslan . This fixes the builds for now. I'm guessing there's some bug added on their end, but haven't confirmed this yet. Some more notes:. A reason I think a bug could be on our end is that current master of anndata reads that dataset just fine, so maybe the previous code relied on unintended behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:110,usability,confirm,confirmed,110,"@gokceneraslan . This fixes the builds for now. I'm guessing there's some bug added on their end, but haven't confirmed this yet. Some more notes:. A reason I think a bug could be on our end is that current master of anndata reads that dataset just fine, so maybe the previous code relied on unintended behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:303,usability,behavi,behavior,303,"@gokceneraslan . This fixes the builds for now. I'm guessing there's some bug added on their end, but haven't confirmed this yet. Some more notes:. A reason I think a bug could be on our end is that current master of anndata reads that dataset just fine, so maybe the previous code relied on unintended behavior.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:0,energy efficiency,Cool,Cool,0,Cool! Thanks a lot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:57,deployability,depend,dependencies,57,I can’t reproduce this locally and would like to get the dependencies unlocked. Where’s the bug report at h5py?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:57,integrability,depend,dependencies,57,I can’t reproduce this locally and would like to get the dependencies unlocked. Where’s the bug report at h5py?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:57,modifiability,depend,dependencies,57,I can’t reproduce this locally and would like to get the dependencies unlocked. Where’s the bug report at h5py?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:57,safety,depend,dependencies,57,I can’t reproduce this locally and would like to get the dependencies unlocked. Where’s the bug report at h5py?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/822:57,testability,depend,dependencies,57,I can’t reproduce this locally and would like to get the dependencies unlocked. Where’s the bug report at h5py?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/822
https://github.com/scverse/scanpy/pull/823:98,usability,workflow,workflows,98,looking forward to this being implemented! Will greatly increase the speed of most of my analysis workflows 😃,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:342,safety,test,test,342,"Hey guys @LuckyMD, @Koncopd, @falexwolf, @flying-sheep. I think this feature would be very useful to have in Scanpy, but this PR has been sort of forgotten. . I would be up to take care of this, but it would be my first contribution and I'd like some advice on how to move forward on this. I take it the main issue with the PR is the missing test for the scran normalization, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:342,testability,test,test,342,"Hey guys @LuckyMD, @Koncopd, @falexwolf, @flying-sheep. I think this feature would be very useful to have in Scanpy, but this PR has been sort of forgotten. . I would be up to take care of this, but it would be my first contribution and I'd like some advice on how to move forward on this. I take it the main issue with the PR is the missing test for the scran normalization, is that correct?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:155,deployability,version,version,155,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:155,integrability,version,version,155,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:155,modifiability,version,version,155,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:74,safety,test,tests,74,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:111,safety,test,test,111,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:189,safety,test,test,189,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:227,safety,test,testing,227,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:251,safety,test,tests,251,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:74,testability,test,tests,74,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:111,testability,test,test,111,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:189,testability,test,test,189,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:227,testability,test,testing,227,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:251,testability,test,tests,251,"A student of @mbuttner started this, and yes, I believe it's only missing tests. I would probably make a small test case and record the results of the `R` version on there, and use it as a test for this. You can check out the `testing/` directory for tests. . To start, just fetch this branch and you should be able to commit to it directly as a member of theislab github.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:47,safety,test,tests,47,Unfortunately the PR was not just missing some tests. There are quite a lot of missing parts and the code is not correct. This will take much more effort than expected. I will try working on it on my own branch and close this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:47,testability,test,tests,47,Unfortunately the PR was not just missing some tests. There are quite a lot of missing parts and the code is not correct. This will take much more effort than expected. I will try working on it on my own branch and close this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/823:215,usability,close,close,215,Unfortunately the PR was not just missing some tests. There are quite a lot of missing parts and the code is not correct. This will take much more effort than expected. I will try working on it on my own branch and close this PR.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/823
https://github.com/scverse/scanpy/pull/824:222,deployability,version,version,222,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:266,deployability,depend,depend,266,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:214,energy efficiency,current,current,214,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:222,integrability,version,version,222,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:266,integrability,depend,depend,266,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:503,integrability,batch,batch,503,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:222,modifiability,version,version,222,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:266,modifiability,depend,depend,266,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:351,performance,time,time,351,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:503,performance,batch,batch,503,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:434,reliability,doe,doesn,434,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:266,safety,depend,depend,266,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:266,testability,depend,depend,266,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:34,usability,efficien,efficiently,34,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:655,usability,user,user,655,"> I think this could be done more efficiently by using the index returned from `filter_genes(..., inplace=False)` in `_highly_variable_genes_single_batch` and instead of the whole data frame merging you add in the current version of your changes. I guess that would depend if you want to have a `filter_genes` call in the HVG selection function every time, or whether you only want it in there in a case where `filter_genes` normally doesn't work. You typically use it on the whole dataset, but not per batch. Another issue atm is that if you set the verbosity high, then the `filter_genes()` call gives you an output, which is not really intended as the user can't see the function call.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:45,integrability,batch,batch,45,Am I correct in thinking this is a fix for a batch having zero variance for a gene? What was the output in that case?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:45,performance,batch,batch,45,Am I correct in thinking this is a fix for a batch having zero variance for a gene? What was the output in that case?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:200,availability,error,error,200,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:878,availability,error,error,878,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:136,deployability,fail,failed,136,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:200,performance,error,error,200,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:878,performance,error,error,878,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:136,reliability,fail,failed,136,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:200,safety,error,error,200,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:878,safety,error,error,878,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:174,usability,close,close,174,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:200,usability,error,error,200,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:878,usability,error,error,878,"This is mainly a fix for cases when multiple genes have zero variance. The output in that case was that `sc.pp.highly_variable_genes()` failed as the bin boundaries were too close to one another. The error I got is:. ```. ValueError: Bin edges must be unique: array([ -inf, 9.99999996e-13, 9.99999996e-13, 3.71624832e-03,. 4.50723944e-03, 5.04237041e-03, 7.96065722e-03, 9.17631686e-03,. 1.15813100e-02, 1.34968273e-02, 1.62843971e-02, 1.89858746e-02,. 2.27864407e-02, 2.76163086e-02, 3.43018658e-02, 4.27573830e-02,. 5.52219763e-02, 7.87758350e-02, 1.42211060e-01, 3.10728383e+00,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. I figured the best way forward would be to exclude those genes from the function, rather than changing the bins in the `_highly_variable_genes_single_batch()` function with the `duplicates` argument as suggested in the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:171,availability,error,error,171,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:276,availability,mask,masking,276,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:148,integrability,batch,batch,148,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:148,performance,batch,batch,148,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:171,performance,error,error,171,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:99,safety,test,test,99,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:171,safety,error,error,171,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:99,testability,test,test,99,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:171,usability,error,error,171,"> This is mainly a fix for cases when multiple genes have zero variance. Could you add that as the test case? When some genes aren't expressed in a batch you won't get an error. > the best way forward would be to exclude those genes from the function. I think the approach of masking out the non-expressed genes sounds reasonable, since that's what you'd probably do if it were just one dataset. I'd definitely defer to @gokceneraslan on any more about the appropriateness of the approach.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:175,deployability,fail,failing,175,@ivirshup Is this fine for you as is? I think I've addressed all the points now. I'd be keen for this to be merged asap as we need this for another project where this code is failing. Note that I have not addressed the issue with `inplace=False` when using the `batch_key` parameter.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:273,modifiability,paramet,parameter,273,@ivirshup Is this fine for you as is? I think I've addressed all the points now. I'd be keen for this to be merged asap as we need this for another project where this code is failing. Note that I have not addressed the issue with `inplace=False` when using the `batch_key` parameter.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:175,reliability,fail,failing,175,@ivirshup Is this fine for you as is? I think I've addressed all the points now. I'd be keen for this to be merged asap as we need this for another project where this code is failing. Note that I have not addressed the issue with `inplace=False` when using the `batch_key` parameter.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:52,availability,error,error,52,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:159,integrability,sub,subset,159,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:52,performance,error,error,52,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:58,reliability,doe,doesn,58,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:36,safety,test,testing,36,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:52,safety,error,error,52,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:104,safety,test,test,104,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:36,testability,test,testing,36,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:104,testability,test,test,104,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:52,usability,error,error,52,"I had to use the pbmc3k dataset for testing, as the error doesn't occur on blobs or pbmc68k_reduced. To test I need sufficient genes that have 0 variance in a subset of the cells.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:63,safety,test,test,63,Cancel that @flying-sheep sheep helped me find a way around to test with `pbmc68k_reduced`. This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:63,testability,test,test,63,Cancel that @flying-sheep sheep helped me find a way around to test with `pbmc68k_reduced`. This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:0,usability,Cancel,Cancel,0,Cancel that @flying-sheep sheep helped me find a way around to test with `pbmc68k_reduced`. This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:32,usability,help,helped,32,Cancel that @flying-sheep sheep helped me find a way around to test with `pbmc68k_reduced`. This should speed up Travis again.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:25,modifiability,refact,refactor,25,Works for me! I’d say we refactor the helper function in a separate PR,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:25,performance,refactor,refactor,25,Works for me! I’d say we refactor the helper function in a separate PR,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/pull/824:38,usability,help,helper,38,Works for me! I’d say we refactor the helper function in a separate PR,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/824
https://github.com/scverse/scanpy/issues/828:54,availability,consist,consistently,54,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:795,availability,mask,masks,795,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:838,availability,error,error,838,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:6,deployability,updat,update,6,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:945,deployability,modul,module,945,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:844,integrability,messag,message,844,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:990,integrability,pub,public,990,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:844,interoperability,messag,message,844,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:137,modifiability,layer,layer,137,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:236,modifiability,layer,layer,236,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:494,modifiability,layer,layers,494,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:501,modifiability,layer,layer,501,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:786,modifiability,variab,variable,786,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:945,modifiability,modul,module,945,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:1036,modifiability,pac,packages,1036,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:838,performance,error,error,838,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:6,safety,updat,update,6,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:838,safety,error,error,838,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:945,safety,modul,module,945,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:6,security,updat,update,6,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:400,testability,assert,assert,400,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:631,testability,assert,assert,631,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:35,usability,help,helper,35,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:54,usability,consist,consistently,54,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:774,usability,support,support,774,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:838,usability,error,error,838,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:894,usability,help,helper,894,"As an update, I've been using this helper function to consistently handle this:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```. This could use support for variable masks like `use_highly_variable`. Also the error message should be better. I think a collection of helper functions like this should go in to a utils module (`sc.utils.argutils`?) which could be public so it's easier to use in `scanpy`-like packages.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/issues/828:0,usability,Support,Support,0,Support for `pca` and `regress_out` started in: https://github.com/scverse/scanpy/pull/2588,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/828
https://github.com/scverse/scanpy/pull/830:71,availability,error,errors,71,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:176,modifiability,pac,packages,176,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:71,performance,error,errors,71,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:257,reliability,doe,doesn,257,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:288,reliability,Doe,Does,288,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:71,safety,error,errors,71,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:28,testability,simpl,simple,28,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:28,usability,simpl,simple,28,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:71,usability,error,errors,71,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:296,usability,support,support,296,"I think this looks good and simple enough. Could you please fix the CI errors? Also there’s 3 added optional deps: cuml, cudf, and cugraph. I assume they’re all different CUDA packages. Could you add them into an `extra` in setup.py? The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:142,energy efficiency,current,currently,142,"> The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean? No, it only supports Euclidean distance currently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:25,reliability,doe,doesn,25,"> The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean? No, it only supports Euclidean distance currently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:56,reliability,Doe,Does,56,"> The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean? No, it only supports Euclidean distance currently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:64,usability,support,support,64,"> The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean? No, it only supports Euclidean distance currently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:114,usability,support,supports,114,"> The RAPIDS umap branch doesn’t use a metric argument. Does it support metrics other than euclidean? No, it only supports Euclidean distance currently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:58,availability,error,errors,58,@flying-sheep thanks for taking a look. I've fixed the CI errors now and added the deps as suggested.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:58,performance,error,errors,58,@flying-sheep thanks for taking a look. I've fixed the CI errors now and added the deps as suggested.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:58,safety,error,errors,58,@flying-sheep thanks for taking a look. I've fixed the CI errors now and added the deps as suggested.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:58,usability,error,errors,58,@flying-sheep thanks for taking a look. I've fixed the CI errors now and added the deps as suggested.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:23,energy efficiency,GPU,GPU,23,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:83,energy efficiency,CPU,CPU,83,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:4,modifiability,pac,packages,4,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:23,performance,GPU,GPU,23,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:83,performance,CPU,CPU,83,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:116,safety,test,test,116,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/830:116,testability,test,test,116,"The packages do need a GPU, unfortunately. There is no way to fallback to run on a CPU, so I don't think Travis can test them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/830
https://github.com/scverse/scanpy/pull/831:19,reliability,doe,does,19,"Hey @VolkerBergen, does it work like you want?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/831
https://github.com/scverse/scanpy/pull/831:124,performance,memor,memory,124,"Thanks, that option is very useful and works perfectly. mini-benchmark on my data (compared to non-compressed): . gzip: 35% memory, 3x runtime. lzf: 66% memory, 2x runtime",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/831
https://github.com/scverse/scanpy/pull/831:153,performance,memor,memory,153,"Thanks, that option is very useful and works perfectly. mini-benchmark on my data (compared to non-compressed): . gzip: 35% memory, 3x runtime. lzf: 66% memory, 2x runtime",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/831
https://github.com/scverse/scanpy/pull/831:124,usability,memor,memory,124,"Thanks, that option is very useful and works perfectly. mini-benchmark on my data (compared to non-compressed): . gzip: 35% memory, 3x runtime. lzf: 66% memory, 2x runtime",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/831
https://github.com/scverse/scanpy/pull/831:153,usability,memor,memory,153,"Thanks, that option is very useful and works perfectly. mini-benchmark on my data (compared to non-compressed): . gzip: 35% memory, 3x runtime. lzf: 66% memory, 2x runtime",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/831
https://github.com/scverse/scanpy/issues/832:198,availability,down,downgrade,198,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:246,deployability,instal,install,246,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:46,modifiability,pac,package,46,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:218,modifiability,pac,package,218,"Hi Dylan,. This is an issue with the new h5py package, which @ivirshup already fixed on master (https://github.com/theislab/scanpy/commit/928d475a8e2d2901c5744c3afc75e2d5a1b65f29). For now, you can downgrade your h5py package to 2.9.0 using `pip install h5py==2.9.0` as a workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:81,deployability,pipelin,pipeline,81,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:171,deployability,modul,module,171,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:178,deployability,version,version,178,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:81,integrability,pipelin,pipeline,81,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:178,integrability,version,version,178,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:171,modifiability,modul,module,171,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:178,modifiability,version,version,178,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:171,safety,modul,module,171,@gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:300,deployability,pipelin,pipeline,300,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:390,deployability,modul,module,390,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:397,deployability,version,version,397,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:300,integrability,pipelin,pipeline,300,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:397,integrability,version,version,397,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:390,modifiability,modul,module,390,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:397,modifiability,version,version,397,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:390,safety,modul,module,390,"Just a heads up, there is a remaining issue on anndata master where reading older files with h5py 2.10.0 results in bytestring indexes. > On Sep 12, 2019, at 05:28, Bruce Martin <notifications@github.com> wrote:. > . > @gokceneraslan - thanks for the fast response. This broke our (cellxgene) travis pipeline as well. Do you have any info on eta for a fix/workaround other than pinning the module version? TY! > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:20,availability,error,error,20,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:217,availability,down,downgrade,217,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:351,availability,error,error,351,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:468,availability,error,error,468,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:197,deployability,version,version,197,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:380,deployability,version,version,380,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:680,deployability,modul,module,680,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3637,deployability,scale,scaleoffset,3637," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3771,deployability,log,logical,3771," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:173,energy efficiency,load,load,173,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:317,energy efficiency,load,load,317,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:432,energy efficiency,load,loading,432,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:758,energy efficiency,core,core,758,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3637,energy efficiency,scale,scaleoffset,3637," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:197,integrability,version,version,197,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:380,integrability,version,version,380,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:197,modifiability,version,version,197,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:380,modifiability,version,version,380,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:680,modifiability,modul,module,680,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:1171,modifiability,layer,layers,1171,"oad it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:1186,modifiability,layer,layers,1186,"th that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3194,modifiability,pac,packages,3194,"ing(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `ada",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3482,modifiability,pac,packages,3482," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3637,modifiability,scal,scaleoffset,3637," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:20,performance,error,error,20,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:173,performance,load,load,173,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:317,performance,load,load,317,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:351,performance,error,error,351,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:432,performance,load,loading,432,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:468,performance,error,error,468,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3637,performance,scale,scaleoffset,3637," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:56,reliability,doe,doesn,56,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:20,safety,error,error,20,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:351,safety,error,error,351,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:468,safety,error,error,468,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:653,safety,input,input-,653,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:680,safety,modul,module,680,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3771,safety,log,logical,3771," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3771,security,log,logical,3771," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:609,testability,Trace,Traceback,609,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:3771,testability,log,logical,3771," value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_array(f, key, value, dataset_kwargs). 152 elif value.dtype.names is not None:. 153 value = _to_hdf5_vlen_strings(value). --> 154 f.create_dataset(key, data=value, **dataset_kwargs). 155 . 156 . ~/new_anndata/anndata/anndata/h5py/h5sparse.py in create_dataset(self, name, data, chunk_size, **kwargs). 151 if not isinstance(data, SparseDataset) and not ss.issparse(data):. 152 return self.h5py_group.create_dataset(. --> 153 name=name, data=data, **kwargs. 154 ). 155 if self.force_dense:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds). 134 . 135 with phil:. --> 136 dsid = dataset.make_new_dset(self, shape, dtype, data, **kwds). 137 dset = dataset.Dataset(dsid). 138 if name is not None:. ~/anaconda3/envs/sc-tutorial/lib/python3.6/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl). 116 else:. 117 dtype = numpy.dtype(dtype). --> 118 tid = h5t.py_create(dtype, logical=1). 119 . 120 # Legacy. h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t._c_compound(). h5py/h5t.pyx in h5py.h5t.py_create(). h5py/h5t.pyx in h5py.h5t.py_create(). TypeError: Object dtype dtype('O') has no native HDF5 equivalent. ```. Everything however seems to work fine when I throw out the rank_genes_groups results from `adata.uns`. Edit: actually cellxgene still isn't working, but I could at least save again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:20,usability,error,error,20,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:351,usability,error,error,351,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:468,usability,error,error,468,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:653,usability,input,input-,653,"I'm having the same error with `h5py==2.9.0`. Cellxgene doesn't seem to be working with the object that I created the object with scanpy `1.4.3+116.g0075c62`. I can however load it again with that version. But when I downgrade to 1.3.7 (recommendation from @mbuttner who had the same cellxgene issue) I can no longer load the object and get the above error. Back in the 1.4.3 dev version scanpy it no longer writes the object after loading, and gives me the following error:. ```. In [23]: adata.write(""cellxgene.h5ad"") . ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-23-33b15d710f71> in <module>. ----> 1 adata.write(""cellxgene.h5ad""). ~/new_anndata/anndata/anndata/core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense). 2222 compression=compression,. 2223 compression_opts=compression_opts,. -> 2224 force_dense=force_dense,. 2225 ). 2226 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_h5ad(filepath, adata, force_dense, dataset_kwargs, **kwargs). 90 write_attribute(f, ""varp"", adata.varp, dataset_kwargs). 91 write_attribute(f, ""layers"", adata.layers, dataset_kwargs). ---> 92 write_attribute(f, ""uns"", adata.uns, dataset_kwargs). 93 write_attribute(f, ""raw"", adata.raw, dataset_kwargs). 94 if adata.isbacked:. ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[key]. --> 105 _write_method(type(value))(f, key, value, dataset_kwargs). 106 . 107 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 203 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 204 for sub_key, sub_value in value.items():. --> 205 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs). 206 . 207 . ~/new_anndata/anndata/anndata/readwrite/h5ad.py in write_attribute(f, key, value, dataset_kwargs). 103 if key in f:. 104 del f[ke",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:17,availability,replic,replicate,17,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:263,energy efficiency,current,current,263,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:359,modifiability,variab,variable,359,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:432,modifiability,variab,variable,432,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:303,reliability,doe,doesn,303,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:351,reliability,doe,does,351,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:421,reliability,doe,doesn,421,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:235,testability,context,context,235,"@LuckyMD . I can replicate that with:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). pbmc.write(""tmp.h5ad""). fromdisk = sc.read(""tmp.h5ad"") # Do we read okay. fromdisk.write(pbmc) # Can we round trip. ```. Some context around this, and my current thinking on a solution:. * h5py doesn't do fixed length unicode strings. * h5py does do variable length unicode strings, pretty much anywhere. * zarr doesn't do variable length strings in structured arrays. * We probably don't actually want to use fixed length unicode strings much. Bytestrings, more likely. * We can probably just add another element type to allow special handling for these. I think it'd be fine to not do `np.str_` type arrays.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:22,usability,minim,minimal,22,Sorry for the lack of minimal reproducible example... and thanks for creating one :).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:33,modifiability,variab,variable-length,33,"It is, too bad numpy has no good variable-length string array type. When would bytes make sense? Bytes just mean “data, but I don’t know its structure or am about to write it to disk”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/832:178,performance,disk,disk,178,"It is, too bad numpy has no good variable-length string array type. When would bytes make sense? Bytes just mean “data, but I don’t know its structure or am about to write it to disk”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/832
https://github.com/scverse/scanpy/issues/833:55,availability,error,error,55,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:231,availability,sli,slice,231,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:284,availability,error,error,284,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:154,deployability,updat,updated,154,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:55,performance,error,error,55,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:284,performance,error,error,284,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:231,reliability,sli,slice,231,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:55,safety,error,error,55,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:154,safety,updat,updated,154,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:284,safety,error,error,284,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:154,security,updat,updated,154,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:55,usability,error,error,55,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:284,usability,error,error,284,"I think I found a way around it. The issue here is the error is thrown when the new louvain groups are created by the adata.obs['louvain_colors'] are not updated until the plotting sc.pl function is run. Therefore, when you try to slice anything, it throws out an index out of bounds error. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:138,availability,error,error,138,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:82,deployability,updat,update,82,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:159,deployability,stack,stack,159,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:341,integrability,messag,message,341,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:341,interoperability,messag,message,341,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:138,performance,error,error,138,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:82,safety,updat,update,82,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:138,safety,error,error,138,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:82,security,updat,update,82,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:165,testability,trace,trace,165,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:191,testability,trace,traceback,191,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:288,testability,Trace,Traceback,288,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:138,usability,error,error,138,Thank you! If you add a few more details we can fix this quickly: Which call will update the groups but not the color and which call will error out with which stack trace? Please add the the traceback to your comment this:. ````md. ```python. sc.tl.something(adata). ```. ```pytb. XError Traceback (most recent call last). .... XError: some message. ```. ````,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:46,usability,close,close,46,"Thank you for bringing up this issue! We will close the issue for now, hopefully the expected behaviour is reached here :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/issues/833:94,usability,behavi,behaviour,94,"Thank you for bringing up this issue! We will close the issue for now, hopefully the expected behaviour is reached here :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/833
https://github.com/scverse/scanpy/pull/835:42,usability,user,user,42,"I think it also makes sense to inform the user that n_top_genes > n_var. Edit: Oh you do already, please ignore :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/835
https://github.com/scverse/scanpy/issues/836:66,availability,slo,slot,66,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:18,energy efficiency,load,loadings,18,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:442,energy efficiency,load,loadings,442,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:565,energy efficiency,load,loading,565,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:802,energy efficiency,load,loadings,802,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:1209,energy efficiency,load,loadings,1209,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:1078,modifiability,deco,decomposition,1078,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:18,performance,load,loadings,18,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:442,performance,load,loadings,442,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:565,performance,load,loading,565,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:802,performance,load,loadings,802,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:1209,performance,load,loadings,1209,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/836:66,reliability,slo,slot,66,"Scanpy stores the loadings for each PC in the `adata.varm['PCs']` slot. The order is the same is `obs_names`, but you can use pandas functions like `sort_values` to look at the top genes or do something like `np.argsort` or `scipy.stats.rankdata` on the columns (the PCs) to get their ranks. ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.pca(pbmc, svd_solver='arpack', random_state=0). # Get loadings for each gene for each PC. df_loadings = pd.DataFrame(pbmc.varm['PCs'], index=pbmc.var_names). # get rank of each loading for each PC. df_rankings = pd.DataFrame((-1 * df_loadings.values).argsort(0).argsort(0), index=df_loadings.index, columns=df_loadings.columns). # c.f. with df_loadings.apply(scipy.stats.rankdata, axis=0). # evaluate . print(""Top loadings for PC1...""). print(df_loadings[0].sort_values().tail()). print(""Rank of PTPRCAP for first 5 PCs...""). print(df_rankings.loc[""PTPRCAP""].head()). sc.pl.pca_loadings(pbmc). # alternatively, you can do SVD or PCA manually with scipy, numpy, sklearn, etc. # from sklearn.decomposition import PCA. # pc = PCA(n_components=50, svd_solver='arpack', random_state=0).fit(pbmc.X). # pc.components_.T has the loadings. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/836
https://github.com/scverse/scanpy/issues/837:120,availability,operat,operations,120,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:40,deployability,version,version,40,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:40,integrability,version,version,40,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:109,integrability,sub,subsetting,109,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:40,modifiability,version,version,40,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:68,modifiability,maintain,maintain,68,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/837:68,safety,maintain,maintain,68,"This seems to work with the development version of anndata where we maintain the dimensions of arrays during subsetting operations. If you want to get your results back however, I think you'd have to do something more like:. ```python. a = sc.datasets.paul15(). b = a[:, 0]. sc.pp.neighbors(b). # or. b = sc.pp.neighbors(a[:, 0], copy=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/837
https://github.com/scverse/scanpy/issues/838:104,integrability,batch,batch,104,"Would something like this work? ```python. adata.obs[""comparison""] = np.nan. adata.obs.loc[. adata.obs[""batch""].isin([""sample01"", ""sample02""]) & adata.obs[""leiden""].isin([""1"", ""2"", ""3""]),. ""comparison"". ] = ""A"". adata.obs.loc[. (adata.obs[""batch""] == ""sample03"") & adata.obs[""leiden""].isin([""2"", ""3""]),. ""comparison"". ] = ""B"". sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). sc.get.rank_genes_groups_df(adata, ""A""). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:240,integrability,batch,batch,240,"Would something like this work? ```python. adata.obs[""comparison""] = np.nan. adata.obs.loc[. adata.obs[""batch""].isin([""sample01"", ""sample02""]) & adata.obs[""leiden""].isin([""1"", ""2"", ""3""]),. ""comparison"". ] = ""A"". adata.obs.loc[. (adata.obs[""batch""] == ""sample03"") & adata.obs[""leiden""].isin([""2"", ""3""]),. ""comparison"". ] = ""B"". sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). sc.get.rank_genes_groups_df(adata, ""A""). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:104,performance,batch,batch,104,"Would something like this work? ```python. adata.obs[""comparison""] = np.nan. adata.obs.loc[. adata.obs[""batch""].isin([""sample01"", ""sample02""]) & adata.obs[""leiden""].isin([""1"", ""2"", ""3""]),. ""comparison"". ] = ""A"". adata.obs.loc[. (adata.obs[""batch""] == ""sample03"") & adata.obs[""leiden""].isin([""2"", ""3""]),. ""comparison"". ] = ""B"". sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). sc.get.rank_genes_groups_df(adata, ""A""). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:240,performance,batch,batch,240,"Would something like this work? ```python. adata.obs[""comparison""] = np.nan. adata.obs.loc[. adata.obs[""batch""].isin([""sample01"", ""sample02""]) & adata.obs[""leiden""].isin([""1"", ""2"", ""3""]),. ""comparison"". ] = ""A"". adata.obs.loc[. (adata.obs[""batch""] == ""sample03"") & adata.obs[""leiden""].isin([""2"", ""3""]),. ""comparison"". ] = ""B"". sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). sc.get.rank_genes_groups_df(adata, ""A""). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:198,availability,error,error,198,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:252,deployability,modul,module,252,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:467,deployability,modul,module,467,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:713,deployability,api,api,713,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:877,deployability,modul,module,877,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1292,deployability,modul,module,1292,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1317,deployability,modul,module,1317,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:483,integrability,pub,public-supool,483,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:713,integrability,api,api,713,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:893,integrability,pub,public-supool,893,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:713,interoperability,api,api,713,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:252,modifiability,modul,module,252,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:467,modifiability,modul,module,467,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:554,modifiability,pac,packages,554,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:877,modifiability,modul,module,877,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:964,modifiability,pac,packages,964,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1292,modifiability,modul,module,1292,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1317,modifiability,modul,module,1317,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:198,performance,error,error,198,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:198,safety,error,error,198,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:252,safety,modul,module,252,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:467,safety,modul,module,467,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:877,safety,modul,module,877,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1292,safety,modul,module,1292,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1317,safety,modul,module,1317,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:403,testability,Trace,Traceback,403,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:813,testability,Trace,Traceback,813,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1228,testability,Trace,Traceback,1228,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:31,usability,help,help,31,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:198,usability,error,error,198,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:570,usability,tool,tools,570,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:980,usability,tool,tools,980,"@ivirshup . Hi, thank for your help. When I ran this code (sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]); the previous three code worked perfectly), I got some error. I don't know whether they came from the scanpy module or something else. ```python. >>> import scanpy as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.api as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py"", line 120, in rank_genes_groups. groups_order += [reference]. TypeError: must be str, not list. >>> import scanpy.external as sc. >>> sc.tl.rank_genes_groups(adata, ""comparison"", reference=""B"", n_genes=adata.shape[1]). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. AttributeError: module 'scanpy.external.tl' has no attribute 'rank_genes_groups'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:161,deployability,api,api,161,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:263,deployability,releas,release,263,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:319,deployability,upgrad,upgrade,319,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:403,deployability,instal,install,403,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:161,integrability,api,api,161,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:161,interoperability,api,api,161,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:319,modifiability,upgrad,upgrade,319,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:45,usability,document,documentation,45,"Hi! You shouldn’t need to try here: Read the documentation at https://scanpy.rtfd.io to figure out if what you want is in `scanpy` or `scanpy.external`. `scanpy.api` is deprecated, you should never use it. The code @ivirshup gave you will work in the next scanpy release, as scanpy 1.4.4 still has the bug #346. Please upgrade to scanpy from git master and try again. You can do that via:. ```bash. pip install git+https://github.com/theislab/scanpy.git. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:80,availability,error,errors,80,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:481,availability,error,error,481,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:834,availability,down,download,834,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1116,availability,error,error,1116," pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1167,availability,Down,Download,1167,"git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1463,availability,Down,Downloading,1463,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1588,availability,down,downloaded,1588,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:29,deployability,instal,install,29,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:45,deployability,version,version,45,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:124,deployability,instal,install,124,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:327,deployability,build,build,327,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:462,deployability,build,build,462,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:469,deployability,fail,failed,469,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:536,deployability,instal,install,536,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:733,deployability,build,build,733,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:910,deployability,build,build,910,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1029,deployability,instal,install,1029,"all the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1104,deployability,fail,failed,1104," code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1322,deployability,fail,failed,1322,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1345,deployability,instal,install,1345,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1622,deployability,build,build,1622,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1753,deployability,build,build,1753,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2189,deployability,fail,failed,2189,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2230,deployability,instal,install,2230,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2266,deployability,instal,install,2266,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:45,integrability,version,version,45,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1133,integrability,pub,public-supool,1133,"s://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1692,interoperability,format,format,1692,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1725,interoperability,format,format,1725,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:45,modifiability,version,version,45,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:963,modifiability,Pac,PackageNotFoundError,963,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2184,modifiability,pac,pack,2184,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:80,performance,error,errors,80,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:481,performance,error,error,481,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1116,performance,error,error,1116," pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1629,performance,content,content-type,1629,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:469,reliability,fail,failed,469,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1104,reliability,fail,failed,1104," code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1322,reliability,fail,failed,1322,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2189,reliability,fail,failed,2189,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:80,safety,error,errors,80,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:481,safety,error,error,481,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1116,safety,error,error,1116," pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1677,safety,detect,detect,1677,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1677,security,detect,detect,1677,"/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung up unexpectedly MiB | 28.00 KiB/s. fatal: early EOF. fatal: index-pack failed. ```. however, i can successfully install scanpy 1.4.4 with. ```. pip install scanpy. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:80,usability,error,errors,80,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:363,usability,help,helper,363,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:383,usability,Command,Command,383,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:481,usability,error,error,481,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:793,usability,stop,stop,793,"@flying-sheep Hi, I tried to install the new version of scanpy, but encountered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1069,usability,Command,Command,1069,"ntered errors. first, I tried your code . ```. pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1116,usability,error,error,1116," pip install git+https://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /tmp/pip-_z2v8och-build. fatal: Unable to find remote helper for 'https'. Command ""git clone -q https://github.com/theislab/scanpy.git /tmp/pip-_z2v8och-build"" failed with error code 128 in None. ```. second, I tried. ```. pip install git+git://github.com/theislab/scanpy.git . ```. I got ouput as:. ```. Collecting git+git://github.com/theislab/scanpy.git. Cloning git://github.com/theislab/scanpy.git to /tmp/pip-2jry40l_-build. ```. and there was no more information and I have to stop it with ""ctrl+C"". third, I tried to download the zip and `cd` to that directory and used . ```. python setup.py build. ```. I got ouput as:. ```. importlib_metadata.PackageNotFoundError: scanpy. ```. after this, I tried . ```. pip install -e . ```. I got ouput as:. ```. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```. I searched the relative information in GitHub/Scanpy, but still have no solution for my situation. the following was another failed code. ``` . pip install https://github.com/theislab/scanpy.git. ```. output:. ```. Collecting https://github.com/theislab/scanpy.git. Downloading https://github.com/theislab/scanpy.git. \ 143kB 442kB/s. Cannot unpack file /tmp/pip-chtzh_a9-unpack/scanpy.git (downloaded from /tmp/pip-xolhyav7-build, content-type: text/html; charset=utf-8); cannot detect archive format. Cannot determine archive format of /tmp/pip-xolhyav7-build. ```. and i also tried. ```. git clone --recursive git://github.com/theislab/scanpy.git. ```. output:. ```. Cloning into 'scanpy'... remote: Enumerating objects: 122, done. remote: Counting objects: 100% (122/122), done. remote: Compressing objects: 100% (109/109), done. Receiving objects: 3% (577/14992), 156.00 KiB | 3.00 KiB/s. fatal: The remote end hung u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:460,availability,down,downloadable,460,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:6,deployability,instal,install,6,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:119,deployability,instal,installation,119,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:234,deployability,instal,installing,234,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:287,deployability,instal,installing,287,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:334,deployability,instal,install,334,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:404,deployability,instal,install,404,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:428,deployability,instal,install,428,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:686,deployability,instal,installation,686,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:542,integrability,repositor,repository,542,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:542,interoperability,repositor,repository,542,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:166,modifiability,Pac,PackageNotFoundError,166,"> pip install git+git://github.com/theislab/scanpy.git . should have worked, there seems to be a problem with your git installation or internet. > importlib_metadata.PackageNotFoundError: scanpy. That’s my mistake, seems like a broke installing from .zips (not that anyone tried so far, installing from git is more convenient). > pip install https://github.com/theislab/scanpy.git. This won’t work, `pip install http...` means “install me a `sdist` or `wheel` downloadable from that URL”, but there’s no sdist or wheel at that URL, but a git repository. > git clone --recursive git://github.com/theislab/scanpy.git. again, this should work, probably a problem with your internet or git installation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:115,deployability,instal,install,115,What you can do is. 1. go into the folder from the extracted zip. 2. `git init`. 3. `git tag v1.4.5.dev0`. 4. `pip install -e .`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:305,availability,Down,Download,305,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:513,availability,Down,Download,513,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:670,availability,Down,Download,670,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1015,availability,Down,Download,1015," the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. C",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1154,availability,Down,Download,1154,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1294,availability,Down,Download,1294,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2065,availability,error,error,2065,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2116,availability,Down,Download,2116,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:383,deployability,Fail,Failed,383,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:448,deployability,instal,install,448,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:727,deployability,modul,module,727,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:776,deployability,Modul,ModuleNotFoundError,776,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:800,deployability,modul,module,800,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:965,deployability,modul,module,965,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1062,deployability,modul,module,1062,"ter]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1211,deployability,modul,module,1211,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1234,deployability,version,version,1234,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1348,deployability,version,version,1348,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1364,deployability,version,version,1364,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1515,deployability,version,version,1515,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1553,deployability,version,version,1553,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2053,deployability,fail,failed,2053,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:256,integrability,repositor,repository,256,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:271,integrability,pub,public-supool,271,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:479,integrability,pub,public-supool,479,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:636,integrability,pub,public-supool,636,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:981,integrability,pub,public-supool,981,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1120,integrability,pub,public-supool,1120," pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1234,integrability,version,version,1234,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1260,integrability,pub,public-supool,1260,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1348,integrability,version,version,1348,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1364,integrability,version,version,1364,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1389,integrability,pub,public-supool,1389,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1515,integrability,version,version,1515,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1553,integrability,version,version,1553,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1569,integrability,pub,public-supool,1569,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1756,integrability,pub,public-supool,1756,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2082,integrability,pub,public-supool,2082,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:256,interoperability,repositor,repository,256,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1531,interoperability,distribut,distribution,1531,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1695,interoperability,distribut,distribution,1695,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1716,interoperability,Distribut,Distribution,1716,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:727,modifiability,modul,module,727,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:776,modifiability,Modul,ModuleNotFoundError,776,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:800,modifiability,modul,module,800,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:965,modifiability,modul,module,965,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1062,modifiability,modul,module,1062,"ter]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1211,modifiability,modul,module,1211,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1234,modifiability,version,version,1234,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1348,modifiability,version,version,1348,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1364,modifiability,version,version,1364,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1372,modifiability,pac,package,1372,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1460,modifiability,pac,packages,1460,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1515,modifiability,version,version,1515,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1544,modifiability,pac,package,1544,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1553,modifiability,version,version,1553,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1640,modifiability,pac,packages,1640,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1739,modifiability,pac,package,1739,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1827,modifiability,pac,packages,1827,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1899,modifiability,Pac,PackageNotFoundError,1899,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1946,modifiability,Pac,PackageNotFoundError,1946,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2065,performance,error,error,2065,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:383,reliability,Fail,Failed,383,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2053,reliability,fail,failed,2053,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:413,safety,valid,valid,413,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:537,safety,Compl,Complete,537,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:727,safety,modul,module,727,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:776,safety,Modul,ModuleNotFoundError,776,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:800,safety,modul,module,800,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:860,safety,except,exception,860,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:879,safety,except,exception,879,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:965,safety,modul,module,965,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1062,safety,modul,module,1062,"ter]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:1211,safety,modul,module,1211,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2065,safety,error,error,2065,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:537,security,Compl,Complete,537,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:593,testability,Trace,Traceback,593,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:900,testability,Trace,Traceback,900,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:558,usability,command,command,558,"@flying-sheep I got the similar result. ```python. >>> scanpy-master]$ ls. conftest.py CONTRIBUTING.md docs LICENSE MANIFEST.in pyproject.toml pytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2018,usability,Command,Command,2018,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:2065,usability,error,error,2065,"ytest.ini README.rst requirements.txt scanpy setup.py. >>> scanpy-master]$ git init. Reinitialized existing Git repository in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/.git/. >>> scanpy-master]$ git tag v1.4.5.dev0. fatal: Failed to resolve 'HEAD' as a valid ref. >>> scanpy-master]$ pip install -e . Obtaining file:///public-supool/home/wuhaoda/Scanpy/Download/scanpy-master. Complete output from command python setup.py egg_info:. Traceback (most recent call last):. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 25, in <module>. from setuptools_scm import get_version. ModuleNotFoundError: No module named 'setuptools_scm'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/setup.py"", line 11, in <module>. from scanpy import __author__, __email__. File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/__init__.py"", line 29, in <module>. __version__ = version(__name__). File ""/public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/scanpy/_utils.py"", line 29, in version. return version(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 438, in version. return distribution(package).version. File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 411, in distribution. return Distribution.from_name(package). File ""/public-supool/home/wuhaoda/anaconda2/envs/Grim3.6.8/lib/python3.6/site-packages/importlib_metadata/__init__.py"", line 184, in from_name. raise PackageNotFoundError(name). importlib_metadata.PackageNotFoundError: scanpy. ----------------------------------------. Command ""python setup.py egg_info"" failed with error code 1 in /public-supool/home/wuhaoda/Scanpy/Download/scanpy-master/. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:5,deployability,Modul,ModuleNotFoundError,5,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:29,deployability,modul,module,29,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:5,modifiability,Modul,ModuleNotFoundError,5,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:29,modifiability,modul,module,29,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:5,safety,Modul,ModuleNotFoundError,5,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:29,safety,modul,module,29,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:177,usability,help,help,177,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/issues/838:187,usability,help,helping,187,"```. ModuleNotFoundError: No module named 'setuptools_scm'. ```. Aha! well, I’d like you to look out for obvious and fixable problems like this and fix them before you turn for help. I’m helping many people for free and a bit of thinking for oneself goes a long way.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/838
https://github.com/scverse/scanpy/pull/839:52,safety,test,tests,52,"I think separating static analysis from running the tests is the way to go (in #841 I added black checking as a separate step.). Also mypy is very strict, so we might have to fix *a lot*.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:52,testability,test,tests,52,"I think separating static analysis from running the tests is the way to go (in #841 I added black checking as a separate step.). Also mypy is very strict, so we might have to fix *a lot*.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:95,interoperability,stub,stubs,95,I'm not sure the benefits from using mypy would outweigh the pain in using unstable numpy type-stubs,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:95,testability,stub,stubs,95,I'm not sure the benefits from using mypy would outweigh the pain in using unstable numpy type-stubs,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:79,reliability,doe,doesn,79,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:132,safety,test,testing,132,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:193,safety,test,test,193,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:345,safety,compl,complex,345,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:345,security,compl,complex,345,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:132,testability,test,testing,132,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:193,testability,test,test,193,"It’s both bullshit that that numpy/numpy#2776 is unfixed since 2012 and Python doesn’t have instance checks for collections without testing for all the mixed-in methods. What we mostly want to test for is if something is iterable and/or indexable. For “sized iterable”, this is possible via `isinstance(x, cabc.Collection)`, but everything more complex has all those mixin methods that are checked for …. At least what we have now is better than `isinstance(x, list)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:567,reliability,doe,doesn,567,"Actually, I call bullshit even more:. ```py. class seq_array(np.ndarray):. def __reversed__(self):. return iter(self[::-1]). def index(self, value) -> int:. return np.in1d(self, value).nonzero()[0]. def count(self, value) -> int:. return (self == value).sum(). assert issubclass(seq_array, cabc.Collection). assert issubclass(seq_array, cabc.Reversible). for meth in ""__contains__ __iter__ __reversed__ index count"".split():. assert hasattr(seq_array, meth), meth. print(issubclass(seq_array, cabc.Sequence)). ```. prints `False`. wat.jpg. /edit: Hilarious. Sequence doesn’t implement `__subclasscheck__`, so only things that are `Sequence.register`ed are considered sequences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:261,testability,assert,assert,261,"Actually, I call bullshit even more:. ```py. class seq_array(np.ndarray):. def __reversed__(self):. return iter(self[::-1]). def index(self, value) -> int:. return np.in1d(self, value).nonzero()[0]. def count(self, value) -> int:. return (self == value).sum(). assert issubclass(seq_array, cabc.Collection). assert issubclass(seq_array, cabc.Reversible). for meth in ""__contains__ __iter__ __reversed__ index count"".split():. assert hasattr(seq_array, meth), meth. print(issubclass(seq_array, cabc.Sequence)). ```. prints `False`. wat.jpg. /edit: Hilarious. Sequence doesn’t implement `__subclasscheck__`, so only things that are `Sequence.register`ed are considered sequences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:308,testability,assert,assert,308,"Actually, I call bullshit even more:. ```py. class seq_array(np.ndarray):. def __reversed__(self):. return iter(self[::-1]). def index(self, value) -> int:. return np.in1d(self, value).nonzero()[0]. def count(self, value) -> int:. return (self == value).sum(). assert issubclass(seq_array, cabc.Collection). assert issubclass(seq_array, cabc.Reversible). for meth in ""__contains__ __iter__ __reversed__ index count"".split():. assert hasattr(seq_array, meth), meth. print(issubclass(seq_array, cabc.Sequence)). ```. prints `False`. wat.jpg. /edit: Hilarious. Sequence doesn’t implement `__subclasscheck__`, so only things that are `Sequence.register`ed are considered sequences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:426,testability,assert,assert,426,"Actually, I call bullshit even more:. ```py. class seq_array(np.ndarray):. def __reversed__(self):. return iter(self[::-1]). def index(self, value) -> int:. return np.in1d(self, value).nonzero()[0]. def count(self, value) -> int:. return (self == value).sum(). assert issubclass(seq_array, cabc.Collection). assert issubclass(seq_array, cabc.Reversible). for meth in ""__contains__ __iter__ __reversed__ index count"".split():. assert hasattr(seq_array, meth), meth. print(issubclass(seq_array, cabc.Sequence)). ```. prints `False`. wat.jpg. /edit: Hilarious. Sequence doesn’t implement `__subclasscheck__`, so only things that are `Sequence.register`ed are considered sequences.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:133,reliability,doe,does,133,"Is a multidimensional array still a sequence? Should `iter(s: Sequence[T]) -> Iterable[T]`? That's not what a multidimensional array does. I guess I'm not even sure what the definition of a sequence is meant to be. That thread brings up a good case of 0-dimensional arrays. On generic types, working with both numpy and pythons type system is a bit of a pain. `isinstance(np.int64(1), int) == False`. Plus numpy's `dtype` system is a bit of a mess in general. This is the stuff that makes me go write Julia for a while.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:227,availability,error,errors,227,"Of course it is, but it’s a sequence of sequences (… of sequences of sequences …):. ```py. >>> list(iter(np.array([[1,2],[3,5]]))) . [array([1, 2]), array([3, 5])]. ```. Yes, 0D-arrays aren’t sequences, but I’m OK with runtime errors if you pass one of those here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:227,performance,error,errors,227,"Of course it is, but it’s a sequence of sequences (… of sequences of sequences …):. ```py. >>> list(iter(np.array([[1,2],[3,5]]))) . [array([1, 2]), array([3, 5])]. ```. Yes, 0D-arrays aren’t sequences, but I’m OK with runtime errors if you pass one of those here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:227,safety,error,errors,227,"Of course it is, but it’s a sequence of sequences (… of sequences of sequences …):. ```py. >>> list(iter(np.array([[1,2],[3,5]]))) . [array([1, 2]), array([3, 5])]. ```. Yes, 0D-arrays aren’t sequences, but I’m OK with runtime errors if you pass one of those here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/pull/839:227,usability,error,errors,227,"Of course it is, but it’s a sequence of sequences (… of sequences of sequences …):. ```py. >>> list(iter(np.array([[1,2],[3,5]]))) . [array([1, 2]), array([3, 5])]. ```. Yes, 0D-arrays aren’t sequences, but I’m OK with runtime errors if you pass one of those here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/839
https://github.com/scverse/scanpy/issues/842:33,safety,test,test,33,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:360,safety,test,test,360,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:524,safety,test,test,524,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:33,testability,test,test,33,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:360,testability,test,test,360,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:524,testability,test,test,524,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:597,testability,assert,assert,597,"What's happening is in the first test you're still comparing each group to all other cells. Here's a quick example of that:. ```python. import scanpy as sc. import numpy as np. adata = sc.datasets.pbmc68k_reduced(). adata.X = adata.raw.X.copy(). sc.tl.leiden(adata). a = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). b = sc.tl.rank_genes_groups( . adata=adata, . groupby='leiden', . use_raw=False, . method='t-test', . # groups=['1', '2'], . n_genes=adata.shape[1], . copy=True . ). assert np.all(sc.get.rank_genes_groups_df(a, ""1"") == sc.get.rank_genes_groups_df(b, ""1"")). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:84,deployability,api,api,84,"Thanks, however I think the [documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups) is not perfectly clear about it:. > groups : str, Iterable[str]. Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:84,integrability,api,api,84,"Thanks, however I think the [documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups) is not perfectly clear about it:. > groups : str, Iterable[str]. Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:215,integrability,Sub,Subset,215,"Thanks, however I think the [documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups) is not perfectly clear about it:. > groups : str, Iterable[str]. Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:84,interoperability,api,api,84,"Thanks, however I think the [documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups) is not perfectly clear about it:. > groups : str, Iterable[str]. Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:29,usability,document,documentation,29,"Thanks, however I think the [documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups) is not perfectly clear about it:. > groups : str, Iterable[str]. Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:167,usability,clear,clear,167,"Thanks, however I think the [documentation](https://scanpy.readthedocs.io/en/stable/api/scanpy.tl.rank_genes_groups.html#scanpy.tl.rank_genes_groups) is not perfectly clear about it:. > groups : str, Iterable[str]. Subset of groups, e.g. ['g1', 'g2', 'g3'], to which comparison shall be restricted, or 'all' (default), for all groups. What do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:41,usability,clear,clearer,41,Sorry about that. Any idea how we can be clearer?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:305,deployability,API,API,305,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:623,deployability,api,api,623,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:41,integrability,Sub,Subset,41,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:231,integrability,sub,subset,231,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:305,integrability,API,API,305,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:326,integrability,sub,subsetting,326,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:623,integrability,api,api,623,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:697,integrability,interfac,interface,697,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:305,interoperability,API,API,305,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:528,interoperability,specif,specific,528,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:623,interoperability,api,api,623,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:697,interoperability,interfac,interface,697,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:372,modifiability,paramet,parameter,372,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:467,modifiability,paramet,parameter,467,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:697,modifiability,interfac,interface,697,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/842:410,usability,intuit,intuitive,410,"No worries. It can be something like:. > Subset of groups, e.g. ['g1', 'g2', 'g3'], for which the list of DE genes should be computed. Each group of cells is always compared to the remaining cells, even if they don't belong to the subset of groups. However, it would be probably more useful to change the API and to implement subsetting of the groups through the 'groups' parameter. I think this would be more intuitive, also together with the use of the 'reference' parameter. In particular, because retrieving of DE genes for specific groups can be more easily done with the [get](https://scanpy.readthedocs.io/en/stable/api/scanpy.get.rank_genes_groups_df.html#scanpy.get.rank_genes_groups_df) interface. But there may be other use cases I haven't considered in which the actual implementation may be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/842
https://github.com/scverse/scanpy/issues/843:149,deployability,releas,release,149,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:258,deployability,releas,release,258,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:71,interoperability,heterogen,heterogeneous,71,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:234,reliability,doe,does,234,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:335,safety,test,test,335,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:335,testability,test,test,335,"It looks like the underlying issue (`np.zeros` was being called with a heterogeneous `shape` tuple) has been marked to be resolved in the next numba release. We could implement a workaround here where we force the dtype, though numba does have a pretty fast release cadence. @fkoegel, if we implemented a fix here would you be able to test it for us on master branches?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:34,availability,error,errors,34,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:112,energy efficiency,Current,Currently,112,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:34,performance,error,errors,34,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:34,safety,error,errors,34,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:70,safety,test,test,70,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:70,testability,test,test,70,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/issues/843:34,usability,error,errors,34,@ivirshup I am getting same numba errors on windows 10 machine. I can test the workaround if you provide a fix. Currently to make the function working I set `percent_top=None`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/843
https://github.com/scverse/scanpy/pull/844:397,deployability,version,version,397,"Benchmark results from my laptop:. | | Parallel | Single |. |-|--------|--------|. | Compilation | ~12s | ~5s |. | Run (3k cells, 37k genes) | ~70ms | ~120ms | . | Run (50k cells, 35k genes) | ~3.8s | ~8.1s | . | Run (370k cells, 33k genes) | ~13.7s | ~17.4 s |. So... probably worth it? I recall the difference being more pronounced with larger dataset sizes, but that was with a different numba version and maybe a different machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:397,integrability,version,version,397,"Benchmark results from my laptop:. | | Parallel | Single |. |-|--------|--------|. | Compilation | ~12s | ~5s |. | Run (3k cells, 37k genes) | ~70ms | ~120ms | . | Run (50k cells, 35k genes) | ~3.8s | ~8.1s | . | Run (370k cells, 33k genes) | ~13.7s | ~17.4 s |. So... probably worth it? I recall the difference being more pronounced with larger dataset sizes, but that was with a different numba version and maybe a different machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:397,modifiability,version,version,397,"Benchmark results from my laptop:. | | Parallel | Single |. |-|--------|--------|. | Compilation | ~12s | ~5s |. | Run (3k cells, 37k genes) | ~70ms | ~120ms | . | Run (50k cells, 35k genes) | ~3.8s | ~8.1s | . | Run (370k cells, 33k genes) | ~13.7s | ~17.4 s |. So... probably worth it? I recall the difference being more pronounced with larger dataset sizes, but that was with a different numba version and maybe a different machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:39,performance,Parallel,Parallel,39,"Benchmark results from my laptop:. | | Parallel | Single |. |-|--------|--------|. | Compilation | ~12s | ~5s |. | Run (3k cells, 37k genes) | ~70ms | ~120ms | . | Run (50k cells, 35k genes) | ~3.8s | ~8.1s | . | Run (370k cells, 33k genes) | ~13.7s | ~17.4 s |. So... probably worth it? I recall the difference being more pronounced with larger dataset sizes, but that was with a different numba version and maybe a different machine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:4,availability,down,downside,4,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:213,availability,slo,slow,213,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:218,availability,down,down,218,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:277,integrability,wrap,wrap,277,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:47,performance,time,time,47,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:205,reliability,doe,doesn,205,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:213,reliability,slo,slow,213,"> A downside of this is it takes a really long time to compile on first run, which might be off-putting. Right, numba only compiles stuff when first run (because otherwise it can’t know the types) so this doesn’t slow down importing scanpy. > So... probably worth it? We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. If we do this in a generic way we could even defer importing numpy, saving on import duration (although there probably isn’t much functionality without running numpy-driven functions)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:341,deployability,instal,install,341,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:11,integrability,wrap,wrap,11,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:231,performance,disk,disk,231,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:236,performance,cach,cacheing,236,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:248,performance,parallel,parallelized,248,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:355,performance,cach,cache,355,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:488,performance,time,times,488,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:480,safety,test,testing,480,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:416,security,modif,modified,416,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:480,testability,test,testing,480,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:520,usability,document,documentation,520,"> We could wrap it in a function that checks the number of cells and only compiles this to faster code when necessary. So that's what this PR would replace. The reason I thought this could be replaced is that `numba` now allows on-disk cacheing of parallelized functions. This means that the function would only have to be compiled once per install. That cache only get's invalidated if function's source code get's modified, so this shouldn't cause too much pain for development testing times. I've added a note to the documentation mentioning this, so I think it's fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:18,deployability,instal,install,18,"OK! A global, per-install cache. Where is it stored?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/844:26,performance,cach,cache,26,"OK! A global, per-install cache. Where is it stored?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/844
https://github.com/scverse/scanpy/pull/847:91,availability,checkpoint,checkpoints,91,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:108,deployability,pipelin,pipeline,108,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:108,integrability,pipelin,pipeline,108,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:71,performance,cach,caches,71,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:91,reliability,checkpoint,checkpoints,91,"@ivirshup I think writing a file for uploading it to the web, for read caches, and for for checkpoints of a pipeline has different requirements. I think a `h5ad_compression` or even `hdf5_compression` setting could have its place, but separately from the `cache_compression`. We’ll have to think about naming though. Maybe we want to namespace our settings like matplotlib’s rcparams?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:156,deployability,api,api,156,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:264,deployability,api,api,264,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:156,integrability,api,api,156,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:264,integrability,api,api,264,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:156,interoperability,api,api,156,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:264,interoperability,api,api,264,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:322,interoperability,specif,specifically,322,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:30,usability,document,document,30,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/pull/847:98,usability,document,documented,98,"ah, right, we should probably document it better. The attributes you can set on `sc.settings` are documented [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.html), `cache_compression` [here](https://scanpy.readthedocs.io/en/stable/api/scanpy._settings.ScanpyConfig.cache_compression.html) specifically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/847
https://github.com/scverse/scanpy/issues/849:52,deployability,updat,updates,52,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:260,deployability,version,version,260,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:301,deployability,fail,fail,301,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:323,deployability,canary,canary,323,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:340,deployability,fail,fails,340,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:260,integrability,version,version,260,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:144,modifiability,concern,concerned,144,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:260,modifiability,version,version,260,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:301,reliability,fail,fail,301,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:340,reliability,fail,fails,340,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:52,safety,updat,updates,52,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:330,safety,test,test,330,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:52,security,updat,updates,52,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:144,testability,concern,concerned,144,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/849:330,testability,test,test,330,"This seems to be working now. Given that matplotlib updates are known to introduce bugs, I'm not sure we want to pin matplotlib to `3.3.3`. I'm concerned that's too strong of a restriction, since it's likely there's someone out there who needs to use an older version. Right now this is causing CI to fail, since there's a canary test that fails when the function works 😆.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/849
https://github.com/scverse/scanpy/issues/850:121,security,sign,signify,121,"It’s hard to read … Please use markdown syntax for code:. ````markdown. My code:. ```python. <code here>. ```. ````. And signify which lines are code and which are output, e.g. by adding `#` in front of output lines",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:44,deployability,updat,updated,44,"@flying-sheep sorry for the trouble, I have updated my code and output.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:44,safety,updat,updated,44,"@flying-sheep sorry for the trouble, I have updated my code and output.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:44,security,updat,updated,44,"@flying-sheep sorry for the trouble, I have updated my code and output.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:141,performance,time,time,141,"I tried "">>>"" before, and thought the grey front may make it difficult for you to read....and then change it to $..... I would use that next time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:8,safety,compl,complete,8,mission complete :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:8,security,compl,complete,8,mission complete :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:131,reliability,doe,does,131,"Looks good, thank you. The reason I was so insistent is that it’s important here what the notebook cells are. Jupyter notebook/lab does fancy stuff with matplotlib figures, so that might well be a factor here. Am I right that each of the 3 code blocks is a separate cell in your notebook?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:319,availability,down,download,319,"@flying-sheep sorry, I didn't use Jupyter notebook. one is because i am a fresh man in python. second is that our engineer of the lab server told us that we don't have ""??? some image software"" due to the limited memory. (I think, he means we could use R, but we cannot see the figure like Rstudio. we have to save it, download it to our PC, and view the figure.) I would try Juputer tomorrow~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:213,performance,memor,memory,213,"@flying-sheep sorry, I didn't use Jupyter notebook. one is because i am a fresh man in python. second is that our engineer of the lab server told us that we don't have ""??? some image software"" due to the limited memory. (I think, he means we could use R, but we cannot see the figure like Rstudio. we have to save it, download it to our PC, and view the figure.) I would try Juputer tomorrow~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:213,usability,memor,memory,213,"@flying-sheep sorry, I didn't use Jupyter notebook. one is because i am a fresh man in python. second is that our engineer of the lab server told us that we don't have ""??? some image software"" due to the limited memory. (I think, he means we could use R, but we cannot see the figure like Rstudio. we have to save it, download it to our PC, and view the figure.) I would try Juputer tomorrow~",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:302,deployability,instal,install,302,"Well, it makes working with all this easier, specifically if you can just see your figures inline instead of popup windows. You can try out jupyterlab here to get a small tutorial: https://mybinder.org/v2/gh/jupyterlab/jupyterlab-demo/try.jupyter.org?urlpath=lab. If you think you’d like it, just `pip install jupyterlab` and start it with `jupyter lab`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:45,interoperability,specif,specifically,45,"Well, it makes working with all this easier, specifically if you can just see your figures inline instead of popup windows. You can try out jupyterlab here to get a small tutorial: https://mybinder.org/v2/gh/jupyterlab/jupyterlab-demo/try.jupyter.org?urlpath=lab. If you think you’d like it, just `pip install jupyterlab` and start it with `jupyter lab`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:559,modifiability,paramet,parameter,559,"Sure! By the way: this is still a bug: `save` doesn’t seem to work at all! ```python. >>> import scanpy as sc. >>> adata = sc.datasets.pbmc68k_reduced(). >>> sc.tl.dendrogram(adata, 'louvain', n_pcs=30). >>> sc.pl.correlation_matrix(adata, 'louvain', save='Correlation--57.png'). [<matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f5ab390>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e5bfbd1d0>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f55a8d0>]. ```. I looked into the code and `correlation_matrix` doesn’t accept the `ax` parameter, but instead creates a figure. Your code doesn’t work because it won’t use your figure, therefore it stays empty! What you can do now is:. ```python. axes = sc.pl.correlation_matrix(adata, 'louvain'). axes[0].figure.savefig('57.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:46,reliability,doe,doesn,46,"Sure! By the way: this is still a bug: `save` doesn’t seem to work at all! ```python. >>> import scanpy as sc. >>> adata = sc.datasets.pbmc68k_reduced(). >>> sc.tl.dendrogram(adata, 'louvain', n_pcs=30). >>> sc.pl.correlation_matrix(adata, 'louvain', save='Correlation--57.png'). [<matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f5ab390>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e5bfbd1d0>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f55a8d0>]. ```. I looked into the code and `correlation_matrix` doesn’t accept the `ax` parameter, but instead creates a figure. Your code doesn’t work because it won’t use your figure, therefore it stays empty! What you can do now is:. ```python. axes = sc.pl.correlation_matrix(adata, 'louvain'). axes[0].figure.savefig('57.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:535,reliability,doe,doesn,535,"Sure! By the way: this is still a bug: `save` doesn’t seem to work at all! ```python. >>> import scanpy as sc. >>> adata = sc.datasets.pbmc68k_reduced(). >>> sc.tl.dendrogram(adata, 'louvain', n_pcs=30). >>> sc.pl.correlation_matrix(adata, 'louvain', save='Correlation--57.png'). [<matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f5ab390>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e5bfbd1d0>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f55a8d0>]. ```. I looked into the code and `correlation_matrix` doesn’t accept the `ax` parameter, but instead creates a figure. Your code doesn’t work because it won’t use your figure, therefore it stays empty! What you can do now is:. ```python. axes = sc.pl.correlation_matrix(adata, 'louvain'). axes[0].figure.savefig('57.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/850:610,reliability,doe,doesn,610,"Sure! By the way: this is still a bug: `save` doesn’t seem to work at all! ```python. >>> import scanpy as sc. >>> adata = sc.datasets.pbmc68k_reduced(). >>> sc.tl.dendrogram(adata, 'louvain', n_pcs=30). >>> sc.pl.correlation_matrix(adata, 'louvain', save='Correlation--57.png'). [<matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f5ab390>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e5bfbd1d0>,. <matplotlib.axes._subplots.AxesSubplot object at 0x7f7e4f55a8d0>]. ```. I looked into the code and `correlation_matrix` doesn’t accept the `ax` parameter, but instead creates a figure. Your code doesn’t work because it won’t use your figure, therefore it stays empty! What you can do now is:. ```python. axes = sc.pl.correlation_matrix(adata, 'louvain'). axes[0].figure.savefig('57.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/850
https://github.com/scverse/scanpy/issues/851:0,deployability,updat,update,0,"update on this, seems like this is an issue when the package is installed through conda,. reinstalled the package using pip and everything works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:64,deployability,instal,installed,64,"update on this, seems like this is an issue when the package is installed through conda,. reinstalled the package using pip and everything works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:53,modifiability,pac,package,53,"update on this, seems like this is an issue when the package is installed through conda,. reinstalled the package using pip and everything works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:106,modifiability,pac,package,106,"update on this, seems like this is an issue when the package is installed through conda,. reinstalled the package using pip and everything works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:0,safety,updat,update,0,"update on this, seems like this is an issue when the package is installed through conda,. reinstalled the package using pip and everything works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:0,security,updat,update,0,"update on this, seems like this is an issue when the package is installed through conda,. reinstalled the package using pip and everything works!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:43,modifiability,pac,package,43,@flying-sheep do we benefit from the conda package at all? I have been hearing complaints about it being outdated. if it's not maintained as good as the pypi package why don't we drop it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:127,modifiability,maintain,maintained,127,@flying-sheep do we benefit from the conda package at all? I have been hearing complaints about it being outdated. if it's not maintained as good as the pypi package why don't we drop it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:158,modifiability,pac,package,158,@flying-sheep do we benefit from the conda package at all? I have been hearing complaints about it being outdated. if it's not maintained as good as the pypi package why don't we drop it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:79,safety,compl,complaints,79,@flying-sheep do we benefit from the conda package at all? I have been hearing complaints about it being outdated. if it's not maintained as good as the pypi package why don't we drop it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:127,safety,maintain,maintained,127,@flying-sheep do we benefit from the conda package at all? I have been hearing complaints about it being outdated. if it's not maintained as good as the pypi package why don't we drop it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:79,security,compl,complaints,79,@flying-sheep do we benefit from the conda package at all? I have been hearing complaints about it being outdated. if it's not maintained as good as the pypi package why don't we drop it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:9,usability,support,support,9,"We don’t support it, @bgruening and @epruesse seem to do it: https://github.com/bioconda/bioconda-recipes/blob/master/recipes/scanpy/meta.yaml",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:34,energy efficiency,reduc,reduced,34,some of the datasets like pbmc68k-reduced also seem to have an issue loading in conda.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:69,energy efficiency,load,loading,69,some of the datasets like pbmc68k-reduced also seem to have an issue loading in conda.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:69,performance,load,loading,69,some of the datasets like pbmc68k-reduced also seem to have an issue loading in conda.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:85,deployability,releas,releases,85,"Actually I've always been using the conda package and never had any issues. . Github releases are watched by the bioconda-bot, so it should never be out of date, either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
https://github.com/scverse/scanpy/issues/851:42,modifiability,pac,package,42,"Actually I've always been using the conda package and never had any issues. . Github releases are watched by the bioconda-bot, so it should never be out of date, either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/851
